[{"texts": ["A person wearing denim jeans is standing and mixing something in a white cup with a hand mixer while a person whom hand is visible is pouring something in the white cup with the white mug."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/--7qK_w-g3Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 32, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_0_0_0"}, {"texts": ["The white cup starts rolling, and the person lifts the hand mixer from the white cup while the person takes a white bowl towards the white cup and he puts aside the white mug."], "durations": null, "exact_frames_per_prompt": [48], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/--7qK_w-g3Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 32, "npz_gt_video_start_frame": 32, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 32, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_0_0_1"}, {"texts": ["A person is putting liquid in a cup with a white mug while a person wearing a blue jeans is standing and holding a hand blander and blends some liquid in a cup the he steps back."], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/--7qK_w-g3Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 41, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_0_1_0"}, {"texts": ["The person is moving his hand backward."], "durations": null, "exact_frames_per_prompt": [5], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/--7qK_w-g3Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 41, "npz_gt_video_start_frame": 41, "npz_gt_video_end_frame": 46, "skip_frames_after_generation": 41, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_0_1_1"}, {"texts": ["The person puts something in a cup with a white bowl while a person stands on the backside."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/--7qK_w-g3Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 46, "npz_gt_video_start_frame": 46, "npz_gt_video_end_frame": 64, "skip_frames_after_generation": 46, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_0_1_2"}, {"texts": ["A person whose only hand is visible is holding a spoon while a person standing on the right side holding a hug and filling water to cup"], "durations": null, "exact_frames_per_prompt": [66], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/--7qK_w-g3Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 70, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_0_2_0"}, {"texts": ["The person moves his hand toward the cup while holding a spoon while a person moves hand towards the left side and holding a jug"], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/--7qK_w-g3Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 70, "npz_gt_video_start_frame": 70, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 70, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_0_2_1"}, {"texts": ["A man wearing a black jacket and white cap is standing and tightening the knot of the fish wire."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-b-YkpzFphk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_101_0_0"}, {"texts": ["A lady wearing blue clothes is sitting on a dark brown horse and driving the buffaloes towards the left side on a soil surface while a man in a blue shirt rides a brown horse to the right on the soil surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5ft5ebGnMFU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_104_1_0"}, {"texts": ["A man wearing blue clothes is sitting on a horse and coming from the left side and going toward the right side on a brown soil surface while a woman wearing blue jeans is riding a horse towards the left side on a soil surface, and a black animal is walking on a soil surface."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5ft5ebGnMFU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 40, "npz_gt_video_start_frame": 40, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 40, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_104_2_0"}, {"texts": ["A dark brown horse carrying a lady on his back is driving the buffaloes toward the left on a brown soil surface while a group of buffaloes is moving here and there on the soil surface, some people are standing, and a man is riding a brown horse towards the right."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5ft5ebGnMFU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_104_4_0"}, {"texts": ["A man wearing a white beekeeping suit is holding a beehive frame."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0M1SkaJJcV0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 31, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_105_0_0"}, {"texts": ["The man is then tapping the beehive frame behind the green plants."], "durations": null, "exact_frames_per_prompt": [32], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0M1SkaJJcV0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 31, "npz_gt_video_start_frame": 31, "npz_gt_video_end_frame": 63, "skip_frames_after_generation": 31, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_105_0_1"}, {"texts": ["The man starts walking to the left side."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0M1SkaJJcV0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 63, "npz_gt_video_start_frame": 63, "npz_gt_video_end_frame": 77, "skip_frames_after_generation": 63, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_105_0_2"}, {"texts": ["A man wearing a white t-shirt is juggling with the bottles while a group of people are sitting and looking at the glasses."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1VfEeERUGKM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_108_0_0"}, {"texts": ["A person wearing a white t-shirt first sits behind the man."], "durations": null, "exact_frames_per_prompt": [59], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1VfEeERUGKM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 63, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_108_1_0"}, {"texts": ["The person wearing a white t-shirt bends forward."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1VfEeERUGKM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 63, "npz_gt_video_start_frame": 63, "npz_gt_video_end_frame": 76, "skip_frames_after_generation": 63, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_108_1_1"}, {"texts": ["The person again sits back."], "durations": null, "exact_frames_per_prompt": [4], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1VfEeERUGKM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 76, "npz_gt_video_start_frame": 76, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 76, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_108_1_2"}, {"texts": ["A man wearing a grey t-shirt is sitting on a red chair and eating food."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-2kJpg1NIzM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_115_0_0"}, {"texts": ["A man wearing blue-black cloth is standing and holding a golf stick."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0u4c8Cel91U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 30, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_11_0_0"}, {"texts": ["The man is hitting a golf ball with his golf stick."], "durations": null, "exact_frames_per_prompt": [50], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0u4c8Cel91U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 30, "npz_gt_video_start_frame": 30, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 30, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_11_0_1"}, {"texts": ["A kid wearing a red-white striped t-shirt is sitting while a person whose hand is visible is holding a feeding bottle."], "durations": null, "exact_frames_per_prompt": [34], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0JFH2o8xhOc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 38, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_121_0_0"}, {"texts": ["The kid is drinking water given by a person."], "durations": null, "exact_frames_per_prompt": [42], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0JFH2o8xhOc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 38, "npz_gt_video_start_frame": 38, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 38, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_121_0_1"}, {"texts": ["A person whose hand is visible is holding the baby's bottle while a baby wearing a pink and white t-shirt sitting on the left side looking left again and again"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0JFH2o8xhOc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_121_2_0"}, {"texts": ["A boy wearing a red t-shirt is standing and making a sushi roll on a table in front of a group of children and speaking."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-C9gnkkNI6Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_124_0_0"}, {"texts": ["A man wearing a black t-shirt is playing golf inside a room while holding a golf stick."], "durations": null, "exact_frames_per_prompt": [45], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1QNmZ23rVzU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 49, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_125_0_0"}, {"texts": ["The man wearing a black t-shirt hits a golf ball with that stick."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1QNmZ23rVzU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 49, "npz_gt_video_start_frame": 49, "npz_gt_video_end_frame": 76, "skip_frames_after_generation": 49, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_125_0_1"}, {"texts": ["The ball goes into the golf putting cup."], "durations": null, "exact_frames_per_prompt": [4], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1QNmZ23rVzU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 76, "npz_gt_video_start_frame": 76, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 76, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_125_0_2"}, {"texts": ["A girl wearing a red-purple top is walking on a gray floor while a girl in a red t-shirt is standing and opening a present."], "durations": null, "exact_frames_per_prompt": [68], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-1Gh2yyYY7M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 72, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_127_0_0"}, {"texts": ["A girl wearing a red top is standing on a gray floor, holding a box and unwrapping it and looking at it while another baby wears a red top and is walking around her."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-1Gh2yyYY7M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_127_1_0"}, {"texts": ["A man wearing dark gray shorts is standing on a soil surface, holding a snake."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-g5emSW-SOg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_12_0_0"}, {"texts": ["The man is letting the snake go."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-g5emSW-SOg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 40, "npz_gt_video_start_frame": 40, "npz_gt_video_end_frame": 68, "skip_frames_after_generation": 40, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_12_0_1"}, {"texts": ["A black snake is getting held by the man."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-g5emSW-SOg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_12_1_0"}, {"texts": ["The snake is crawling on the soil surface while a man wearing a grey short is releasing a snake on the soil surface."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-g5emSW-SOg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 40, "npz_gt_video_start_frame": 40, "npz_gt_video_end_frame": 68, "skip_frames_after_generation": 40, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_12_1_1"}, {"texts": ["A person whose hand is visible is caressing a brown-white cat."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/24cgfaG8WI0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_133_0_0"}, {"texts": ["A brown-white cat is lying on a black printed surface and getting caressed by the person."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/24cgfaG8WI0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_133_1_0"}, {"texts": ["A boy wearing a blue outfit is standing on the grey surface and feeding a brown baby goat while a group of goats is standing at the back."], "durations": null, "exact_frames_per_prompt": [34], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-3cl74lG6T4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 38, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_135_0_0"}, {"texts": ["The boy starts moving towards the left."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-3cl74lG6T4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 38, "npz_gt_video_start_frame": 38, "npz_gt_video_end_frame": 67, "skip_frames_after_generation": 38, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_135_0_1"}, {"texts": ["The brown baby goat is standing on the grey surface in front of the first boy and is being fed by the boy while a group of goats and a group of people are standing and moving at the back."], "durations": null, "exact_frames_per_prompt": [63], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-3cl74lG6T4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 67, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_135_1_0"}, {"texts": ["A person wearing an orange t-shirt and grey shorts is standing and holding a black snake by its tail."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-g5emSW-SOg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_13_0_0"}, {"texts": ["The person wearing an orange t-shirt and grey shorts is letting it free on the ground while the snake is moving slowly on the surface."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-g5emSW-SOg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 40, "npz_gt_video_start_frame": 40, "npz_gt_video_end_frame": 68, "skip_frames_after_generation": 40, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_13_0_1"}, {"texts": ["A black snake is held by a person with its tail."], "durations": null, "exact_frames_per_prompt": [39], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-g5emSW-SOg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 7, "npz_gt_video_start_frame": 7, "npz_gt_video_end_frame": 46, "skip_frames_after_generation": 7, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_13_1_0"}, {"texts": ["The snake starts moving on the brown surface."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-g5emSW-SOg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 46, "npz_gt_video_start_frame": 46, "npz_gt_video_end_frame": 68, "skip_frames_after_generation": 46, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_13_1_1"}, {"texts": ["A kid wearing a brown vest is eating the cake with a fork and then turns back."], "durations": null, "exact_frames_per_prompt": [65], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0pQACKjlllc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 69, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_142_0_0"}, {"texts": ["A kid wearing pink-white clothes is walking while holding the leash of a puppy."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0Y6xqWo_kM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_144_0_0"}, {"texts": ["The kid drops the leash and walks toward the right."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0Y6xqWo_kM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 44, "npz_gt_video_start_frame": 44, "npz_gt_video_end_frame": 66, "skip_frames_after_generation": 44, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_144_0_1"}, {"texts": ["A brown puppy is walking on the grass while it's leash is held by a kid."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0Y6xqWo_kM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_144_1_0"}, {"texts": ["Then the kid drops the leash and the puppy walks forward."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0Y6xqWo_kM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 45, "npz_gt_video_start_frame": 45, "npz_gt_video_end_frame": 66, "skip_frames_after_generation": 45, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_144_1_1"}, {"texts": ["A person whose only hands are visible is making a knot with the white thread."], "durations": null, "exact_frames_per_prompt": [64], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-54Bs-0kdhA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 16, "npz_gt_video_start_frame": 16, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 16, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_145_0_0"}, {"texts": ["A man wearing a red vest and black pants is standing on the right side of the sheep while a woman wearing a grey hoodie is shearing the sheep with a wool shearing machine."], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1WqYcl4nNCE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 47, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_146_0_0"}, {"texts": ["A woman wearing a gray jacket and black pants is leaning forward and trimming the hairs of the sheep while a man in a red vest is holding it with his legs."], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1WqYcl4nNCE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 47, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_146_1_0"}, {"texts": ["A sheep is lying on the concrete surface and getting trimmed by the woman while a man in a red vest and black pants stands holding the sheep from his leg."], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1WqYcl4nNCE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 47, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_146_2_0"}, {"texts": ["A girl wearing a pink dress is riding on a baby elephant while a man wearing a blue t-shirt is holding and moving with the baby elephant, other people are sitting and moving."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-4jhRyZILBc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_14_0_0"}, {"texts": ["A man on the left side wearing a blue t-shirt is walking on the grey surface and holding the baby elephant on which a girl is riding while a group of people in which some are walking and some are sitting on the backside."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-4jhRyZILBc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_14_1_0"}, {"texts": ["A baby elephant is held by a man and walking on the grey surface while carrying a girl on its back."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-4jhRyZILBc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_14_2_0"}, {"texts": ["A girl on the left side wearing an orange top is sitting and using her mobile phone while another girl in the middle wearing a white t-shirt is sitting and eating something, the third girl on the right side wearing a black top is sitting and pointing at something and two men are standing behind on the brown surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-7784_WqE1E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_158_0_0"}, {"texts": ["A girl in the centre wearing a grey t-shirt is sitting and picking up the food while a woman on the left is using her phone and another woman on the right is moving her hand and two boys are standing on the backside and talking with each other."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-7784_WqE1E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 30, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_158_1_0"}, {"texts": ["The girl takes a bite."], "durations": null, "exact_frames_per_prompt": [50], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-7784_WqE1E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 30, "npz_gt_video_start_frame": 30, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 30, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_158_1_1"}, {"texts": ["A lady wearing blue clothes is sitting on a dark brown horse and driving buffaloes towards the left side on a soil surface.\n while a man is riding another horse."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5ft5ebGnMFU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_159_1_0"}, {"texts": ["A man wearing blue clothes is sitting on a horse and coming from the left side and going toward the right on a soil surface while a woman wearing a blue outfit is riding on a horse from right to left and a black animal runs towards the left  on a soil surface."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5ft5ebGnMFU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 40, "npz_gt_video_start_frame": 40, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 40, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_159_2_0"}, {"texts": ["A dark brown horse carrying a lady on his back is driving the buffaloes toward the left on a soil surface while a group of buffaloes is moving here and there on the soil surface, some people are standing, and a man is riding a brown horse towards the right."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5ft5ebGnMFU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_159_4_0"}, {"texts": ["A man wearing blue shorts is sitting on the couch while a cat putted leg on the bed and moving leg towards the first person"], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5G94o6UdX2w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 32, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_15_0_0"}, {"texts": ["The man is pampering a cat while a cat watching the first person"], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5G94o6UdX2w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 32, "npz_gt_video_start_frame": 32, "npz_gt_video_end_frame": 62, "skip_frames_after_generation": 32, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_15_0_1"}, {"texts": ["A cat is walking under the table while a man wearing blue shorts is sitting on the sofa."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5G94o6UdX2w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 20, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_15_1_0"}, {"texts": ["The cat stands near a man."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5G94o6UdX2w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 20, "npz_gt_video_start_frame": 20, "npz_gt_video_end_frame": 33, "skip_frames_after_generation": 20, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_15_1_1"}, {"texts": ["The cat gets pampered by a man."], "durations": null, "exact_frames_per_prompt": [47], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5G94o6UdX2w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 33, "npz_gt_video_start_frame": 33, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 33, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_15_1_2"}, {"texts": ["A girl wearing a purple t-shirt is standing and clapping"], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-1GsilN0qjU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 17, "npz_gt_video_start_frame": 17, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 17, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_164_2_0"}, {"texts": ["The girl picks something from the table and puts it into her pocket."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-1GsilN0qjU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 45, "npz_gt_video_start_frame": 45, "npz_gt_video_end_frame": 70, "skip_frames_after_generation": 45, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_164_2_1"}, {"texts": ["The girl starts walking."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-1GsilN0qjU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 70, "npz_gt_video_start_frame": 70, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 70, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_164_2_2"}, {"texts": ["A woman wearing black clothes is massaging her cheeks with her finger."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0cONsRVrLbU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_167_0_0"}, {"texts": ["A girl wearing a light blue and black dress is lying upside down on the bed and laughing while rolling to the right side."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0gR5FP7HpZ4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_170_0_0"}, {"texts": ["A person wearing black clothes is riding on a white mole on the rock surface.\n while the girl wearing a yellow top is sitting on a mule and riding on the rock surface."], "durations": null, "exact_frames_per_prompt": [45], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0xTPF7ePX5c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 9, "npz_gt_video_start_frame": 9, "npz_gt_video_end_frame": 54, "skip_frames_after_generation": 9, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_174_0_0"}, {"texts": ["A person wearing yellow clothes is riding on a brown mule after the first person on the rock surface."], "durations": null, "exact_frames_per_prompt": [45], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0xTPF7ePX5c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 9, "npz_gt_video_start_frame": 9, "npz_gt_video_end_frame": 54, "skip_frames_after_generation": 9, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_174_1_0"}, {"texts": ["A white mule is walking on the rock surface while carrying a person on its back while a woman in a yellow jacket is riding mule behind the white mule."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0xTPF7ePX5c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 8, "npz_gt_video_start_frame": 8, "npz_gt_video_end_frame": 54, "skip_frames_after_generation": 8, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_174_2_0"}, {"texts": ["A brown mule is walking on the rock surface while carrying another person on its back while a white mule is walking on the rock surface in front of first mule and a person wearing black outfit is sitting on its back."], "durations": null, "exact_frames_per_prompt": [49], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0xTPF7ePX5c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 5, "npz_gt_video_start_frame": 5, "npz_gt_video_end_frame": 54, "skip_frames_after_generation": 5, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_174_3_0"}, {"texts": ["A man wearing blue pants is holding a newspaper and turning its pages."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-8oPwToqArE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_177_0_0"}, {"texts": ["A woman wearing a waitress dress is standing holding a tray and a bowl filled with food and she is serving the food with the tongs to the woman while speaking while a group of people is standing, sitting, and moving at the back."], "durations": null, "exact_frames_per_prompt": [62], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-vOrVT1CiPQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 66, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_17_0_0"}, {"texts": ["The woman walks aside."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-vOrVT1CiPQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 66, "npz_gt_video_start_frame": 66, "npz_gt_video_end_frame": 76, "skip_frames_after_generation": 66, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_17_0_1"}, {"texts": ["A woman wearing a green dress is sitting, and she is getting served food by the first woman, and then the second woman moves her hand towards the plate as a group of people is standing and sitting on the backside."], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-vOrVT1CiPQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 37, "npz_gt_video_start_frame": 37, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 37, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_17_1_0"}, {"texts": ["A woman wearing a pink dress is standing."], "durations": null, "exact_frames_per_prompt": [51], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-kahgmRD-4g.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 55, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_186_0_0"}, {"texts": ["The woman is moving her hand toward the screen showing weather forecast."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-kahgmRD-4g.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 55, "npz_gt_video_start_frame": 55, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 55, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_186_0_1"}, {"texts": ["A man whose half body is visible is holding a fish."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0N5cgaMCfY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 33, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_188_0_0"}, {"texts": ["The man left the fish into the ice fishing hole."], "durations": null, "exact_frames_per_prompt": [11], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0N5cgaMCfY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 33, "npz_gt_video_start_frame": 33, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 33, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_188_0_1"}, {"texts": ["A man whose only half body is visible is wearing a blue-white jacket and pants is holding a fishing rod and doing ice fishing while the other person sitting opposite to him"], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0N5cgaMCfY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 45, "npz_gt_video_start_frame": 45, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 45, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_188_2_0"}, {"texts": ["A man wearing a white sumo uniform is standing on the right side and holding a child while another man on the left side wearing a sumo uniform is standing while holding a child and the third man on the right side wearing a golden kimono is standing and looking at the child."], "durations": null, "exact_frames_per_prompt": [59], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-C7WEhlgf7w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 18, "npz_gt_video_start_frame": 18, "npz_gt_video_end_frame": 77, "skip_frames_after_generation": 18, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_189_2_0"}, {"texts": ["A man wearing a black cap is standing on the right side and watching the children while two men are holding the babies in their hands."], "durations": null, "exact_frames_per_prompt": [62], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-C7WEhlgf7w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 18, "npz_gt_video_start_frame": 18, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 18, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_189_4_0"}, {"texts": ["A child wearing a purple cloth is crying and held by the first man while a group of people are roaming around the man, and one of them is holding a baby."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-C7WEhlgf7w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_189_5_0"}, {"texts": ["A child wearing a pink t-shirt is crying and held by the second man while another man wearing a white cloth is standing facing backwards and is carrying another child, and other man wearing a black hat is looking at the child and smiling then stands on the right and looks at another child."], "durations": null, "exact_frames_per_prompt": [63], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-C7WEhlgf7w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 17, "npz_gt_video_start_frame": 17, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 17, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_189_6_0"}, {"texts": ["A person whose only hands are visible is pouring the engine oil into a car engine with the help of a green funnel."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/--rC9Wkh6HA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_195_0_0"}, {"texts": ["A man wearing a black t-shirt is standing and playing cello."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-fbscFfkh4M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_196_0_0"}, {"texts": ["A man wearing a shirt is sitting and playing the guitar while another man in a white shirt is drinking beer, a third man in a black shirt is playing guitar, and a fourth man in a gray shirt is playing banjo and then drinking beer."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-fbscFfkh4M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_196_1_0"}, {"texts": ["A man on the right side is sitting, playing banjo while another man wearing black and blue outfit is standing on the backside and playing cello."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-fbscFfkh4M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 34, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_196_3_0"}, {"texts": ["The man lifts a drink bottle, starts drinking while third man wearing brown and white checkered shirt and blue pant, holding a guitar is sitting on the backside and he is playing guitar."], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-fbscFfkh4M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 34, "npz_gt_video_start_frame": 34, "npz_gt_video_end_frame": 67, "skip_frames_after_generation": 34, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_196_3_1"}, {"texts": ["The man puts the bottle on the table while fourth man wearing white outfit, holding a violin in his left hand and a bottle in his right hand is sitting beside third man and he is drinking and moving his head."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-fbscFfkh4M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 67, "npz_gt_video_start_frame": 67, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 67, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_196_3_2"}, {"texts": ["A man wearing a gray sweatshirt and spectacles is sitting on the red seat and eating the food."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-AMpy1HyBfk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_199_0_0"}, {"texts": ["A boy wearing a green t-shirt and grey shorts is moving on the left side of a girl on the red floor. He is holding a doll and a red object and puts his other hand in it.\n while the girl move towards the boy."], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1f0Nce2SgOE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 35, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_200_0_0"}, {"texts": ["A girl wearing a pink dress is on the right side of the first boy and she is standing and holding objects in her hands."], "durations": null, "exact_frames_per_prompt": [11], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1f0Nce2SgOE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 15, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_200_1_0"}, {"texts": ["The girl wearing a pink dress starts moving on the red floor."], "durations": null, "exact_frames_per_prompt": [65], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1f0Nce2SgOE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 15, "npz_gt_video_start_frame": 15, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 15, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_200_1_1"}, {"texts": ["A woman wearing an apron is cooking food in a frying pan using a spatula."], "durations": null, "exact_frames_per_prompt": [45], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-DhAghDNh60.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 49, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_206_0_0"}, {"texts": ["The woman wearing an apron starts speaking."], "durations": null, "exact_frames_per_prompt": [32], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-DhAghDNh60.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 49, "npz_gt_video_start_frame": 49, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 49, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_206_0_1"}, {"texts": ["A man wearing a blue jeans is trimming the hoof of the sheep while another man is trimming the hair of the other sheep."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5o48YgRlkQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_20_0_0"}, {"texts": ["A man wearing a blue t-shirt is shearing the sheep and same is done by the second man wearing blue jeans"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5o48YgRlkQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_20_1_0"}, {"texts": ["A sheep on the left side is getting its hooves trimmed by the man in blue jeans while a man wearing a blue t-shirt on the right side is trimming the hooves of a sheep."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5o48YgRlkQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_20_2_0"}, {"texts": ["A sheep on the right side is getting sheared by the man in blue t-shirt as another sheep on the left side is getting its hooves cleaned by the man in blue jeans."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5o48YgRlkQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_20_3_0"}, {"texts": ["A man wearing an olive t-shirt is standing and putting chips in his mouth which are snatched by a bird."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1G2zxrAC7Q8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_210_0_0"}, {"texts": ["A person wearing a light grey t-shirt is standing and unscrewing the air filter."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1C4Q1Xjyeig.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 56, "npz_gt_video_start_frame": 56, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 56, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_213_1_0"}, {"texts": ["A man is bending towards the counter-top and eating food from the plate through his mouth directly.\n while the woman wearing black t-shirt is drinking milk from the glass and chewing the food"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2WtmYtTUr_c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_214_0_0"}, {"texts": ["A woman wearing a black t-shirt is bending down and drinking white liquid from the glass."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2WtmYtTUr_c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 29, "npz_gt_video_start_frame": 29, "npz_gt_video_end_frame": 55, "skip_frames_after_generation": 29, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_214_1_0"}, {"texts": ["The woman is putting the glass back on the counter-top while a man on the right is bent down and eating something from the plate."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2WtmYtTUr_c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 55, "npz_gt_video_start_frame": 55, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 55, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_214_1_1"}, {"texts": ["A man on the right side is bent and eating from the white plate on the black table.\n while the other woman is also bent drinking and eating"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2WtmYtTUr_c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_215_0_0"}, {"texts": ["A kid is sitting near the person and eating watermelon."], "durations": null, "exact_frames_per_prompt": [50], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-xA_1WuydMU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 30, "npz_gt_video_start_frame": 30, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 30, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_217_0_0"}, {"texts": ["A woman wearing blue clothes is holding the baby on her lap and talking and smiling while looking at the baby."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-Ovwq0kVUx4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_219_0_0"}, {"texts": ["A baby wearing red clothes is sitting on the lap of the woman and watching the person tearing a piece of paper."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-Ovwq0kVUx4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_219_1_0"}, {"texts": ["A man on the left, wearing a light purple shirt and jeans, is leaning forward and cutting the hoof of the sheep.\n while another man on the right wearing blue and black outfit is also leaning forward and cutting the hoof of the sheep and the sheep is lying on the ground and getting its hoof cut by the man."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5o48YgRlkQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_21_0_0"}, {"texts": ["A man wearing a blue t-shirt and black pants, is leaning forward and trimming the hair of another sheep with a trimming machine while another man wearing a lilac shirt is leaning forward and is cutting something on the sheep's foot."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5o48YgRlkQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_21_1_0"}, {"texts": ["A sheep on the left side is sitting on the brown surface and getting its hoof cut by the first man while another sheep on the right side is also being shaved by the man wearing a blue t-shirt."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5o48YgRlkQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_21_2_0"}, {"texts": ["A sheep on the right side is sitting on the brown surface and getting trimmed by the second man while the other man with blue jeans holding the sheep's leg"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5o48YgRlkQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_21_3_0"}, {"texts": ["A person wearing a blue t-shirt is sitting inside the car which is moving on the grey road surface and reading a newspaper.\n"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0NZewzomYbA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_222_0_0"}, {"texts": ["A man wearing red and blue clothes is holding the sheep between his legs and shearing the sheep."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3qW7LQxH4fo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_223_0_0"}, {"texts": ["A sheep is being held by the man and getting sheared."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3qW7LQxH4fo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_223_1_0"}, {"texts": ["A man wearing a blue and red jumpsuit is shaving the wool off the sheep.\n while a group of sheep are standing behind the wooden fence."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3qW7LQxH4fo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_224_0_0"}, {"texts": ["A sheep lying on the brown surface is being shaved by the man while a person whose hands are visible is holding a phone in the direction of the wooden stage and other sheep are moving behind the wooden structure."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3qW7LQxH4fo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_224_1_0"}, {"texts": ["A person whose hand is visible is picking up an electric kettle."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0r6NmrdKCU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 17, "npz_gt_video_start_frame": 17, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 17, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_225_0_0"}, {"texts": ["The person is putting water into the disposable glass from the kettle."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0r6NmrdKCU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 44, "npz_gt_video_start_frame": 44, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 44, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_225_0_1"}, {"texts": ["A brown-white dog attached to a leash held by a person is moving on one side of a road"], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-dMaV5Il324.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 29, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_226_0_0"}, {"texts": ["The dog starts running towards the other side of the road."], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-dMaV5Il324.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 29, "npz_gt_video_start_frame": 29, "npz_gt_video_end_frame": 62, "skip_frames_after_generation": 29, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_226_0_1"}, {"texts": ["A person wearing white clothes is playing golf on the green surface while another person wearing white pants is also playing golf."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/6Cwq13Oaays.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_229_0_0"}, {"texts": ["A person wearing white trousers is standing and playing golf on the green surface."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/6Cwq13Oaays.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 39, "npz_gt_video_start_frame": 39, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 39, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_229_1_0"}, {"texts": ["A man wearing a yellow t-shirt is standing in one knee position and holding a fishing rod with a girl."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-2eq0citAJg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_233_0_0"}, {"texts": ["A girl wearing a brown t-shirt is sitting on a red-blue cloth and holding a fishing rod with the man wearing yellow t-shirt while a woman wearing a green skirt comes running from the right and grabs a stick from the man then moves back, and another man wearing t-shirt is holding a fishing net and runs towards the water."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-2eq0citAJg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_233_2_0"}, {"texts": ["A girl wearing a green dress is running on the beach and taking a fishing rod from the second man then goes to the left side while a boy and a girl are holding a fishing rod and watching the another girl."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-2eq0citAJg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 44, "npz_gt_video_start_frame": 44, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 44, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_233_3_0"}, {"texts": ["A person whom hands are visible is mixing the vegetables in a glass bowl with a spoon."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1bihmEt95PI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_235_0_0"}, {"texts": ["A baby whose bare body is sitting on the white baby feeding chair and eating food with his hand."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-AEUGxV9mpg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_241_0_0"}, {"texts": ["A girl wearing a pink cap is standing on the right and moving her hand towards a group of pigeons.\n"], "durations": null, "exact_frames_per_prompt": [69], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/264oaD4orK0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 11, "npz_gt_video_start_frame": 11, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 11, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_243_0_0"}, {"texts": ["A woman wearing a black sweatshirt is standing and tossing food in a frying pan."], "durations": null, "exact_frames_per_prompt": [62], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-yv8c2CDbR8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 18, "npz_gt_video_start_frame": 18, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 18, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_244_0_0"}, {"texts": ["A man wearing a black jacket is holding a bundle of paper money in his hand and counting it."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-02UO1KSdZ0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 28, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_248_0_0"}, {"texts": ["The man stops and speaks while doing the hand movement."], "durations": null, "exact_frames_per_prompt": [39], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-02UO1KSdZ0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 28, "npz_gt_video_start_frame": 28, "npz_gt_video_end_frame": 67, "skip_frames_after_generation": 28, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_248_0_1"}, {"texts": ["The man moves his hand in the right direction to take another bundle of paper money."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-02UO1KSdZ0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 67, "npz_gt_video_start_frame": 67, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 67, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_248_0_2"}, {"texts": ["A person is holding a bowl of rice. The person pours an egg on the rice."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1koxtPz76MU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_253_0_0"}, {"texts": ["The person starts mixing the egg with the red chopsticks."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1koxtPz76MU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 40, "npz_gt_video_start_frame": 40, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 40, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_253_0_1"}, {"texts": ["A woman wearing black and blue clothes is holding a piece of cloth."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-QRY9rDrJf0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 18, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_254_0_0"}, {"texts": ["The woman folds the clothes."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-QRY9rDrJf0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 18, "npz_gt_video_start_frame": 18, "npz_gt_video_end_frame": 59, "skip_frames_after_generation": 18, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_254_0_1"}, {"texts": ["The woman puts the clothes on the left side."], "durations": null, "exact_frames_per_prompt": [5], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-QRY9rDrJf0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 59, "npz_gt_video_start_frame": 59, "npz_gt_video_end_frame": 64, "skip_frames_after_generation": 59, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_254_0_2"}, {"texts": ["A child wearing a grey t-shirt is held by a woman while a group of people are are moving here and there."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2WowmnRTyqY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 26, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_259_0_0"}, {"texts": ["The child gets put on the left by the woman and starts crawling on the floor."], "durations": null, "exact_frames_per_prompt": [34], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2WowmnRTyqY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 26, "npz_gt_video_start_frame": 26, "npz_gt_video_end_frame": 60, "skip_frames_after_generation": 26, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_259_0_1"}, {"texts": ["A person wearing a white outfit is standing and sprinkling salt on the meat."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1CjON-2Oqxc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 14, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_264_0_0"}, {"texts": ["The person pours the substance in the bowl with the help of a glass cup."], "durations": null, "exact_frames_per_prompt": [44], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1CjON-2Oqxc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 14, "npz_gt_video_start_frame": 14, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 14, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_264_0_1"}, {"texts": ["Then the person mixes them with a black spoon."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1CjON-2Oqxc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 58, "npz_gt_video_start_frame": 58, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 58, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_264_0_2"}, {"texts": ["A grey-white husky is sitting in the front and getting blow dried given by a person."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-9BGMU4WYMg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_267_0_0"}, {"texts": ["A man wearing white clothes is standing in a kitchen and holding a frying pan in his hand."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5RvkhL92b4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 20, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_269_0_0"}, {"texts": ["The man at first scatters the food kept on the plate with a wooden spatula."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5RvkhL92b4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 20, "npz_gt_video_start_frame": 20, "npz_gt_video_end_frame": 60, "skip_frames_after_generation": 20, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_269_0_1"}, {"texts": ["The man looks in the left direction while speaking."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5RvkhL92b4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 60, "npz_gt_video_start_frame": 60, "npz_gt_video_end_frame": 70, "skip_frames_after_generation": 60, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_269_0_2"}, {"texts": ["The man again starts scattering the food."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5RvkhL92b4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 70, "npz_gt_video_start_frame": 70, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 70, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_269_0_3"}, {"texts": ["A girl whose half face is visible is filling her eyebrow with an eyebrow pencil."], "durations": null, "exact_frames_per_prompt": [12], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-BlV342BAM4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 16, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_270_0_0"}, {"texts": ["The girl whose half face is visible is brushing her eyebrow."], "durations": null, "exact_frames_per_prompt": [64], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-BlV342BAM4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 16, "npz_gt_video_start_frame": 16, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 16, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_270_0_1"}, {"texts": ["A person whose hands are visible is folding a white paper."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-35wittelPs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_274_0_0"}, {"texts": ["A man wearing a white shirt is tying a black and white neck tie around his neck."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3I5Nf4z4XrU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_279_0_0"}, {"texts": ["A kid wearing a red t-shirt is sitting on the tile floor while the boy in grey t-shirt sits back side of him."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0fCDlKYkRxc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 19, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_282_0_0"}, {"texts": ["The kid is eating something from a plastic cup with the help of a spoon along with grey t-shirt kid."], "durations": null, "exact_frames_per_prompt": [61], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0fCDlKYkRxc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 19, "npz_gt_video_start_frame": 19, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 19, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_282_0_1"}, {"texts": ["A kid behind the first kid is also eating something from the plastic cup with the help of a spoon."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0fCDlKYkRxc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_282_1_0"}, {"texts": ["A woman wearing a black top is sitting, holding and knotting a tie on the table.\n"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0byZyStAYQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_283_0_0"}, {"texts": ["A man wearing a white t-shirt is holding a brown-yellow snake wrapped in his hand and showing it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/02L6JyleSLE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_284_0_0"}, {"texts": ["A brown-yellow snake is wrapped in the hand of the man."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/02L6JyleSLE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 23, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_284_1_0"}, {"texts": ["The snake is crawling towards the bottom.  while the man is moving his hands."], "durations": null, "exact_frames_per_prompt": [57], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/02L6JyleSLE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 23, "npz_gt_video_start_frame": 23, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 23, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_284_1_1"}, {"texts": ["A man wearing a white t-shirt is holding a yellow-orange snake in his hands."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/02L6JyleSLE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_285_0_0"}, {"texts": ["A yellow-orange snake is held by the man, and the snake is moving in his hands."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/02L6JyleSLE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_285_1_0"}, {"texts": ["A woman wearing a purple pink top is sitting in the back and milking a statue cow then a man wearing a white t-shirt is sitting and milking a statue cow and another man man is standing on the the right side and watching the the first man and the woman."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0-s1eu4sF4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_28_0_0"}, {"texts": ["A man wearing a white t-shirt is sitting and watching the woman while another man whose head is visible is watching the man."], "durations": null, "exact_frames_per_prompt": [49], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0-s1eu4sF4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 53, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_28_1_0"}, {"texts": ["The man is milking the statue cow and the woman stands up and puts her hand on the man's shoulder and another man moves aside."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0-s1eu4sF4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 53, "npz_gt_video_start_frame": 53, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 53, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_28_1_1"}, {"texts": ["A man wearing a black t-shirt is standing in the front and watching the other two people."], "durations": null, "exact_frames_per_prompt": [66], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0-s1eu4sF4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 70, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_28_2_0"}, {"texts": ["A person wearing orange clothes is holding a brown fish with a fish landing net."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-2yTc7WxGMM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_290_0_0"}, {"texts": ["A brown fish is moving in the fish landing net while a person wearing an orange outfit is holding the fish landing net."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-2yTc7WxGMM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_290_1_0"}, {"texts": ["A brown fish is moving in the fish landing net."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-2yTc7WxGMM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_291_1_0"}, {"texts": ["A man wearing a white-red shirt is standing behind a counter and doing flair."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1-qCqfG-iMg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_293_0_0"}, {"texts": ["A woman wearing a multi-color t-shirt is sitting in the back and milking a statue cow while the other men are seeing towards her."], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0-s1eu4sF4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 47, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_29_0_0"}, {"texts": ["A man wearing a white t-shirt is sitting in the middle while a woman wearing a printed top is milking a statue cow, another man wearing a black T-shirt is standing and leaning towards the woman and the man."], "durations": null, "exact_frames_per_prompt": [50], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0-s1eu4sF4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 54, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_29_1_0"}, {"texts": ["The man wearing a white t-shirt starts milking the statue cow while a woman wearing printed top and a man wearing black t-shir move backward."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0-s1eu4sF4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 54, "npz_gt_video_start_frame": 54, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 54, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_29_1_1"}, {"texts": ["A man wearing a black t-shirt is standing and watching the other two people."], "durations": null, "exact_frames_per_prompt": [67], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0-s1eu4sF4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 71, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_29_2_0"}, {"texts": ["A man wearing a t-shirt is standing while holding bottles in his left hand and then moves his right hand while holding a glass."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-M3_7e_exd8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 18, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_32_0_0"}, {"texts": ["The man puts the glass."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-M3_7e_exd8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 18, "npz_gt_video_start_frame": 18, "npz_gt_video_end_frame": 29, "skip_frames_after_generation": 18, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_32_0_1"}, {"texts": ["The man is pouring a drink into the glass with the bottles."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-M3_7e_exd8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 29, "npz_gt_video_start_frame": 29, "npz_gt_video_end_frame": 42, "skip_frames_after_generation": 29, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_32_0_2"}, {"texts": ["The man puts the bottles on the table."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-M3_7e_exd8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 42, "npz_gt_video_start_frame": 42, "npz_gt_video_end_frame": 52, "skip_frames_after_generation": 42, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_32_0_3"}, {"texts": ["The man throws up the glass from his right hand to left hand."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-M3_7e_exd8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 52, "npz_gt_video_start_frame": 52, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 52, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_32_0_4"}, {"texts": ["A baby is lying on the floor near a couch and crying."], "durations": null, "exact_frames_per_prompt": [68], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-1Te0BM0oU8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 72, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_38_0_0"}, {"texts": ["A lady wearing a black and white cloth is standing and trying to open a bottle with a piece of cloth then the man in a black outfit is holding the bottle."], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-4szNHl4P0c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 47, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_39_0_0"}, {"texts": ["The lady is giving the bottle to a man."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-4szNHl4P0c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 47, "npz_gt_video_start_frame": 47, "npz_gt_video_end_frame": 57, "skip_frames_after_generation": 47, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_39_0_1"}, {"texts": ["A man wearing black clothes is standing and taking the bottle from the lady while a woman wearing grey outfits standing on the right side holding the towel and talking something"], "durations": null, "exact_frames_per_prompt": [58], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-4szNHl4P0c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 22, "npz_gt_video_start_frame": 22, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 22, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_39_1_0"}, {"texts": ["A man wearing black-white clothes is speaking and presenting the monsoon forecast."], "durations": null, "exact_frames_per_prompt": [44], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0KRZpDL6rWQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 48, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_42_0_0"}, {"texts": ["A person whose only hands are visible is tearing papers in front of a baby and making him laugh."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2Vzh7XO912Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_48_0_0"}, {"texts": ["A baby wearing a diaper is sitting on the rug, holding a piece of paper and playing with it, and laughing when the person tears the papers."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2Vzh7XO912Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_48_1_0"}, {"texts": ["A man wearing a black t-shirt and hat is sitting in front and drinking from a green-grey jar."], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-A7PrCTRvOY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 41, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_51_0_0"}, {"texts": ["The man stops and cleans his mouth with his hand."], "durations": null, "exact_frames_per_prompt": [39], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-A7PrCTRvOY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 41, "npz_gt_video_start_frame": 41, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 41, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_51_0_1"}, {"texts": ["A man wearing a t-shirt is sitting and tightening a bolt of the vehicle.\n"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2-M5TagOHMw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_52_0_0"}, {"texts": ["A person wearing red upper and black lower is standing and holding a food and rolling it."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-3LxDH4ZusU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_53_0_0"}, {"texts": ["The person is dropping it in a white powder."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-3LxDH4ZusU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 45, "npz_gt_video_start_frame": 45, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 45, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_53_0_1"}, {"texts": ["A man wearing a printed black t-shirt standing on a brown surface is speaking on a mic while moving his left hand."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5U0O1P6qgDI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_56_0_0"}, {"texts": ["A person wearing blue jeans is sitting on the left side of the brown surface, holding a scissor and cutting the bandage and an animal's leg is visible, which is bandaged."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3nTMc2nK_W8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 23, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_57_0_0"}, {"texts": ["The person is pasting it on the animal's leg while another person whose hand is visible is holding the animal's leg."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3nTMc2nK_W8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 23, "npz_gt_video_start_frame": 23, "npz_gt_video_end_frame": 46, "skip_frames_after_generation": 23, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_57_0_1"}, {"texts": ["An animal whose leg is only visible is held by the second person and pasting a bandage while a person on the left side is sitting and cutting the bandage with a scissor."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3nTMc2nK_W8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_57_2_0"}, {"texts": ["A person wearing a blue t-shirt is riding on a camel and looking here and there while another person wearing a white t-shirt is also riding on a camel, and a group of people are standing and walking at the back."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5fqwdtpSOY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_59_0_0"}, {"texts": ["A person wearing white clothes is riding a camel in the front while another person wearing a blue t-shirt is also riding the camel, and a group of people are standing and walking at the back."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5fqwdtpSOY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_59_1_0"}, {"texts": ["A camel is walking on the gray surface and carrying people on its back."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5fqwdtpSOY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_59_2_0"}, {"texts": ["A man wearing a green shirt is standing and holding a baby and man's finger is locked by the baby."], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1168w8ZwiVk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 49, "npz_gt_video_start_frame": 49, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 49, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_60_1_0"}, {"texts": ["A white goat is standing on the dry grass surface and touched by two people while a kid wearing a pink dress is moving and standing on the dry grass."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1168w8ZwiVk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 39, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_60_4_0"}, {"texts": ["The goat's back is brushed by a kid."], "durations": null, "exact_frames_per_prompt": [6], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1168w8ZwiVk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 39, "npz_gt_video_start_frame": 39, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 39, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_60_4_1"}, {"texts": ["A man whose hands are visible lifts the lid of the sandwich maker."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0dUkWf8gBkU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 27, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_61_0_0"}, {"texts": ["The man uses a spatula to remove the burger from the sandwich maker."], "durations": null, "exact_frames_per_prompt": [53], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0dUkWf8gBkU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 27, "npz_gt_video_start_frame": 27, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 27, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_61_0_1"}, {"texts": ["A person whose hands are visible is opening the upper section of a burger maker."], "durations": null, "exact_frames_per_prompt": [11], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0dUkWf8gBkU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 15, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_62_0_0"}, {"texts": ["The person picks up a burger using his hands and a spatula."], "durations": null, "exact_frames_per_prompt": [51], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0dUkWf8gBkU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 15, "npz_gt_video_start_frame": 15, "npz_gt_video_end_frame": 66, "skip_frames_after_generation": 15, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_62_0_1"}, {"texts": ["The person drags the burger machine aside and starts placing the burger on the surface."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0dUkWf8gBkU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 66, "npz_gt_video_start_frame": 66, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 66, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_62_0_2"}, {"texts": ["A man wearing a graphic black t-shirt is peeling an apple on the apple peeler corer machine and making faces."], "durations": null, "exact_frames_per_prompt": [66], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-aLdPxMzGhg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 70, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_64_0_0"}, {"texts": ["A woman wearing a blue checked shirt is standing and writing on a white board with a marker."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-HutuMqTAPw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_65_0_0"}, {"texts": ["The woman turns and starts speaking."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-HutuMqTAPw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 44, "npz_gt_video_start_frame": 44, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 44, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_65_0_1"}, {"texts": ["A woman wearing a blue patterned shirt is standing and writing on a white board  with a marker."], "durations": null, "exact_frames_per_prompt": [11], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-HutuMqTAPw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 15, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_66_0_0"}, {"texts": ["The woman turns and then starts speaking."], "durations": null, "exact_frames_per_prompt": [65], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-HutuMqTAPw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 15, "npz_gt_video_start_frame": 15, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 15, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_66_0_1"}, {"texts": ["A man wearing a red t-shirt, is using a funny face filter with huge eyeballs, and  speaking"], "durations": null, "exact_frames_per_prompt": [34], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-Cfmw6L4cI0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 38, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_67_0_0"}, {"texts": ["The man wearing a red t-shirt starts eating a chip very fast in a funny way."], "durations": null, "exact_frames_per_prompt": [42], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-Cfmw6L4cI0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 38, "npz_gt_video_start_frame": 38, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 38, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_67_0_1"}, {"texts": ["An old man wearing a dark blue t-shirt is sitting and looking at the kids."], "durations": null, "exact_frames_per_prompt": [69], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2mFclrl0wo8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 73, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_78_0_0"}, {"texts": ["A boy sitting besides person one is eating cake from the white plate while another kid on the right side is also  eating cake from the white plate.."], "durations": null, "exact_frames_per_prompt": [69], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2mFclrl0wo8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 73, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_78_1_0"}, {"texts": ["A girl sitting besides person two is also eating the cake from another white plate.\n while an old man on the left side in a blue t-shirt is sitting."], "durations": null, "exact_frames_per_prompt": [56], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2mFclrl0wo8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 17, "npz_gt_video_start_frame": 17, "npz_gt_video_end_frame": 73, "skip_frames_after_generation": 17, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_78_2_0"}, {"texts": ["A man wearing a blue t-shirt is sitting on the left while a boy and a girl is sitting on the chair and eating food."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2mFclrl0wo8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 29, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_79_0_0"}, {"texts": ["A boy wearing a red-black t-shirt is sitting on a chair and eating food while an old man is looking at him and a girl is sitting on the left is also eating food."], "durations": null, "exact_frames_per_prompt": [69], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2mFclrl0wo8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 73, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_79_1_0"}, {"texts": ["A girl wearing a white t-shirt is sitting on a chair and eating her food.\n and a boy wearing blue t-shirt is sitting on her right is also eating food while the old man wearing blue t-shirt is watching them"], "durations": null, "exact_frames_per_prompt": [62], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2mFclrl0wo8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 11, "npz_gt_video_start_frame": 11, "npz_gt_video_end_frame": 73, "skip_frames_after_generation": 11, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_79_2_0"}, {"texts": ["A boy is sitting beside old man, is eating cake from the white plate along with the girl."], "durations": null, "exact_frames_per_prompt": [69], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2mFclrl0wo8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 73, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_80_1_0"}, {"texts": ["A girl is sitting beside the boy, is also eating cake from the white plate while an old man wearing a grey t-shirt is sitting on the left side."], "durations": null, "exact_frames_per_prompt": [60], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2mFclrl0wo8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 13, "npz_gt_video_start_frame": 13, "npz_gt_video_end_frame": 73, "skip_frames_after_generation": 13, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_80_2_0"}, {"texts": ["A boy wearing a red-blue-white t-shirt is sitting on a wooden chair and eating cake with a fork from a white plate.\n while a girl wearing a white t-shirt is sitting on a wooden chair and eating cake with a fork from a white plate, and a man wearing a blue t-shirt is sitting on the left side."], "durations": null, "exact_frames_per_prompt": [69], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2mFclrl0wo8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 73, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_81_0_0"}, {"texts": ["A girl wearing a white printed t-shirt is sitting on a wooden chair and eating cake from a white plate with a fork while the boy beside wearing black, red and white t-shirt eating the food"], "durations": null, "exact_frames_per_prompt": [62], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2mFclrl0wo8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 11, "npz_gt_video_start_frame": 11, "npz_gt_video_end_frame": 73, "skip_frames_after_generation": 11, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_81_1_0"}, {"texts": ["A man wearing a blue t-shirt is sitting on the left side while two kids on the right are sitting and eating cake."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2mFclrl0wo8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 28, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_81_2_0"}, {"texts": ["A boy wearing a green t-shirt is holding a white glass with some brown liquid in it while the boy in black t-shirt drink the liquid and turn back."], "durations": null, "exact_frames_per_prompt": [50], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/15FiZ48tTUU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 54, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_85_0_0"}, {"texts": ["The boy starts drinking the liquid from the glass."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/15FiZ48tTUU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 54, "npz_gt_video_start_frame": 54, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 54, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_85_0_1"}, {"texts": ["A boy wearing a navy blue t-shirt is moving on a grey surface behind the first boy while a boy wearing grey t-shirt is sitting on the table is holding a white glass and another boy is standing on the left."], "durations": null, "exact_frames_per_prompt": [72], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/15FiZ48tTUU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 8, "npz_gt_video_start_frame": 8, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 8, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_85_1_0"}, {"texts": ["A person is straightening the white wrapping paper.\n"], "durations": null, "exact_frames_per_prompt": [50], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0WZKTu0xNk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 30, "npz_gt_video_start_frame": 30, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 30, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_88_0_0"}, {"texts": ["A person wearing a black t-shirt is moving."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-hFa8jTSaJw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_99_1_0"}, {"texts": ["The person wearing a black t-shirt is giving the poly bag to the first person."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-hFa8jTSaJw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 45, "npz_gt_video_start_frame": 45, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 45, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_dense_val_99_1_1"}, {"texts": ["A person on the right side is standing on a white surface and eating something with his hand.\n and the man wearing white t-shirt facing the first man along with the man wearing black t-shirt who is dancing"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/13-k56ie2wQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1002_0_0"}, {"texts": ["A person wearing a white t-shirt is chewing something, and standing on a white surface and two are also chewing something, and one of them is jumping while chewing it on a white surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/13-k56ie2wQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1002_1_0"}, {"texts": ["A person wearing a black t-shirt is moving his hands, and standing on a white surface while a man wearing a white t-shirt is standing beside the person and chewing something, another man is standing on the right and eating something, and another person is standing at the back holding the door."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/13-k56ie2wQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1002_2_0"}, {"texts": ["A girl wearing a grey t-shirt is feeding milk to the goats with a baby feeding bottle while a group of people are walking in different directions on the grey road and a group of goats are standing on the soil surface and a wooden platform."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0-9PkPLBeB4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1003_0_0"}, {"texts": ["A black goat on the right is drinking milk with a baby feeding bottle while some other goats are also standing near the fence and some people are walking in the back."], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0-9PkPLBeB4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 49, "npz_gt_video_start_frame": 49, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 49, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1003_2_0"}, {"texts": ["A woman whose hand is visible is putting a tea maker on the blue cup."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/01WVMe1Vrsw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 38, "npz_gt_video_start_frame": 38, "npz_gt_video_end_frame": 63, "skip_frames_after_generation": 38, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1004_0_0"}, {"texts": ["The woman is pointing and touching her finger on the jar."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/01WVMe1Vrsw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 63, "npz_gt_video_start_frame": 63, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 63, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1004_0_1"}, {"texts": ["A girl wearing a black coat is standing, holding a peeled pineapple."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-rvS_b-OUpo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 26, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1005_0_0"}, {"texts": ["The girl is cutting the pineapple with a knife."], "durations": null, "exact_frames_per_prompt": [54], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-rvS_b-OUpo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 26, "npz_gt_video_start_frame": 26, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 26, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1005_0_1"}, {"texts": ["A baby wearing a white dress with a blue and white teddy picture on it and lying on the white-brown clothes."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0XKR4zE_cdQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1010_0_0"}, {"texts": ["A girl wearing a black dress is standing in front and speaking."], "durations": null, "exact_frames_per_prompt": [64], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1CbmYck1MO4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 17, "npz_gt_video_start_frame": 17, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 17, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1011_0_0"}, {"texts": ["A boy wearing a blue school uniform is sitting and reading a newspaper."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5FxmDqFj-oA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1017_0_0"}, {"texts": ["A man wearing a black t-shirt is standing."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-Jr4hagX4fY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 23, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1022_0_0"}, {"texts": ["The man wearing a black t-shirt is writing on the white board with a black pen."], "durations": null, "exact_frames_per_prompt": [57], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-Jr4hagX4fY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 23, "npz_gt_video_start_frame": 23, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 23, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1022_0_1"}, {"texts": ["A girl wearing a pink top is sitting on a chair."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/16CDSpDlU1c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 19, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1023_0_0"}, {"texts": ["The girl is eating a donut from a white black plate."], "durations": null, "exact_frames_per_prompt": [60], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/16CDSpDlU1c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 19, "npz_gt_video_start_frame": 19, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 19, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1023_0_1"}, {"texts": ["A person wearing black t-shirt and pants is leaning forward holding a lug wrench."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4QE6LGVB30A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1025_0_0"}, {"texts": ["The person attached the wrench into a car stepney nut."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4QE6LGVB30A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 50, "npz_gt_video_start_frame": 50, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 50, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1025_0_1"}, {"texts": ["A girl wearing a blue-white t-shirt and blue shorts is standing on the left side while holding a hand mixer machine in her right hand and mixing the yellow paste with a hand mixer machine in the bowl."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2aEDSBdE-c0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1026_0_0"}, {"texts": ["A person in greyish-white clothing is preparing the sushi roll."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-qNOmqblmyQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1033_0_0"}, {"texts": ["A baby wearing a white t-shirt is standing in a baby bed and watching the first person and laughing."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-tuKSaADF3c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1036_0_0"}, {"texts": ["A person whose hands are visible is tearing the paper and a baby is laughing while looking here and there."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-tuKSaADF3c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1036_1_0"}, {"texts": ["A man on the left side wearing a green jacket is sitting on his knee holding a fish accompanied by the man wearing red jacket"], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0lxip_X2LmY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1037_0_0"}, {"texts": ["The man is holding a drone in his hands and speaking and the man wearing red jacket is holding the fish"], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0lxip_X2LmY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 44, "npz_gt_video_start_frame": 44, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 44, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1037_0_1"}, {"texts": ["A gray fish is held by the first man while the man in red hoodie watches the fish."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0lxip_X2LmY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 21, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1037_2_0"}, {"texts": ["The fish lure wire is cut in her mouth."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0lxip_X2LmY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 21, "npz_gt_video_start_frame": 21, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 21, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1037_2_1"}, {"texts": ["The fish is lifted up by the second man while the other man picks up the drone."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0lxip_X2LmY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 45, "npz_gt_video_start_frame": 45, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 45, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1037_2_2"}, {"texts": ["A man wearing a white shirt and black pants is playing golf.\n"], "durations": null, "exact_frames_per_prompt": [39], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-mmRPduUwZg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 43, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1040_0_0"}, {"texts": ["A man wearing a black suit is standing in front of the digital screen."], "durations": null, "exact_frames_per_prompt": [63], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-do4D3M20aM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 5, "npz_gt_video_start_frame": 5, "npz_gt_video_end_frame": 68, "skip_frames_after_generation": 5, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1041_0_0"}, {"texts": ["The man wearing a black suit is turning towards the screen, speaking and moving his hand."], "durations": null, "exact_frames_per_prompt": [12], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-do4D3M20aM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 68, "npz_gt_video_start_frame": 68, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 68, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1041_0_1"}, {"texts": ["A woman wearing a top is standing, pouring the egg into the pan, and then starts mixing it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4p3zFOelr4Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1045_0_0"}, {"texts": ["A woman wearing black clothes is cleaning a steel pan with a tissue wipe."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-BptOURMao8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 54, "npz_gt_video_start_frame": 54, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 54, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1049_1_ms_0"}, {"texts": ["A woman on the extreme right is standing with the first woman."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-BptOURMao8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 55, "npz_gt_video_start_frame": 55, "npz_gt_video_end_frame": 75, "skip_frames_after_generation": 55, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1049_2_ms_0"}, {"texts": ["The woman is showing a victory gesture."], "durations": null, "exact_frames_per_prompt": [5], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-BptOURMao8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 75, "npz_gt_video_start_frame": 75, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 75, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1049_2_ms_1"}, {"texts": ["A man wearing blue red clothes is standing and holding a cycle rim."], "durations": null, "exact_frames_per_prompt": [38], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2OSUhsn1klQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 42, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_104_0_0"}, {"texts": ["And then showing a cycle tube wall."], "durations": null, "exact_frames_per_prompt": [38], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2OSUhsn1klQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 42, "npz_gt_video_start_frame": 42, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 42, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_104_0_1"}, {"texts": ["A woman wearing a blue top and dark blue jeans is sitting and checking the dog from ears to mouth."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1stnFgiop8U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1052_0_0"}, {"texts": ["A black dog is sitting and getting his face, ears and mouth checked by the woman."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1stnFgiop8U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1052_1_0"}, {"texts": ["A woman wearing a blue top is sitting on the floor and checking a dog."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1stnFgiop8U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1053_0_0"}, {"texts": ["A black dog is sitting and getting checked by a woman."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1stnFgiop8U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1053_1_0"}, {"texts": ["A white and black horse is standing on a gray surface while the woman in blue jeans tries to tie some cloth on thee leg of the horse"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1g_AV6ocuAY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1055_0_0"}, {"texts": ["A girl wearing a black top is sitting on a gray floor."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1g_AV6ocuAY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 13, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1055_2_0"}, {"texts": ["The girl wearing a black top wrapping a white cloth in a horse leg."], "durations": null, "exact_frames_per_prompt": [67], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1g_AV6ocuAY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 13, "npz_gt_video_start_frame": 13, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 13, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1055_2_1"}, {"texts": ["A woman wearing a black t-shirt is sitting on the brown surface a white-black horse is standing on the brown surface."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1g_AV6ocuAY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 13, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1056_0_0"}, {"texts": ["The woman is rolling a white cloth on the leg of the horse."], "durations": null, "exact_frames_per_prompt": [67], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1g_AV6ocuAY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 13, "npz_gt_video_start_frame": 13, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 13, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1056_0_1"}, {"texts": ["A black-white horse is standing, and the leash of the horse is tied on the white railing while a woman wearing a black top is sitting and is wrapping a white object around the horse's leg."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1g_AV6ocuAY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1056_1_0"}, {"texts": ["A man wearing white clothes is standing and holding a pineapple."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1jgnab5xbhI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 39, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_105_0_0"}, {"texts": ["The man is cutting a pineapple with a knife."], "durations": null, "exact_frames_per_prompt": [42], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1jgnab5xbhI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 39, "npz_gt_video_start_frame": 39, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 39, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_105_0_1"}, {"texts": ["A person whom hands are visible wearing a black glove in the right hand while holding a knife in the right hand and holding a potato in the left hand, is peeling the potato with the knife."], "durations": null, "exact_frames_per_prompt": [54], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5Tq5X4A9ahM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1062_0_0"}, {"texts": ["The person whom hands are visible puts knife on the table."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5Tq5X4A9ahM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 58, "npz_gt_video_start_frame": 58, "npz_gt_video_end_frame": 68, "skip_frames_after_generation": 58, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1062_0_1"}, {"texts": ["The person whom hands are visible puts aside the potato peel."], "durations": null, "exact_frames_per_prompt": [12], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5Tq5X4A9ahM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 68, "npz_gt_video_start_frame": 68, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 68, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1062_0_2"}, {"texts": ["A man wearing a shirt is standing on the right side."], "durations": null, "exact_frames_per_prompt": [12], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-ptMoBcBe7Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 16, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1067_0_0"}, {"texts": ["The man is going towards the left side."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-ptMoBcBe7Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 16, "npz_gt_video_start_frame": 16, "npz_gt_video_end_frame": 34, "skip_frames_after_generation": 16, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1067_0_1"}, {"texts": ["A brown cow is standing on the blue surface getting milked by the milking machine while a man wearing a red-white checked shirt stands up and walks away toward the left."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-ptMoBcBe7Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1067_1_0"}, {"texts": ["A woman on the left side is folding a yellow t-shirt with a cardboard and then she puts the t-shirt on the cardboard."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/21XG9zZZqDU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1074_0_0"}, {"texts": ["A person whose hands are visible is folding a green top using brown cardboard on a gray surface."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/21XG9zZZqDU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 32, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1075_0_0"}, {"texts": ["A woman whose only hands are visible is folding a green t-shirt using cardboard."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/21XG9zZZqDU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 21, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1076_0_0"}, {"texts": ["The woman flips the t-shirt on the cardboard."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/21XG9zZZqDU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 21, "npz_gt_video_start_frame": 21, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 21, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1076_0_1"}, {"texts": ["A woman wearing a blue top is standing behind the countertop."], "durations": null, "exact_frames_per_prompt": [34], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/9-nZy24oAr4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 38, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1080_0_0"}, {"texts": ["The woman wearing a blue top is chopping the watermelon with the help of the knife."], "durations": null, "exact_frames_per_prompt": [42], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/9-nZy24oAr4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 38, "npz_gt_video_start_frame": 38, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 38, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1080_0_1"}, {"texts": ["A girl wearing a blue top is sitting on the bed and is crying."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/01Sy8Hh6i-s.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1087_0_0"}, {"texts": ["A woman wearing dark blue pants is holding some papers and moving on a grey surface inside a room."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5bTbbfEHypQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1090_0_0"}, {"texts": ["A man wearing a white t-shirt and black pants is standing and drinking from a glass while a man wearing a black jacket is standing and drinking beer from a beer bottle, and another man wearing a black t-shirt is standing at the back near the bar."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3cOlaoWmXxA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1092_0_0"}, {"texts": ["A man wearing black clothes is standing and drinking from a bottle while the other man wearing grey t-shirt drinks along with him."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3cOlaoWmXxA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1092_1_0"}, {"texts": ["A woman wearing a gray top is sitting on a brown wooden floor and folding a white cloth."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2GviuVuJDiI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 24, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1093_0_0"}, {"texts": ["A brown camel is walking while carrying three girls, another camel is standing and people are sitting on it, and a group of people are standing and few are sitting in the audience area."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0yy1Df51_QE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1095_1_0"}, {"texts": ["A boy wearing a white t-shirt is sitting."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-FYZWo0YmtE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 14, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1096_0_0"}, {"texts": ["The boy blowing air on noodles."], "durations": null, "exact_frames_per_prompt": [11], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-FYZWo0YmtE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 14, "npz_gt_video_start_frame": 14, "npz_gt_video_end_frame": 25, "skip_frames_after_generation": 14, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1096_0_1"}, {"texts": ["The boy starts eating."], "durations": null, "exact_frames_per_prompt": [55], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-FYZWo0YmtE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 25, "npz_gt_video_start_frame": 25, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 25, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1096_0_2"}, {"texts": ["A man wearing a red t-shirt is standing and making a sushi roll."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/37MLRj0s4ok.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_109_0_0"}, {"texts": ["A woman wearing black clothes is standing and dancing on a green surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1qNpl-VZjM0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_10_0_0"}, {"texts": ["A woman wearing a pink t-shirt and printed pant is holding a baby with the green carrier wrap and and it's pouring the butter on bread"], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0kArTUqGOAI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 39, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1109_0_0"}, {"texts": ["The woman is putting the bread on the grill sandwich maker machine and then picking up the napkins."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0kArTUqGOAI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 39, "npz_gt_video_start_frame": 39, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 39, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1109_0_1"}, {"texts": ["A horse is walking in the front while carrying a person on his back, and two other people are moving behind the first horse while sitting on their horses."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4x6djgqGXp4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1120_3_0"}, {"texts": ["A horse is walking in the middle while a horse is walking in front on a soil surface, another horse is walking at the back on a soil surface, and three people are riding horses."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4x6djgqGXp4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1120_4_0"}, {"texts": ["A man wearing a blue-orange shirt is standing on the left side with his thumb up while the girl wearing blue top is eating watermelon"], "durations": null, "exact_frames_per_prompt": [38], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0CV5LDRWwJ8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 42, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1121_0_0"}, {"texts": ["The man goes behind the other girls and does a pose with thumb up while the second and third girl both wearing white top and the second girl throws something"], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0CV5LDRWwJ8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 42, "npz_gt_video_start_frame": 42, "npz_gt_video_end_frame": 72, "skip_frames_after_generation": 42, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1121_0_1"}, {"texts": ["The man starts putting a green sticker in his mouth second and third girl are eating watermelon"], "durations": null, "exact_frames_per_prompt": [8], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0CV5LDRWwJ8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 72, "npz_gt_video_start_frame": 72, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 72, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1121_0_2"}, {"texts": ["A girl wearing a black t-shirt is sitting on the right side while the boy behind wearing blue shirt smiling and showing the sign thumbs up"], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0CV5LDRWwJ8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 22, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1121_1_0"}, {"texts": ["The girl wearing a black t-shirt is eating watermelon while the boy walks to the back of another two girls and puts a green and white colored paper in his mouth"], "durations": null, "exact_frames_per_prompt": [58], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0CV5LDRWwJ8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 22, "npz_gt_video_start_frame": 22, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 22, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1121_1_1"}, {"texts": ["A man wearing white trousers is standing a man in a black coat and pants enters the stage and receives something from the man on the right in a purple shirt."], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0z10mPSYfB0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 47, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1125_2_0"}, {"texts": ["The man is shaking hands with the first man and looking here and there."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0z10mPSYfB0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 47, "npz_gt_video_start_frame": 47, "npz_gt_video_end_frame": 63, "skip_frames_after_generation": 47, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1125_2_1"}, {"texts": ["A man wearing a suit is standing while the other person comes to receive award"], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0z10mPSYfB0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 32, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1125_3_0"}, {"texts": ["The man is clapping, shaking hands with the first man and looking here and there while others watching him."], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0z10mPSYfB0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 32, "npz_gt_video_start_frame": 32, "npz_gt_video_end_frame": 63, "skip_frames_after_generation": 32, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1125_3_1"}, {"texts": ["A baby wearing a white-pink dress is sitting on the gray baby chair and eating food."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3b08kaRvXUc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1131_0_0"}, {"texts": ["A woman wearing black coat is sitting on a chair and speaking on a mike."], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2jwiuVTwaS0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 37, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1134_0_ms_0"}, {"texts": ["A man wearing a black suit and blue tie is speaking on a mike while a group of people sat on either side of him."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2jwiuVTwaS0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 40, "npz_gt_video_start_frame": 40, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 40, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1134_1_0"}, {"texts": ["A woman wearing a black coat and a pink top is sitting on the wooden chair and speaking on the mic while a group of people are also sitting on wooden chairs."], "durations": null, "exact_frames_per_prompt": [34], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2jwiuVTwaS0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 38, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1135_0_0"}, {"texts": ["A man wearing a white shirt, black coat and spectacles is sitting in the middle of another group of people and speaking on the mic."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2jwiuVTwaS0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 40, "npz_gt_video_start_frame": 40, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 40, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1135_2_ms_0"}, {"texts": ["A group of people, including some who are sitting on the right side of the man, some who are sitting on the left side of the man, and one who is standing away, are watching and listening."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2jwiuVTwaS0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 39, "npz_gt_video_start_frame": 39, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 39, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1135_3_ms_0"}, {"texts": ["A woman wearing a black coat is sitting in a wooden chair and speaking while the man wearing black coat is also speaking on the mic."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2jwiuVTwaS0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1136_0_0"}, {"texts": ["A man wearing a black suit is sitting and speaking while other people are also sitting next to him."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2jwiuVTwaS0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 39, "npz_gt_video_start_frame": 39, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 39, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1136_1_0"}, {"texts": ["A group of people is sitting in the back and a person is standing."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2jwiuVTwaS0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 39, "npz_gt_video_start_frame": 39, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 39, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1136_2_ms_0"}, {"texts": ["A person wearing blue clothes is riding on the head of an elephant while a man and a woman are also riding on an elephant."], "durations": null, "exact_frames_per_prompt": [42], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Pb4ghR0COE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 46, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1138_0_0"}, {"texts": ["An elephant is walking on the muddy surface behind the other elephant, and giving a ride to the person in blue clothes and the another elephant is walking in the front while carrying people on its back."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Pb4ghR0COE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1138_2_0"}, {"texts": ["An elephant who is walking on the head of another elephant is giving a ride to the group of people."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Pb4ghR0COE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1138_3_0"}, {"texts": ["A person wearing blue shorts is standing, holding and moving the black tire on the gray surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-He1Ivgwyxc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1140_0_0"}, {"texts": ["A person  wearing black clothes is sitting on the couch and petting a black-white cat."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-QlQrBZOY0w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1141_0_0"}, {"texts": ["A black-white cat is sitting on the couch and getting petted by a person."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-QlQrBZOY0w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1141_1_0"}, {"texts": ["A man wearing a light gray t-shirt is sitting on a brown sofa holding the baby and speaking and the baby wearing a pink shirt is laughing."], "durations": null, "exact_frames_per_prompt": [47], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0GsiopyhDgI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 51, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1142_0_0"}, {"texts": ["A baby wearing a light pink cloth is sitting on the man's lap and laughing while man doing hand gestures and looking on the right side."], "durations": null, "exact_frames_per_prompt": [47], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0GsiopyhDgI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 51, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1142_1_0"}, {"texts": ["A man wearing a light gray t-shirt is sitting on a sofa, holding a baby."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0GsiopyhDgI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 24, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1143_0_0"}, {"texts": ["The man is talking a baby wearing pink shirt is laughing."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0GsiopyhDgI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 24, "npz_gt_video_start_frame": 24, "npz_gt_video_end_frame": 51, "skip_frames_after_generation": 24, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1143_0_1"}, {"texts": ["A baby wearing a pink dress is sitting and laughing while being held by a man who is sitting and talking."], "durations": null, "exact_frames_per_prompt": [47], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0GsiopyhDgI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 51, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1143_1_0"}, {"texts": ["A man wearing a green-blue checked shirt and blue trousers is leaning forward and shaving the sheep."], "durations": null, "exact_frames_per_prompt": [62], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0PhpTs9ttHc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 66, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1144_0_0"}, {"texts": ["A white sheep is lying on the floor and being shaved by the man."], "durations": null, "exact_frames_per_prompt": [62], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0PhpTs9ttHc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 66, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1144_1_0"}, {"texts": ["A boy wearing a white shirt is sitting behind the black table and drinking from the glass."], "durations": null, "exact_frames_per_prompt": [49], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3bhDPbdMbp4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 53, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1146_0_0"}, {"texts": ["The boy is sliding a green packet towards himself and starts drinking again."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3bhDPbdMbp4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 53, "npz_gt_video_start_frame": 53, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 53, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1146_0_1"}, {"texts": ["A man wearing a black coat is sitting and moving his hands a man wearing a white shirt is sitting and looking towards the right side."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-ATBr1X9HRQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1154_0_0"}, {"texts": ["A man wearing a white shirt is sitting and keeps his hand on the brown table, taking a glass of wine and putting it on the table while a man wearing glasses is sitting on the right side and speaking while moving his hands."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-ATBr1X9HRQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1154_1_0"}, {"texts": ["A man wearing black clothes is folding and flipping a sheet kept on the wooden table."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-8ieGoxXh0A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1158_0_0"}, {"texts": ["A girl wearing a blue cloth, is sitting on the right side and carry a rabbit while a girl wearing a black top is bends towards the soil surface and touching something then she stands and starts touching the rabbit."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1CN2-8KGLKo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1161_0_0"}, {"texts": ["A girl wearing a black t-shirt is standing and leaning forward while a woman on the right side wearing a blue vest is sitting while carrying a rabbit on her lap."], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1CN2-8KGLKo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 47, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1161_1_0"}, {"texts": ["The girl is picking up something."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1CN2-8KGLKo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 47, "npz_gt_video_start_frame": 47, "npz_gt_video_end_frame": 65, "skip_frames_after_generation": 47, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1161_1_1"}, {"texts": ["The girl starts rubbing rabbit's head."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1CN2-8KGLKo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 65, "npz_gt_video_start_frame": 65, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 65, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1161_1_2"}, {"texts": ["A girl wearing a printed t-shirt opens a packet of bread."], "durations": null, "exact_frames_per_prompt": [34], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1hjtUQTTJag.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 38, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1163_0_0"}, {"texts": ["The girl wearing a printed t-shirt put two slices of bread on a plate."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1hjtUQTTJag.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 38, "npz_gt_video_start_frame": 38, "npz_gt_video_end_frame": 52, "skip_frames_after_generation": 38, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1163_0_1"}, {"texts": ["The girl wearing a printed t-shirt lifts the peanut butter jar."], "durations": null, "exact_frames_per_prompt": [5], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1hjtUQTTJag.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 52, "npz_gt_video_start_frame": 52, "npz_gt_video_end_frame": 57, "skip_frames_after_generation": 52, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1163_0_2"}, {"texts": ["The girl wearing a printed t-shirt tries to open it."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1hjtUQTTJag.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 57, "npz_gt_video_start_frame": 57, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 57, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1163_0_3"}, {"texts": ["A black cat is standing and being caressed by a person."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2-3Yv8ws3ys.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1170_1_0"}, {"texts": ["A man wearing a black suit, a beige shirt, and a red tie is standing in front and holding a pen in his right hand."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3-t_qpear60.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1171_0_0"}, {"texts": ["A woman wearing a blue shirt and black shorts is moving and firing coals into the grill with a flame lighter on the grass surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2qzMxBJ5hGo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1172_0_0"}, {"texts": ["A man wearing black clothes is standing and speaking and moving his hands."], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0EISyzfzELo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 47, "npz_gt_video_start_frame": 47, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 47, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1173_0_0"}, {"texts": ["A baby wearing a white-pink frock is feeding a baby goat and another baby and some goats are standing on the backside."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/08u3cb1wyvg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 13, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1174_0_0"}, {"texts": ["The baby wearing a white-pink frock is standing, and moving."], "durations": null, "exact_frames_per_prompt": [39], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/08u3cb1wyvg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 13, "npz_gt_video_start_frame": 13, "npz_gt_video_end_frame": 52, "skip_frames_after_generation": 13, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1174_0_1"}, {"texts": ["A white baby goat is standing behind the square wire fencing and eating a carrot while a baby wearing a dress is feeding the goat and then moves her hand, a kid wearing an orange top is feeding other goats and then turns back."], "durations": null, "exact_frames_per_prompt": [48], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/08u3cb1wyvg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 52, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1174_2_0"}, {"texts": ["A baby wearing a jacket is playing with a newspaper inside a moving car."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/6ZwFwfDcwH8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1175_0_0"}, {"texts": ["A man wearing a red t-shirt is playing golf in the golf course."], "durations": null, "exact_frames_per_prompt": [53], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1gPc7aoFcuc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 57, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1176_0_0"}, {"texts": ["The man wearing a red t-shirt moves backward."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1gPc7aoFcuc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 57, "npz_gt_video_start_frame": 57, "npz_gt_video_end_frame": 73, "skip_frames_after_generation": 57, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1176_0_1"}, {"texts": ["A man wearing a red t-shirt, brown jeans, and white shoes is standing while holding a golf stick."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1gPc7aoFcuc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 18, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1177_0_0"}, {"texts": ["The man wearing a red t-shirt, brown jeans, and white shoes is playing golf while hitting the golf ball with the golf stick to the golf goal hole."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1gPc7aoFcuc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 18, "npz_gt_video_start_frame": 18, "npz_gt_video_end_frame": 54, "skip_frames_after_generation": 18, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1177_0_1"}, {"texts": ["The man wearing a red t-shirt, brown jeans, and white shoes looking in the front while turning his body back."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1gPc7aoFcuc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 54, "npz_gt_video_start_frame": 54, "npz_gt_video_end_frame": 73, "skip_frames_after_generation": 54, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1177_0_2"}, {"texts": ["A person whose only hands are visible is folding a printed white t-shirt using a shirt folding board."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1xzRU8OHyEo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1180_0_0"}, {"texts": ["A person wearing a white cloth is peeling sweet potatoes in a big wicker basket while another person sitting behind the first person is cutting something."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1isKrzrZTMw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_118_0_0"}, {"texts": ["A person wearing a red-white t-shirt and green shorts is sitting beside the first person while another person whose legs are visible is standing and walking towards the second person."], "durations": null, "exact_frames_per_prompt": [67], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1isKrzrZTMw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 71, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_118_1_0"}, {"texts": ["The person is chopping cabbage."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1isKrzrZTMw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 71, "npz_gt_video_start_frame": 71, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 71, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_118_1_1"}, {"texts": ["A man whose upper half-body is visible wearing a green shirt is standing on the left side while holding a white cap in his left hand while a group of people are sitting in front of him."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-qBi-XmpFXU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 18, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1190_1_0"}, {"texts": ["The man is showing the cap to the group of people while a man wearing a black suit is speaking into the mic and moving here and there."], "durations": null, "exact_frames_per_prompt": [62], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-qBi-XmpFXU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 18, "npz_gt_video_start_frame": 18, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 18, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1190_1_1"}, {"texts": ["A man wearing a black shirt and black pants is standing on the right side and pointing his right hand at the group of people while a man wearing a brown shirt is standing on the left side and picking up an object, and another man wearing black suit is standing on the right side."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-qBi-XmpFXU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1190_2_0"}, {"texts": ["A man wearing a black suit, is standing in the middle of the first and second man while holding a microphone in his left hand and speaking on the mic while pointing his right hand to the first man while the first man on the left side wearing a green shirt is raising his hand while holding a white object and showing it to the people."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-qBi-XmpFXU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1190_3_0"}, {"texts": ["A man wearing a green jacket, goggles, and green pants is sitting with his knees while holding a black metal object and is speaking."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1YUEFVWWCpc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1191_0_0"}, {"texts": ["The man is putting the metal object on the snow surface."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1YUEFVWWCpc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 50, "npz_gt_video_start_frame": 50, "npz_gt_video_end_frame": 60, "skip_frames_after_generation": 50, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1191_0_1"}, {"texts": ["A man wearing a brown hoodie is standing on a green golf mat and playing golf."], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Vq-tbqCPWY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 37, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1194_0_0"}, {"texts": ["The man wearing a brown hoodie is adjusting his hoodie."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Vq-tbqCPWY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 37, "npz_gt_video_start_frame": 37, "npz_gt_video_end_frame": 56, "skip_frames_after_generation": 37, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1194_0_1"}, {"texts": ["The man wearing a brown hoodie again starts playing golf."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Vq-tbqCPWY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 56, "npz_gt_video_start_frame": 56, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 56, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1194_0_2"}, {"texts": ["A person wearing a sky-blue t-shirt is standing and cutting the pineapple on the white cardboard."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0W47UXcH2-o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1195_0_0"}, {"texts": ["A boy wearing gray clothes is tearing the white papers and speaking."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1effP13TOtA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1196_0_0"}, {"texts": ["A girl wearing a black t-shirt is standing, holding a potato and peeling it while putting the peels on the black counter-top.\n"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3t7Gz5zlUNc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1199_0_0"}, {"texts": ["A person whose hand is visible on the right side has pigeon food on his hand and is feeding pigeons."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-mVvWNrAjSQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1201_0_0"}, {"texts": ["A woman wearing a white shirt is tying a bow tie."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/6tLxSP7dt8U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 39, "npz_gt_video_start_frame": 39, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 39, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1202_0_0"}, {"texts": ["A woman in a white dress is standing on the left side of the car, covering the pump from a white cloth and placing it in the machine."], "durations": null, "exact_frames_per_prompt": [55], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-o9dVimfAHw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 59, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1203_0_0"}, {"texts": ["The woman is taking the tab from between her legs and walking towards the car."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-o9dVimfAHw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 59, "npz_gt_video_start_frame": 59, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 59, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1203_0_1"}, {"texts": ["A man wearing a white t-shirt is standing and playing golf.\n"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1cGuPiqCsuk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1206_0_0"}, {"texts": ["A person whose only thumb is visible wearing a gray cloth is taking out a black cloth from the orange packet."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-2gL5FducRk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1209_0_0"}, {"texts": ["A man is wearing a black suit is sitting and speaking."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/11ZPBc9tEb4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 25, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_120_0_ms_0"}, {"texts": ["A black cat is walking on a white surface."], "durations": null, "exact_frames_per_prompt": [54], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/11ZPBc9tEb4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 25, "npz_gt_video_start_frame": 25, "npz_gt_video_end_frame": 79, "skip_frames_after_generation": 25, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_120_1_ms_0"}, {"texts": ["A person whose only hand is visible is taking out a bowl from an oven with a cloth."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1CAA1ciBgKY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 34, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1211_0_0"}, {"texts": ["The person is putting bowl on the countertop."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1CAA1ciBgKY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 34, "npz_gt_video_start_frame": 34, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 34, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1211_0_1"}, {"texts": ["A person whom hand is visible is taking a bowl out of the microwave."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1CAA1ciBgKY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 27, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1212_0_0"}, {"texts": ["The person puts it on the kitchen shelf."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1CAA1ciBgKY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 27, "npz_gt_video_start_frame": 27, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 27, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1212_0_1"}, {"texts": ["A bare-chested baby is sitting on the baby chair and making noise."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-tzRVLORGvY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1217_0_0"}, {"texts": ["A person wearing a shirt is sitting on a club chair and drinking beer."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/600a4kiWCv8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 20, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1219_0_0"}, {"texts": ["The person is showing the bottle."], "durations": null, "exact_frames_per_prompt": [44], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/600a4kiWCv8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 20, "npz_gt_video_start_frame": 20, "npz_gt_video_end_frame": 64, "skip_frames_after_generation": 20, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1219_0_1"}, {"texts": ["A man wearing a printed sweater is sitting, drinking liquid."], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4haZVWuL98M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 37, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1221_0_0"}, {"texts": ["The man wearing a printed sweater is removing cigarette ashes in the glass bowl."], "durations": null, "exact_frames_per_prompt": [42], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4haZVWuL98M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 37, "npz_gt_video_start_frame": 37, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 37, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1221_0_1"}, {"texts": ["A woman wearing white clothes is plucking the eyebrows of a woman with a plucker."], "durations": null, "exact_frames_per_prompt": [67], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Z9QAMI6txY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 71, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1223_0_0"}, {"texts": ["A woman wrapped in a blue sheet is getting her eyebrows plucked by the woman in white clothes."], "durations": null, "exact_frames_per_prompt": [67], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Z9QAMI6txY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 71, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1223_1_0"}, {"texts": ["A woman in black and white clothing is walking in the left direction while watching the child in an orange cap playing golf while a kid in a white cap is picking something from the grass surface."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-3dnFPNzuW4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 25, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1225_2_0"}, {"texts": ["A baby wearing a white cloth and a white feeding bib on the neck is sitting on the baby hug booster chair while holding a spoon and eating the food."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2aPVxlEm5r8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1228_1_0"}, {"texts": ["A person wearing yellow clothes is sitting and holding a white cloth."], "durations": null, "exact_frames_per_prompt": [12], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2NelhDcRxA0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 16, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1229_0_0"}, {"texts": ["The person is trying to wrap on the hand of a person."], "durations": null, "exact_frames_per_prompt": [64], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2NelhDcRxA0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 16, "npz_gt_video_start_frame": 16, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 16, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1229_0_1"}, {"texts": ["A man wearing black pants is sitting on a brown sofa, using a drill machine with an apple attached and peeling the apple with a vegetable peeler."], "durations": null, "exact_frames_per_prompt": [57], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2cwC0mVVls0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 61, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1232_0_0"}, {"texts": ["A woman with one visible hand, wearing a black cloth, is holding an ice cream and letting the baby eat it."], "durations": null, "exact_frames_per_prompt": [45], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-X_bcgATtH4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 49, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1236_0_0"}, {"texts": ["The woman is wiping the baby's mouth with a tissue while a person in a black outfit walks away."], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-X_bcgATtH4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 49, "npz_gt_video_start_frame": 49, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 49, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1236_0_1"}, {"texts": ["A baby wearing a white-pink cloth is sitting on the baby's chair while a person whose hand is visible is holding an ice-cream cone and is feeding it to the baby."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-X_bcgATtH4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 31, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1236_1_0"}, {"texts": ["The baby wearing a white-pink cloth is eating an ice-cream then the person wipes the baby's mouth."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-X_bcgATtH4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 31, "npz_gt_video_start_frame": 31, "npz_gt_video_end_frame": 55, "skip_frames_after_generation": 31, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1236_1_1"}, {"texts": ["The baby wearing a white-pink cloth starts crying while a person wearing black clothes moves towards the left."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-X_bcgATtH4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 55, "npz_gt_video_start_frame": 55, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 55, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1236_1_2"}, {"texts": ["A person on the right side wearing black pants is playing golf on a green grass surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0_tWYFDPZd8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1240_0_0"}, {"texts": ["A person wearing white-blue lining clothes is sitting, holding a baby in their lap and feeding the food to a baby."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/45idT3DXxoQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1245_0_0"}, {"texts": ["A baby wearing pink bottoms is sitting in the lap of a person and getting fed by the person."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/45idT3DXxoQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1245_1_0"}, {"texts": ["A man whose only hands are visible is mixing the egg yolk with a fork in the liquid in the fry pan."], "durations": null, "exact_frames_per_prompt": [34], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/11J84KX8K3w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 41, "npz_gt_video_start_frame": 41, "npz_gt_video_end_frame": 75, "skip_frames_after_generation": 41, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1247_0_0"}, {"texts": ["The man is closing the egg storage box."], "durations": null, "exact_frames_per_prompt": [4], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/11J84KX8K3w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 75, "npz_gt_video_start_frame": 75, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 75, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1247_0_1"}, {"texts": ["A woman wearing a full-sleeve gray t-shirt and jeans is opening the microwave door with her left hand, and taking out the cup of tea with her right hand from the microwave."], "durations": null, "exact_frames_per_prompt": [11], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2bPBOkqkwGo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 15, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1249_0_0"}, {"texts": ["The woman wearing a full-sleeve gray t-shirt and jeans walks and putting the cup on the countertop."], "durations": null, "exact_frames_per_prompt": [65], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2bPBOkqkwGo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 15, "npz_gt_video_start_frame": 15, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 15, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1249_0_1"}, {"texts": ["A woman wearing a green shirt is applying a cream on her face and neck."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4i3OTta8DZ4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1250_0_0"}, {"texts": ["A person whose hands are visible with black trousers, holding a tube."], "durations": null, "exact_frames_per_prompt": [59], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-P32zs455zc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 63, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1252_0_0"}, {"texts": ["The person inflating a tire."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-P32zs455zc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 63, "npz_gt_video_start_frame": 63, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 63, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1252_0_1"}, {"texts": ["A girl on the left, standing is making a sandwich while the girl standing on the right side is touching the food."], "durations": null, "exact_frames_per_prompt": [58], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2vfyDImgsNM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 62, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1254_0_0"}, {"texts": ["The girl is picking up a red bowl."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2vfyDImgsNM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 62, "npz_gt_video_start_frame": 62, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 62, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1254_0_1"}, {"texts": ["A girl on the right wearing a blue hoodie is standing while another girl on the left side in a black-white printed top is standing and talking."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2vfyDImgsNM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 20, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1254_1_0"}, {"texts": ["The girl on the right wearing a blue hoodie is adjusting the sandwich and the girl on the left picks up a red object."], "durations": null, "exact_frames_per_prompt": [60], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2vfyDImgsNM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 20, "npz_gt_video_start_frame": 20, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 20, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1254_1_1"}, {"texts": ["A pandemonium of parrots is sitting on the railing."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0rLZNg8EmJ8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 34, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1258_0_ms_0"}, {"texts": ["One of the parrots is walking towards the other parrots and then it flies to the other side of the railing."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0rLZNg8EmJ8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 34, "npz_gt_video_start_frame": 34, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 34, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1258_0_ms_1"}, {"texts": ["A black and white dog is lying on the floor, dog is looking at the fingers."], "durations": null, "exact_frames_per_prompt": [59], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3Qu9OQcbFDU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 63, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1259_1_0"}, {"texts": ["The black and white dog starts searching for something after the person speaks."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3Qu9OQcbFDU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 63, "npz_gt_video_start_frame": 63, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 63, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1259_1_1"}, {"texts": ["A man wearing white-black clothes is standing on a gray surface, holding papers and moving his hand."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5BF1w9DXsWE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1260_0_0"}, {"texts": ["A girl wearing a white dress is sitting on the back of a camel and riding in a right direction and a woman wearing a purple t-shirt is walking while holding the camel's leash, and another camel is also walking behind it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-LHHfaxzj7I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1261_0_0"}, {"texts": ["A woman wearing a blue t-shirt is holding the halter of the camel and walking along with the camel while the girl sits on the camel, and in back other camel follows them."], "durations": null, "exact_frames_per_prompt": [65], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-LHHfaxzj7I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 15, "npz_gt_video_start_frame": 15, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 15, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1261_1_0"}, {"texts": ["A camel is walking in a right direction while giving a ride to the girl on its back while a woman wearing a purple t-shirt is walking and holding the camel's leash, and another camel is also walking behind it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-LHHfaxzj7I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1261_2_0"}, {"texts": ["A woman wearing a white top is standing and is mixing noodles and lettuce in a glass bowl with silver pincers.\n"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2u0tVHw5oOk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1264_0_0"}, {"texts": ["A girl wearing a yellow dress is sitting on a brown sofa."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-xDXYkOG5B0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 14, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1266_0_0"}, {"texts": ["The girl wearing a yellow dress picks up a white shirt and unfolds it."], "durations": null, "exact_frames_per_prompt": [66], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-xDXYkOG5B0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 14, "npz_gt_video_start_frame": 14, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 14, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1266_0_1"}, {"texts": ["A person whose hands are visible is binding a book with a needle and thread."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1tIBysElEBE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1276_0_0"}, {"texts": [" A woman, whose only hands are visible, is holding an egg shell."], "durations": null, "exact_frames_per_prompt": [34], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2T-O7apS96c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 38, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1279_0_0"}, {"texts": ["The woman is putting the egg shell aside."], "durations": null, "exact_frames_per_prompt": [42], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2T-O7apS96c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 38, "npz_gt_video_start_frame": 38, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 38, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1279_0_1"}, {"texts": ["A person wearing blue clothes is putting the sushi pieces in a plate."], "durations": null, "exact_frames_per_prompt": [44], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-dx9-XDIFh8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 48, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1283_0_0"}, {"texts": ["The person is piecing the sushi roll with a knife."], "durations": null, "exact_frames_per_prompt": [32], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-dx9-XDIFh8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 48, "npz_gt_video_start_frame": 48, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 48, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1283_0_1"}, {"texts": ["A man whose hand is visible is caressing the chinchilla rodent's head."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0-ukHRelxA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1291_0_0"}, {"texts": ["A brown chinchilla rodent is sitting in the cage and chewing something and its head caressed by the man."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0-ukHRelxA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1291_1_0"}, {"texts": ["A man wearing a white shirt opens a champagne bottle with a knife."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/s84sJC48qG4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 22, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_129_0_0"}, {"texts": ["The man puts it on the table."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/s84sJC48qG4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 22, "npz_gt_video_start_frame": 22, "npz_gt_video_end_frame": 49, "skip_frames_after_generation": 22, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_129_0_1"}, {"texts": ["The man walks away."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/s84sJC48qG4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 49, "npz_gt_video_start_frame": 49, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 49, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_129_0_2"}, {"texts": ["A man wearing a sky blue shirt and brown pants is standing behind the counter, putting the green bowl on the counter with his right hand."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3hJ3DvXucnk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 13, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1301_0_0"}, {"texts": ["The man starts rotating the nut of the mincer machine with his hands."], "durations": null, "exact_frames_per_prompt": [67], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3hJ3DvXucnk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 13, "npz_gt_video_start_frame": 13, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 13, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1301_0_1"}, {"texts": ["A person wearing a blue shirt is keeping a green bucket aside."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3hJ3DvXucnk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 14, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1302_0_0"}, {"texts": ["The person is unscrewing a metal piece of a meat grinder."], "durations": null, "exact_frames_per_prompt": [66], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3hJ3DvXucnk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 14, "npz_gt_video_start_frame": 14, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 14, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1302_0_1"}, {"texts": ["A woman wearing a dark blue top and white shorts is standing and playing golf on the green surface."], "durations": null, "exact_frames_per_prompt": [44], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0djBLoTFYrA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 48, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1305_1_0"}, {"texts": ["A person wearing pink clothes is pouring food in the baking tray with a spoon."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-l3Cq12DG3Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1306_0_0"}, {"texts": ["A woman wearing a pink t-shirt is standing."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-l3Cq12DG3Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 19, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1307_0_0"}, {"texts": ["The woman is putting chocolates in a tray with the spoon."], "durations": null, "exact_frames_per_prompt": [61], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-l3Cq12DG3Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 19, "npz_gt_video_start_frame": 19, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 19, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1307_0_1"}, {"texts": ["A baby wearing a white t-shirt is sitting on the red mat, holding a book."], "durations": null, "exact_frames_per_prompt": [50], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0EE-R-9pOY4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 54, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1310_0_0"}, {"texts": ["The baby is moving their hands."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0EE-R-9pOY4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 54, "npz_gt_video_start_frame": 54, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 54, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1310_0_1"}, {"texts": ["A kid wearing a blue t-shirt is running on the gray surface and is trying to catch the pigeons."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0hKrYZXvsfA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1312_0_0"}, {"texts": ["A man wearing black clothes is standing and holding fishing rod."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2botTVCE9dI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1313_0_0"}, {"texts": ["The man wearing black clothes is watching on the wrist."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2botTVCE9dI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 40, "npz_gt_video_start_frame": 40, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 40, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1313_0_1"}, {"texts": ["A man wearing a black t-shirt and white pants is sitting on the back of the camel in the desert."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-6usjfP8hys.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1318_0_0"}, {"texts": ["A brown camel is walking in the middle on the sand surface while another two camels are also walking on the sand surface and a group of three people are sitting on the camels."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-6usjfP8hys.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1318_5_0"}, {"texts": ["A boy wearing a blue t-shirt and cap is standing in the middle and feeding the bird while other boys are also trying to feed the bird."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-C5aPmkmjA4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1321_0_0"}, {"texts": ["A bird is sitting on a wooden stick and eating from the first boy hand while the boy standing to the left of first boy also tried to feed bird"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-C5aPmkmjA4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1321_1_0"}, {"texts": ["Another boy wearing a blue-white t-shirt is standing on the right and holding something in his hand and moving his hand towards the bird.\n while a man wearing blue t-shirt holding boy kid giving something for birds"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-C5aPmkmjA4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1321_2_0"}, {"texts": ["A boy wearing a purple t-shirt is standing on the left side and holding the kid's hand and a white bird is eating food from the palm of a man."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-C5aPmkmjA4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1321_3_0"}, {"texts": ["A boy wearing a blue t-shirt and a white cap is standing in the middle on the left side and is feeding the bird while a boy wearing blue strip t-shirt is taking food from right and giving it to the bird and other two person are standing on the left."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-C5aPmkmjA4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1322_0_0"}, {"texts": ["A bird is on the wooden stick and eating from the first boy's hand while a boy in a blue striped t-shirt feeds the bird with his hand, two other boys stand on the left side, looking at the bird."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-C5aPmkmjA4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1322_1_0"}, {"texts": ["A boy wearing a white-blue striped t-shirt and black jeans is standing on the left side and is holding feeding material in his right hand and is moving his hand towards the bird while the others joins him."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-C5aPmkmjA4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1322_2_0"}, {"texts": ["A boy whose upper body is visible wearing a purple t-shirt is standing on the left side behind the child boy, and is holding the child boy's right hand while a boy wearing a cap is standing and feeding a bird with his hands, another boy wearing a multicolored t-shirt is standing, holding bird food in his hand."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-C5aPmkmjA4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1322_3_0"}, {"texts": ["A woman wearing a black dress is doing gift wrapping while instructing how to do gift wrapping."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-ff8k7ezmv0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1323_0_0"}, {"texts": ["A girl wearing a yellow t-shirt and pink shorts is sitting on the bed and folding the clothes."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2fRUyhKgx9k.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1325_0_0"}, {"texts": ["A person whose hands are visible is opening a brown cardboard box with a knife."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0duJnIG59fQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1330_0_0"}, {"texts": ["A person whose only hands are visible is cutting a brown cardboard box with a knife."], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0duJnIG59fQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 41, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1331_0_0"}, {"texts": ["The person trying to open the box with his hands."], "durations": null, "exact_frames_per_prompt": [39], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0duJnIG59fQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 41, "npz_gt_video_start_frame": 41, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 41, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1331_0_1"}, {"texts": ["A person whose hands are only visible is cutting a brown box with a knife."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0duJnIG59fQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1332_0_0"}, {"texts": ["The person whose hands are only visible is tearing the brown box with his hands."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0duJnIG59fQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 45, "npz_gt_video_start_frame": 45, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 45, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1332_0_1"}, {"texts": ["A woman wearing a purple jacket, blue jeans, black gloves, and black shoes is standing on the left side while a brown horse is standing on the right side on the pebble surface."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3QD1bUNhFh8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 29, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1333_0_0"}, {"texts": ["The woman is measuring the figure of the horse while touching the horse from his hip to the legs."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3QD1bUNhFh8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 29, "npz_gt_video_start_frame": 29, "npz_gt_video_end_frame": 69, "skip_frames_after_generation": 29, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1333_0_1"}, {"texts": ["The woman is picking the horse's leg and starts touching from her own leg to her waist."], "durations": null, "exact_frames_per_prompt": [12], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3QD1bUNhFh8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 69, "npz_gt_video_start_frame": 69, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 69, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1333_0_2"}, {"texts": ["A brown horse is standing on the surface."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3QD1bUNhFh8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 28, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1333_1_0"}, {"texts": ["The horse's leg is picked by the woman."], "durations": null, "exact_frames_per_prompt": [53], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3QD1bUNhFh8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 28, "npz_gt_video_start_frame": 28, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 28, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1333_1_1"}, {"texts": ["A woman wearing a gray top is standing on the left and holding a red plastic cup while a man wearing grey and black t-shirt is standing on the right holding a beer bottle in his hand and he is talking."], "durations": null, "exact_frames_per_prompt": [54], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-ndZE5bxS3A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1343_0_0"}, {"texts": ["The woman starts drinking from the cup."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-ndZE5bxS3A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 58, "npz_gt_video_start_frame": 58, "npz_gt_video_end_frame": 76, "skip_frames_after_generation": 58, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1343_0_1"}, {"texts": ["A man wearing a gray-black t-shirt is standing, holding a bottle and talking with the first woman."], "durations": null, "exact_frames_per_prompt": [72], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-ndZE5bxS3A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 76, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1343_1_0"}, {"texts": ["The man wearing a gray-black t-shirt is standing, holding a bottle and talking with the second woman."], "durations": null, "exact_frames_per_prompt": [4], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-ndZE5bxS3A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 76, "npz_gt_video_start_frame": 76, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 76, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1343_1_1"}, {"texts": ["A woman whose hands are visible is holding the pen in her right hand."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1XzuqBmJxK4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1344_0_0"}, {"texts": ["The woman is writing on white paper."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1XzuqBmJxK4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 50, "npz_gt_video_start_frame": 50, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 50, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1344_0_1"}, {"texts": ["A man wearing a blue shirt is standing."], "durations": null, "exact_frames_per_prompt": [64], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/52oamnB8PFc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 68, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1348_0_0"}, {"texts": ["The man holds the mic."], "durations": null, "exact_frames_per_prompt": [12], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/52oamnB8PFc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 68, "npz_gt_video_start_frame": 68, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 68, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1348_0_1"}, {"texts": ["A kid wearing a yellow t-shirt is standing and eating noodles through his hand from the plate."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-yQvLuX6Vfg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_134_0_0"}, {"texts": ["A person whose hand is only visible is opening the glass cover of the electric egg cooker."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/21jxy4pXfYA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 27, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1357_0_0"}, {"texts": ["A person whose hands are visible is pouring something from the white cup into a green bowl."], "durations": null, "exact_frames_per_prompt": [32], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-veWoU_yOjc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 36, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1358_0_0"}, {"texts": ["The person whose hands are visible is mixing it."], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-veWoU_yOjc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 36, "npz_gt_video_start_frame": 36, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 36, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1358_0_1"}, {"texts": ["A woman wearing a blue life jacket is standing and giving something to a group of fishes."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-BT1xG7BvjM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1359_0_0"}, {"texts": ["A woman wearing white clothes is sitting and she is turning book pages and the woman wearing blue top sitting on the right is also turning pages"], "durations": null, "exact_frames_per_prompt": [32], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4hlk-7eLH7U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 36, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1363_0_0"}, {"texts": ["The woman is also talking so dies the woman wearing blue top"], "durations": null, "exact_frames_per_prompt": [44], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4hlk-7eLH7U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 36, "npz_gt_video_start_frame": 36, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 36, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1363_0_1"}, {"texts": ["A woman wearing blue clothes is also sitting on the right."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4hlk-7eLH7U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 13, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1363_1_0"}, {"texts": ["The woman is turning newspaper pages."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4hlk-7eLH7U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 13, "npz_gt_video_start_frame": 13, "npz_gt_video_end_frame": 33, "skip_frames_after_generation": 13, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1363_1_1"}, {"texts": ["The woman is also talking while a woman wearing white top is sitting on left and she is talking and turning pages."], "durations": null, "exact_frames_per_prompt": [47], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4hlk-7eLH7U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 33, "npz_gt_video_start_frame": 33, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 33, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1363_1_2"}, {"texts": ["A girl wearing a white and pink t-shirt is speaking."], "durations": null, "exact_frames_per_prompt": [52], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-mz_oMFUZL8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 56, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1365_0_0"}, {"texts": ["The girl is eating a chip from a blue plastic packet."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-mz_oMFUZL8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 56, "npz_gt_video_start_frame": 56, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 56, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1365_0_1"}, {"texts": ["A man wearing a white shirt is putting dressing in the green beans salad. "], "durations": null, "exact_frames_per_prompt": [12], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/12fQulARGTE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 16, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1370_0_0"}, {"texts": ["The man starts mixing the salad with a tong."], "durations": null, "exact_frames_per_prompt": [51], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/12fQulARGTE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 16, "npz_gt_video_start_frame": 16, "npz_gt_video_end_frame": 67, "skip_frames_after_generation": 16, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1370_0_1"}, {"texts": ["The man puts eggs in the salad with a knife."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/12fQulARGTE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 67, "npz_gt_video_start_frame": 67, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 67, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1370_0_2"}, {"texts": ["A man in a white-black shirt inserts salt into the bowl."], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/32SxoDEQ3T4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 41, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1372_0_0"}, {"texts": ["The man begins marinating."], "durations": null, "exact_frames_per_prompt": [39], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/32SxoDEQ3T4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 41, "npz_gt_video_start_frame": 41, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 41, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1372_0_1"}, {"texts": ["A man wearing a white t-shirt is sitting behind the table, putting some salami on the pizza."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0VWdE2fREQw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 21, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1379_0_0"}, {"texts": ["The man is picking up a bottle."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0VWdE2fREQw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 21, "npz_gt_video_start_frame": 21, "npz_gt_video_end_frame": 57, "skip_frames_after_generation": 21, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1379_0_1"}, {"texts": ["The man is sprinkling something on it."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0VWdE2fREQw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 57, "npz_gt_video_start_frame": 57, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 57, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1379_0_2"}, {"texts": ["A man wearing a white t-shirt is sitting and adding some toppings and cheese on a pizza.\n"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0VWdE2fREQw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1380_0_0"}, {"texts": ["A person wearing a red t-shirt is holding a cat in their arms and rubbing its tummy with their hand."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1rRNNOo3J-A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1384_0_0"}, {"texts": ["A white cat is being held by a person in their arms and getting rubbed by their hand on the belly of the cat, then the cat starts meowing."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1rRNNOo3J-A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1384_1_0"}, {"texts": ["A man wearing black vest is putting his hand on the shoulder of the first man and holding a red paper strip in his mouth while third man wearing red and white outfit is standing on the right side with his arms folded and looking at other men."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2bPlceN5pgY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 18, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1386_1_0"}, {"texts": ["The man is standing and taking out the paper strip from his mouth."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2bPlceN5pgY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 18, "npz_gt_video_start_frame": 18, "npz_gt_video_end_frame": 35, "skip_frames_after_generation": 18, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1386_1_1"}, {"texts": ["A man wearing a white-grey t-shirt is holding a white paper strip in his mouth and the other man tries to grab that paper in his mouth"], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2bPlceN5pgY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 63, "npz_gt_video_start_frame": 63, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 63, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1386_2_0"}, {"texts": ["A man wearing a patterned purple shirt is moving in left direction on a grass surface while a woman wearing a black t-shirt is walking behind a man on the green grass surface while looking here and there."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1xQunZuW7Ds.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1387_0_0"}, {"texts": ["A woman wearing a black bee protection suit is moving in the left direction on a grass surface while an old man on the left side wearing a grey shirt is moving in the left direction on a grass surface."], "durations": null, "exact_frames_per_prompt": [64], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1xQunZuW7Ds.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 16, "npz_gt_video_start_frame": 16, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 16, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1387_1_0"}, {"texts": ["A woman wearing blue jeans whom leg is visible is getting her leg wiped by the man and getting a tattoo on her leg by the man."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1VQwWwyq1nA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1388_0_0"}, {"texts": ["A boy wearing sky blue clothes is sitting and washing clothes near the pond."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0mC_uFdzcIA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1403_0_0"}, {"texts": ["A man wearing a white striped shirt is tying a brown and white tie."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0qYcfEu4heI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1406_0_0"}, {"texts": ["A man wearing a checkered shirt is tying a black neck tie around his neck."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0qYcfEu4heI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1407_0_0"}, {"texts": ["A baby wearing white clothes is lying on the blue cloth, starts yawning and cooing."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1-gAdYe4zSw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1415_0_0"}, {"texts": ["A man wearing a navy blue t-shirt is sitting, licking the ice cream and then giving it to the boy."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0kKfRQWmUHU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1418_0_0"}, {"texts": ["A boy wearing a light blue t-shirt is sitting in the man's lap, licking the ice cream."], "durations": null, "exact_frames_per_prompt": [47], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0kKfRQWmUHU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 51, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1418_1_0"}, {"texts": ["The boy is laughing while the man is licking the boy's ice-cream."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0kKfRQWmUHU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 51, "npz_gt_video_start_frame": 51, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 51, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1418_1_1"}, {"texts": ["A girl wearing a blue t-shirt is sitting and eating noodles."], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-bwMStYyMNI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 41, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1419_0_0"}, {"texts": ["The girl is clapping."], "durations": null, "exact_frames_per_prompt": [39], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-bwMStYyMNI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 41, "npz_gt_video_start_frame": 41, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 41, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1419_0_1"}, {"texts": ["A man wearing a chef dress is standing and frying rolls in a pan and flipping them with a tong."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-k3VNtZJUaM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_141_0_0"}, {"texts": ["A man wearing a white t-shirt is standing and holding a mic."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1BRwWRBtGYg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 27, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1421_0_0"}, {"texts": ["The man is pointing finger towards the soil surface while the others react to it."], "durations": null, "exact_frames_per_prompt": [53], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1BRwWRBtGYg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 27, "npz_gt_video_start_frame": 27, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 27, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1421_0_1"}, {"texts": ["A boy wearing a green t-shirt is standing, eating a burger and drinking water along with other competitors."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1BRwWRBtGYg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1421_2_0"}, {"texts": ["The boy picks something from the soil surface while the boy in left side in brown t-shirt and the girl turns their head and looks at him."], "durations": null, "exact_frames_per_prompt": [8], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1BRwWRBtGYg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 50, "npz_gt_video_start_frame": 50, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 50, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1421_2_1"}, {"texts": ["The boy starts eating it while the boy in right side takes the bottle from the table to drink."], "durations": null, "exact_frames_per_prompt": [3], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1BRwWRBtGYg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 58, "npz_gt_video_start_frame": 58, "npz_gt_video_end_frame": 61, "skip_frames_after_generation": 58, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1421_2_2"}, {"texts": ["A boy wearing a white printed t-shirt is standing while a group of kids is drinking and eating, and a group of people is standing on the brown surface."], "durations": null, "exact_frames_per_prompt": [12], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1BRwWRBtGYg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 16, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1421_3_0"}, {"texts": ["The boy wearing a white printed t-shirt is drinking water while a man wearing a white t-shirt bends downwards and points out towards the brown surface."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1BRwWRBtGYg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 16, "npz_gt_video_start_frame": 16, "npz_gt_video_end_frame": 31, "skip_frames_after_generation": 16, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1421_3_1"}, {"texts": ["The boy wearing a white printed t-shirt puts the bottle on the table again while a boy wearing a green t-shirt bend towards the brown surface and picks up some stuff from the surface and eats it."], "durations": null, "exact_frames_per_prompt": [39], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1BRwWRBtGYg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 31, "npz_gt_video_start_frame": 31, "npz_gt_video_end_frame": 70, "skip_frames_after_generation": 31, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1421_3_2"}, {"texts": ["The boy wearing a white printed t-shirt is holding the bottle and eating a burger."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1BRwWRBtGYg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 70, "npz_gt_video_start_frame": 70, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 70, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1421_3_3"}, {"texts": ["A man in black clothes is holding a mike and he is at first standing near the woman while two men are tightening the chain of the motorbike and a group of people are standing and watching it."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4PDLT41nRZA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 32, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1422_0_0"}, {"texts": ["The man in black clothes is moving here and there."], "durations": null, "exact_frames_per_prompt": [48], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4PDLT41nRZA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 32, "npz_gt_video_start_frame": 32, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 32, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1422_0_1"}, {"texts": ["A man wearing a black t-shirt is standing near the bike and holding the front part of a bike while a man wearing black clothes is holding a mic and talking to a woman, and a group of people are looking at the bike."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4PDLT41nRZA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1422_1_0"}, {"texts": ["A man on the right side is kneeling on the floor, and fixing the rear tire of a bike, and attaching it with the bike chain while a group of people is standing  behind the man and watching him, a few people are standing at the back, another man is standing in front of the bike, another man stands up and walks away, and a man wearing black clothes is standing holding a mic and taking an interview of a woman who is standing and touching the tank of the bike."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4PDLT41nRZA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1422_2_0"}, {"texts": ["A person who is at first sitting near the stage and then stands up while a man wearing black clothes is holding a mic and talking to a woman, and two other men are holding the front and back parts of the bike."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4PDLT41nRZA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 18, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1422_4_0"}, {"texts": ["The person turns around and starts walking while a group of people are looking at the bike."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4PDLT41nRZA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 18, "npz_gt_video_start_frame": 18, "npz_gt_video_end_frame": 41, "skip_frames_after_generation": 18, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1422_4_1"}, {"texts": ["A woman in a black t-shirt is at first speaking to the man on a mic while a man is sitting and he is fixing the bike tyre and another man is holding the bike's front portion."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4PDLT41nRZA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 29, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1422_5_0"}, {"texts": ["The woman is posing while people are standing on the stage."], "durations": null, "exact_frames_per_prompt": [51], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4PDLT41nRZA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 29, "npz_gt_video_start_frame": 29, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 29, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1422_5_1"}, {"texts": ["A girl wearing a white-red checkered shirt, black jeans, and brown boots is standing while holding the first woman's hand."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1wRsP9VYTBE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 27, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1425_3_0"}, {"texts": ["The girl is walking while holding a glass on the brown surface."], "durations": null, "exact_frames_per_prompt": [53], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1wRsP9VYTBE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 27, "npz_gt_video_start_frame": 27, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 27, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1425_3_1"}, {"texts": ["A light brown goat is standing on the left side and looking at the first woman and the girl and a group of people and goats are moving here and there, and some of them are standing."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1wRsP9VYTBE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1425_4_0"}, {"texts": ["A woman wearing a dark purple t-shirt, and blue jeans and black shoes is feeding the food to the big deer while standing on the right side while a group of people are doing different activities, some are standing and some are walking."], "durations": null, "exact_frames_per_prompt": [38], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1wRsP9VYTBE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 17, "npz_gt_video_start_frame": 17, "npz_gt_video_end_frame": 55, "skip_frames_after_generation": 17, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1425_5_0"}, {"texts": ["The woman starts walking to the right side while a sheep is moving to the right side and group of goats are standing on the ground."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1wRsP9VYTBE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 55, "npz_gt_video_start_frame": 55, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 55, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1425_5_1"}, {"texts": ["A big deer is standing on the left side of the brown surface and eating the food given by the second woman and other are moving here and there."], "durations": null, "exact_frames_per_prompt": [55], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1wRsP9VYTBE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 59, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1425_6_0"}, {"texts": ["The deer starts walking towards the right side."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1wRsP9VYTBE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 59, "npz_gt_video_start_frame": 59, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 59, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1425_6_1"}, {"texts": ["A light brown sheep is walking on the brown surface from left to right while a group of people are moving here and there and some animals are moving here and there on the brown surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1wRsP9VYTBE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1425_8_0"}, {"texts": ["A person wearing black clothes is tying the shoelace."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1f0uzBmXElA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1426_0_0"}, {"texts": ["A woman wearing a purple t-shirt is talking in a sigh language."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/6CbEav6UomA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1427_0_0"}, {"texts": ["A girl wearing a printed t-shirt and black jeans is sitting at the other washing machine while holding clothes, and then putting the clothes into the washing machine."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5fdjeWMVscM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1429_0_0"}, {"texts": ["A man wearing a black jacket and blue jeans is sitting on the horse and is horse riding in the straight direction."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3joQORBsR8c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 33, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1431_0_0"}, {"texts": ["The man is riding horse in the backward direction in the shed house."], "durations": null, "exact_frames_per_prompt": [47], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3joQORBsR8c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 33, "npz_gt_video_start_frame": 33, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 33, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1431_0_1"}, {"texts": ["A brown horse is running in the straight direction and then it stops."], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3joQORBsR8c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 35, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1431_1_0"}, {"texts": ["Then the horse is walking in the backward direction while a person is riding on it."], "durations": null, "exact_frames_per_prompt": [45], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3joQORBsR8c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 35, "npz_gt_video_start_frame": 35, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 35, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1431_1_1"}, {"texts": ["A man wearing a black t-shirt is sitting on the chair, keeping one leg on the drawer while holding a plate and eating a hot dog."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4WEPeQYLPfI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1433_0_0"}, {"texts": [" A small boy whose only upper body is visible wearing a blue t-shirt and a white-brown-striped feeding bib, is standing on the left side."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-p_w4ZZpVh4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 27, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1436_0_0"}, {"texts": ["The boy is eating a cake from his mouth while tilting his neck and speaking."], "durations": null, "exact_frames_per_prompt": [53], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-p_w4ZZpVh4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 27, "npz_gt_video_start_frame": 27, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 27, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1436_0_1"}, {"texts": ["A man wearing a white thobe is walking along with the camels."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-chxCS3E9qI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1437_2_0"}, {"texts": ["A man wearing a black suit is walking and moving his hand as a woman wearing a black t-shirt is speaking while holding a mic."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1imVrO0b9GM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1439_1_0"}, {"texts": ["A woman wearing black clothes is sitting on the gray surface and opening the box with her hands."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0s2cFiqUl2M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_144_0_0"}, {"texts": ["A man wearing a white shirt is standing in the front and tying a brown-grey printed tie."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-tj3gU_fMfU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1451_0_0"}, {"texts": ["A boy wearing a red sweatshirt is unpacking a chair base on a beige surface."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-USWJfkof9Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1452_0_0"}, {"texts": ["A girl on the left side wearing green clothes is sitting on a beige surface while another girl wearing a pink-purple top is sitting on the right side and opening a gift."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-koPqEecDtY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 34, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1453_0_0"}, {"texts": ["The girl wearing green clothes is opening a gift box while a person wearing black clothing is sitting on a sofa."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-koPqEecDtY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 34, "npz_gt_video_start_frame": 34, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 34, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1453_0_1"}, {"texts": ["A girl on the right side is opening a gift box and sitting on a beige surface.\n while a girl sitting on the left is looking at the girl on the right and removing the wraps of the gift."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-koPqEecDtY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1453_1_0"}, {"texts": ["A man wearing a vest is standing and picking an object from a container and putting it in the glasses."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3JKOc-rtfYA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1454_0_ms_0"}, {"texts": ["A man wearing a white printed t-shirt is holding a rod and dragging it into the sea water to catch the fish while another man wearing a white t-shirt and hat is standing on the left side, holding a fishing rod."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0WNprz_EwiQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 34, "npz_gt_video_start_frame": 34, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 34, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1455_0_0"}, {"texts": ["A man wearing a beige colored hat is pulling the fishing rod in an up-ward direction while a person wearing white and grey outfit is standing in a bending position on a boat."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0WNprz_EwiQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 42, "npz_gt_video_start_frame": 42, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 42, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1455_1_0"}, {"texts": ["A man wearing white blue clothes is standing and wrapping a box with colored paper."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1qi8ZXUH_wY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1456_0_0"}, {"texts": ["A man wearing white black cloth is standing and holding a paper while another old man is wrapping a box with the red and while colored paper"], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1qi8ZXUH_wY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 19, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1456_1_0"}, {"texts": ["The man is moving towards the left side and the old attached piece of tape to the box and folding with the red and white paper"], "durations": null, "exact_frames_per_prompt": [61], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1qi8ZXUH_wY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 19, "npz_gt_video_start_frame": 19, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 19, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1456_1_1"}, {"texts": ["A man wearing a navy blue blazer is standing and wrapping a white and blue box with his hands while another man in a black blazer holds the paper and walks away and some people are walking on the right side."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1qi8ZXUH_wY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1457_0_0"}, {"texts": ["A man wearing a black jacket and black pants is standing on the left side of the first man and moving his hands while the first man wearing a green sweatshirt is standing while holding a golf club and looking at the second man."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0V8kH1EDmpU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 25, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1458_1_0"}, {"texts": ["The man is sitting on the left side of the third man and holding the stick while the third man wearing blue pants is standing while holding a gold club."], "durations": null, "exact_frames_per_prompt": [55], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0V8kH1EDmpU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 25, "npz_gt_video_start_frame": 25, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 25, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1458_1_1"}, {"texts": ["A man wearing a yellow striped blue t-shirt and blue pants is standing on the right side of the second man and holding a golf stick while the man in black pants is sitting and talking to him."], "durations": null, "exact_frames_per_prompt": [56], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0V8kH1EDmpU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 24, "npz_gt_video_start_frame": 24, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 24, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1458_2_0"}, {"texts": ["A person wearing a black cloth is standing and peeling the potato."], "durations": null, "exact_frames_per_prompt": [34], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2LzWCwYtUzs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 38, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1459_0_0"}, {"texts": ["The person is washing the potato in the big glass bowl."], "durations": null, "exact_frames_per_prompt": [42], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2LzWCwYtUzs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 38, "npz_gt_video_start_frame": 38, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 38, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1459_0_1"}, {"texts": ["A man wearing black t-shirt is standing."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1LF4BrYt4wY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 30, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1464_0_0"}, {"texts": ["The man is showing a white bottle."], "durations": null, "exact_frames_per_prompt": [50], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1LF4BrYt4wY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 30, "npz_gt_video_start_frame": 30, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 30, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1464_0_1"}, {"texts": ["A woman whose only hands are visible is holding a knife and applying buttercream on a cake."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/134j3CCEsQM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1466_0_0"}, {"texts": ["A girl wearing a red top is scratching her head while the boy in black pants watching the toy."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1elitRm1sK4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 21, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1467_1_0"}, {"texts": ["The girl standing and moving on the floor."], "durations": null, "exact_frames_per_prompt": [59], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1elitRm1sK4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 21, "npz_gt_video_start_frame": 21, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 21, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1467_1_1"}, {"texts": ["A kid, who is a boy, wearing a dark red t-shirt and spectacles is standing behind the gray countertop and spreading pizza sauce on the pizza base with the ladle."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0KAuR2nsIj4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_146_0_0"}, {"texts": ["A boy wearing a green-white printed t-shirt is sitting on a bed."], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/8IZfazDanKI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 35, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1473_0_0"}, {"texts": ["The boy is opening a newspaper."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/8IZfazDanKI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 35, "npz_gt_video_start_frame": 35, "npz_gt_video_end_frame": 63, "skip_frames_after_generation": 35, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1473_0_1"}, {"texts": ["The boy starts tapping on the newspaper."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/8IZfazDanKI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 63, "npz_gt_video_start_frame": 63, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 63, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1473_0_2"}, {"texts": ["A person wearing a green shirt is squeezing the white sauce on the bread and the meat."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-i2wIUzvEYI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1477_0_0"}, {"texts": ["A boy wearing an orange t-shirt and blue jeans is sitting on the right side, speaking while opening the gift wrapped paper, and smiling while holding a book while a group of people are sitting and watching the boy."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-kRj53ftJnU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1478_1_0"}, {"texts": ["A baby wearing an orange-striped gray t-shirt and gray shorts is sitting on the woman's lap a baby wearing an orange t-shirt is sitting and opening a book, and group of people are sitting behind the baby and looking at it."], "durations": null, "exact_frames_per_prompt": [57], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-kRj53ftJnU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 61, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1478_3_0"}, {"texts": ["The baby starts holding a wrapping paper with his hand a woman is sitting and looking at the right side."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-kRj53ftJnU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 61, "npz_gt_video_start_frame": 61, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 61, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1478_3_1"}, {"texts": ["A man wearing a gray shirt is sitting on the dining table and holding his cap."], "durations": null, "exact_frames_per_prompt": [71], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-KpXV80cC8M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 9, "npz_gt_video_start_frame": 9, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 9, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1479_1_0"}, {"texts": ["A woman wearing a white top and white trousers with a gray floral design is lying and getting microblading by another woman."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0rbCqeVfTBI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1480_0_0"}, {"texts": ["A woman wearing a white doctor uniform is sitting and microblading the eyebrows of the first woman."], "durations": null, "exact_frames_per_prompt": [52], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0rbCqeVfTBI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 56, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1480_1_0"}, {"texts": ["A woman wearing sky blue clothes is lying on a surface and getting eyebrows brushed by another woman."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0rbCqeVfTBI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1481_0_0"}, {"texts": ["A woman wearing white clothes is sitting and brushing the eyebrows of the first woman."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0rbCqeVfTBI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1481_1_0"}, {"texts": ["A person wearing a black cap is sitting and holding a fish and a fishing rod with his hands."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/432wdISAiaQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1483_0_0"}, {"texts": ["A woman on the right side is sitting on a pink and blue seat and talking to the man facing left while holding a fork while a woman in black-white checked cloth is sitting next to the woman, eating something, and a person is standing at the back."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/07u-CPz93rQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1489_1_0"}, {"texts": ["A woman wearing spectacles sitting with the first woman is eating some dessert from a plate a man is sitting and speaking."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/07u-CPz93rQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1489_2_0"}, {"texts": ["A man wearing a blue-white jacket is sitting and rotating the car jack."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2xTzdb3xHSc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 34, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1490_0_0"}, {"texts": ["The man stands up and starts screwing the car wheel."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2xTzdb3xHSc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 34, "npz_gt_video_start_frame": 34, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 34, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1490_0_1"}, {"texts": ["A man wearing a blue t-shirt is bending on the left side of the second woman and watching the second man, who is trying to catch a fish and another woman in a black outfit is standing on the left side and watching them."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0A6a_oKa8mc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1491_2_0"}, {"texts": ["A man wearing a white shirt is standing on the left side of the first man, holding a fishing rod and trying to catch a fish while a woman wearing a purple t-shirt and another woman wearing black clothes are standing on the white boat."], "durations": null, "exact_frames_per_prompt": [73], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0A6a_oKa8mc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 77, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1491_3_0"}, {"texts": ["A woman wearing a sky-blue t-shirt on the left side is standing and pulling other woman's head down."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2j8zidMcXPA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 27, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1492_0_0"}, {"texts": ["The woman apply cake on her face."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2j8zidMcXPA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 27, "npz_gt_video_start_frame": 27, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 27, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1492_0_1"}, {"texts": ["The woman starts eating cake from the plate another woman starts eating cake from the plate."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2j8zidMcXPA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 40, "npz_gt_video_start_frame": 40, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 40, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1492_0_2"}, {"texts": ["A woman wearing a black t-shirt on the right side is standing and eating cake along with the first woman."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2j8zidMcXPA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1492_1_0"}, {"texts": ["A man wearing a black t-shirt and blue jeans is riding a horse and waving his cap while a man wearing a cap is standing, holding a camera, and recording the man's activity."], "durations": null, "exact_frames_per_prompt": [71], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-kd_rdZ9Xaw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 75, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1496_0_0"}, {"texts": ["A brown horse is running on sand surface while a man in black T-shirt sits on horse and removes the cap from head and riding."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-kd_rdZ9Xaw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1496_1_0"}, {"texts": ["A man wearing a white jacket is standing and pulling threads from a pink mattress."], "durations": null, "exact_frames_per_prompt": [58], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/IztcW1J_pUE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 22, "npz_gt_video_start_frame": 22, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 22, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1497_0_0"}, {"texts": ["A black and white cat, sitting on a blanket is sleeping."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2aIXpCUMon0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 27, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1498_0_0"}, {"texts": ["The black and white cat is being caressed by a person."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2aIXpCUMon0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 27, "npz_gt_video_start_frame": 27, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 27, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1498_0_1"}, {"texts": ["A person whose only hand is visible is caressing the black and white cat."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2aIXpCUMon0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 24, "npz_gt_video_start_frame": 24, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 24, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1498_1_0"}, {"texts": ["A person whose hand is visible, is coming from the left and starts touching the cat."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2aIXpCUMon0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 24, "npz_gt_video_start_frame": 24, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 24, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1499_0_0"}, {"texts": ["A black and white cat is lying on the gray-white bed."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2aIXpCUMon0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 30, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1499_1_0"}, {"texts": ["The person starts touching the cat."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2aIXpCUMon0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 30, "npz_gt_video_start_frame": 30, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 30, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1499_1_1"}, {"texts": ["A man wearing a dark-colored shirt is standing, holding a knife in his left hand and picking the pineapples from the table, and putting them on wooden cardboard."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/29BV21mCC0M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1503_0_0"}, {"texts": ["A man wearing black shirt is sitting with a spoon in his hand, picking up."], "durations": null, "exact_frames_per_prompt": [54], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1cYd7mmJpZg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1504_0_0"}, {"texts": ["The man is eating food."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1cYd7mmJpZg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 58, "npz_gt_video_start_frame": 58, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 58, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1504_0_1"}, {"texts": ["A woman wearing white-black clothes is standing"], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1sCZZv7WQuM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 30, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1508_0_0"}, {"texts": ["The woman wearing white-black clothes is ironing a white cloth with a white iron."], "durations": null, "exact_frames_per_prompt": [49], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1sCZZv7WQuM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 30, "npz_gt_video_start_frame": 30, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 30, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1508_0_1"}, {"texts": ["A girl wearing a black top is standing on the left side."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1sCZZv7WQuM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 31, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1509_0_0"}, {"texts": ["The girl is ironing a white cloth with an iron on a gray ironing board."], "durations": null, "exact_frames_per_prompt": [49], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1sCZZv7WQuM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 31, "npz_gt_video_start_frame": 31, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 31, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1509_0_1"}, {"texts": ["A lady wearing a blue t-shirt is attaching a milk sucking machine into the tears of goats."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0WDRWysQK2k.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1510_0_0"}, {"texts": ["A man wearing a white jacket is sitting on the right side, and holding a fork while a woman whose hand is visible is wearing a brown jacket, holding a fork, and moving her hand."], "durations": null, "exact_frames_per_prompt": [66], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0yyXWU6JKtc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 70, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1515_0_0"}, {"texts": ["The man is eating food from a plate."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0yyXWU6JKtc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 70, "npz_gt_video_start_frame": 70, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 70, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1515_0_1"}, {"texts": ["A woman whose hand is visible is holding a fork and picking food from a plate while a person on the right wearing white jacket is eating."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0yyXWU6JKtc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1515_1_0"}, {"texts": ["A woman wearing a pink vest is sitting, holding a tube."], "durations": null, "exact_frames_per_prompt": [8], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0AqWASz_kWs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 12, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1518_0_0"}, {"texts": ["The woman wearing a pink vest presses it, takes the cream out."], "durations": null, "exact_frames_per_prompt": [47], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0AqWASz_kWs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 12, "npz_gt_video_start_frame": 12, "npz_gt_video_end_frame": 59, "skip_frames_after_generation": 12, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1518_0_1"}, {"texts": ["The woman wearing a pink vest puts the tube away and shows the cream on her hand."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0AqWASz_kWs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 59, "npz_gt_video_start_frame": 59, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 59, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1518_0_2"}, {"texts": ["A boy wearing a white t-shirt and white shorts is sitting on the stool and washing clothes while putting clothes in the tub."], "durations": null, "exact_frames_per_prompt": [61], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2EVwbnZT7OE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 65, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1519_0_0"}, {"texts": ["A person whom half body is visible is standing."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5hpJitgVpAE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 18, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1520_0_0"}, {"texts": ["The person is making sushi from a sushi making wooden mold."], "durations": null, "exact_frames_per_prompt": [62], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5hpJitgVpAE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 18, "npz_gt_video_start_frame": 18, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 18, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1520_0_1"}, {"texts": ["A girl wearing a graphic black t-shirt is sitting on a chair and getting a tattoo on her right arm while a man wearing white gloves is making a tattoo on the left arm of the woman."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0yi-nkwLEnI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1521_0_0"}, {"texts": ["A man wearing a black t-shirt and white gloves is making a tattoo on the right arm of the girl."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0yi-nkwLEnI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1521_1_0"}, {"texts": ["A girl wearing black designer vest is sitting on a chair and getting a tattoo on her right arm while a man wearing gloves is making the tattoo on the woman's arm."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0yi-nkwLEnI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1522_0_0"}, {"texts": ["A man wearing a black t-shirt is making a tattoo on the girl's left arm."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0yi-nkwLEnI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1522_1_0"}, {"texts": ["A boy wearing green t-shirt is sitting and he is eating a doughnut while a boy in a brown patterned t-shirt picks up a donut, sits down, and starts eating it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2uJyGgx8_24.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1530_0_0"}, {"texts": ["A boy wearing white and grey striped t-shirt takes the doughnut."], "durations": null, "exact_frames_per_prompt": [56], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2uJyGgx8_24.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 60, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1530_1_0"}, {"texts": ["The boy wearing white and grey striped t-shirt starts eating while the other boy is also eating"], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2uJyGgx8_24.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 60, "npz_gt_video_start_frame": 60, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 60, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1530_1_1"}, {"texts": ["A man wearing a checkered shirt is holding a book and is speaking."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1DTd-OJa1eA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1533_0_0"}, {"texts": ["A man wearing a blue-gray lining shirt is sitting, speaking, and showing a book."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1DTd-OJa1eA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1534_0_0"}, {"texts": ["A baby wearing a red shirt is sitting on the baby's chair and eating food while moving her hands.  while a person whose hands are visible is feeding the baby with a yellow spoon."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0qcwqmkRLaw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1535_0_0"}, {"texts": ["A woman whose only hands are visible, feeding food to a baby with the spoon."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0qcwqmkRLaw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1535_1_0"}, {"texts": ["A woman whose only upper half-body is visible wearing a black t-shirt is sitting on a chair on the left side and touching the girl's hair while group of people are sitting on chairs and doing different activities."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0AHW5Xlyi3A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 33, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1539_0_0"}, {"texts": ["The woman is pouring the food material on the bread."], "durations": null, "exact_frames_per_prompt": [47], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0AHW5Xlyi3A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 33, "npz_gt_video_start_frame": 33, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 33, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1539_0_1"}, {"texts": ["A woman whose only upper half-body is visible wearing a green top is sitting on a chair on the right side and is spreading the red sauce on the bread while a group of kids and a woman holding them are spreading the red sauce on the bread."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0AHW5Xlyi3A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 33, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1539_2_0"}, {"texts": ["The woman is pouring the white food material on the bread a group of kids and women are pouring the white food material on the bread."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0AHW5Xlyi3A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 33, "npz_gt_video_start_frame": 33, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 33, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1539_2_1"}, {"texts": ["A boy wearing a black t-shirt and red shorts is sitting on a chair on the right side while holding a spatula while two kids are sitting and holding spatula and taking food for a bowl, and a group of women are sitting and watching them."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0AHW5Xlyi3A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 33, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1539_3_0"}, {"texts": ["The boy wearing a black t-shirt and red shorts is holding a white cream butter."], "durations": null, "exact_frames_per_prompt": [47], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0AHW5Xlyi3A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 33, "npz_gt_video_start_frame": 33, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 33, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1539_3_1"}, {"texts": ["A boy wearing a white t-shirt and dark green shorts is sitting on a chair along with other people."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0AHW5Xlyi3A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 20, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1539_4_0"}, {"texts": ["The boy is holding a spatula and pouring the spatula into the bowl while the girl and right side woman spread the sauce on the bread."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0AHW5Xlyi3A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 20, "npz_gt_video_start_frame": 20, "npz_gt_video_end_frame": 34, "skip_frames_after_generation": 20, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1539_4_1"}, {"texts": ["The boy is then pouring the white food material on the bread along with other people."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0AHW5Xlyi3A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 34, "npz_gt_video_start_frame": 34, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 34, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1539_4_2"}, {"texts": ["A lady wearing a black dress lifts a chicken piece with silver tongs and checks the temperature of the chicken piece with a food thermometer."], "durations": null, "exact_frames_per_prompt": [64], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-gRYGmwgGd4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 68, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1545_0_0"}, {"texts": ["A person is holding a fried chicken piece with a tong and checking its temperature then a woman wearing a black chef's coat is speaking while facing forward."], "durations": null, "exact_frames_per_prompt": [64], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-gRYGmwgGd4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 68, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1546_0_0"}, {"texts": ["A woman wearing a black chef coat is speaking facing front while a person whose hands are visible is holding a chicken piece and checking its temperature."], "durations": null, "exact_frames_per_prompt": [64], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-gRYGmwgGd4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 68, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1546_1_0"}, {"texts": ["A person wearing black shoes is shearing a grey sheep on a green grass surface."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0cyNPIGScbA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1547_0_0"}, {"texts": ["A person of whom only hand is visible is holding a white paper with words on it while a group of people are walking and two people are sitting on chairs, a man wearing a gray t-shirt is standing and opening a can and drinking from it, and a group of vehicles are moving in different directions."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/8VXOxaT2Us0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1559_2_0"}, {"texts": ["A man wearing a dark gray t-shirt, white pants, and dark blue shoes is standing while holding a bottle in his hands while another man holding a poster and moves down."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/8VXOxaT2Us0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 24, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1559_3_0"}, {"texts": ["The man opening the bottle cap. and then starts drinking from the bottle while a man in a blue T-shirt watching him"], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/8VXOxaT2Us0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 24, "npz_gt_video_start_frame": 24, "npz_gt_video_end_frame": 46, "skip_frames_after_generation": 24, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1559_3_1"}, {"texts": ["The man then starts drinking from the bottle."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/8VXOxaT2Us0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 46, "npz_gt_video_start_frame": 46, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 46, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1559_3_2"}, {"texts": ["A man wearing white-black clothes is standing on the sidewalk while a group of vehicles is moving in different directions, in a group of people, two of them are sitting on the chairs, one is walking towards the right, and a woman wearing a blue t-shirt is standing on the right side."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/8VXOxaT2Us0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1559_4_0"}, {"texts": ["A girl wearing a purple graphic t-shirt and yellow trousers is sitting on the floor, showing a book and speaking."], "durations": null, "exact_frames_per_prompt": [70], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-jPJvKYKkqo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 74, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1561_0_0"}, {"texts": ["A person whom hands and hair are visible is folding his white shirt."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0pSJ1kAkawU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1562_0_0"}, {"texts": ["A person wearing a white t-shirt is folding clothes."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0pSJ1kAkawU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1563_0_0"}, {"texts": ["A bald man wearing a black shirt is sitting, talking, and moving his hand."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2jJBLg_O5Y8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1566_0_0"}, {"texts": ["A man wearing a white-blue t-shirt is sitting and drinking something from the cup."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2jJBLg_O5Y8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 27, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1566_1_ms_0"}, {"texts": ["A woman wearing an orange top is sitting drinking something from the cup and talking while the other person watches her."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2jJBLg_O5Y8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 64, "npz_gt_video_start_frame": 64, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 64, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1566_3_0"}, {"texts": ["A baby wearing orange clothes is sitting and watching the newspaper on a brown table."], "durations": null, "exact_frames_per_prompt": [75], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/65cgE8eXyrk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 79, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1569_0_0"}, {"texts": ["A girl wearing orange clothes is sitting on a chair and watching the newspaper on a brown table."], "durations": null, "exact_frames_per_prompt": [75], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/65cgE8eXyrk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 79, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1570_0_0"}, {"texts": ["A person, whose only hand is visible, wearing a gray cloth is holding a fruit while a person wearing blue clothes is standing in the backside holding a camera and taking pictures."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1Y-093zNUYw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 52, "npz_gt_video_start_frame": 52, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 52, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1572_3_0"}, {"texts": ["A person whose hand is visible is mixing brown liquid in a white-blue cup with a spoon."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3-wGSNUMoIM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 36, "npz_gt_video_start_frame": 36, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 36, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1576_0_0"}, {"texts": ["The person is mixing light-yellow liquid in a white cup with the spoon."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3-wGSNUMoIM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 50, "npz_gt_video_start_frame": 50, "npz_gt_video_end_frame": 67, "skip_frames_after_generation": 50, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1576_0_1"}, {"texts": ["A person wearing pink striped trousers is at first hitting the golf ball with a golf stick."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-IOJwNb02fA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 33, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1579_0_0"}, {"texts": ["The person picks up another golf ball."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-IOJwNb02fA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 33, "npz_gt_video_start_frame": 33, "npz_gt_video_end_frame": 62, "skip_frames_after_generation": 33, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1579_0_1"}, {"texts": ["The person takes position to hit it with a golf stick."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-IOJwNb02fA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 62, "npz_gt_video_start_frame": 62, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 62, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1579_0_2"}, {"texts": ["A woman wearing white-black clothes is lying on the gray bed and is getting tattooed by a man while a person wearing black clothes is standing."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/09GcDW_bbg0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1580_0_0"}, {"texts": ["A man wearing white clothes is holding a pen and making a tattoo on the leg of the woman while a person wearing black clothes is standing."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/09GcDW_bbg0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1580_1_0"}, {"texts": ["A girl wearing a gray t-shirt is sitting and applying makeup on her eyebrow with a brush."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0dh0SVaws_E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1584_0_0"}, {"texts": ["A person wearing white clothes is standing on the right side of the machine and folding a paper."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/11JpwKsubmc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1586_0_0"}, {"texts": ["A man in an army dress is sitting and looking to the right while speaking while another man wearing grey outfit is sitting on the right side of first man and he is eating something."], "durations": null, "exact_frames_per_prompt": [57], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5GNA1wOpfPk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 18, "npz_gt_video_start_frame": 18, "npz_gt_video_end_frame": 75, "skip_frames_after_generation": 18, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1587_1_0"}, {"texts": ["A man wearing a brown shirt is sitting, and eating sesame cake."], "durations": null, "exact_frames_per_prompt": [45], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5GNA1wOpfPk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 49, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1588_1_0"}, {"texts": ["The man starts talking."], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5GNA1wOpfPk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 49, "npz_gt_video_start_frame": 49, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 49, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1588_1_1"}, {"texts": ["A woman whose only hands are visible is folding a white envelope from the corner to the center line."], "durations": null, "exact_frames_per_prompt": [64], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1FCzkG5Z1Lg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 16, "npz_gt_video_start_frame": 16, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 16, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1589_0_0"}, {"texts": ["A woman whose hands are visible is folding a white paper sheet."], "durations": null, "exact_frames_per_prompt": [64], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1FCzkG5Z1Lg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 16, "npz_gt_video_start_frame": 16, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 16, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1590_0_0"}, {"texts": ["A girl wearing a grey-blue jacket with red stripes is sitting inside a car."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0J2hIKBCSDg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 27, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1596_0_0"}, {"texts": ["The girl starts eating chips."], "durations": null, "exact_frames_per_prompt": [53], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0J2hIKBCSDg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 27, "npz_gt_video_start_frame": 27, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 27, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1596_0_1"}, {"texts": ["A person whose hands are visible is peeling a potato."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2M_mheOleKA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1597_0_0"}, {"texts": ["The person puts it on the cutting board."], "durations": null, "exact_frames_per_prompt": [8], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2M_mheOleKA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 40, "npz_gt_video_start_frame": 40, "npz_gt_video_end_frame": 49, "skip_frames_after_generation": 40, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1597_0_1"}, {"texts": ["The person lifts the knife."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2M_mheOleKA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 49, "npz_gt_video_start_frame": 49, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 49, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1597_0_2"}, {"texts": ["A woman whose hands are visible is peeling the purple sweet potato with the potato peeler utensil."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2M_mheOleKA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 32, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1598_0_0"}, {"texts": ["The woman sides the sweet potato peels."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2M_mheOleKA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 32, "npz_gt_video_start_frame": 32, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 32, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1598_0_1"}, {"texts": ["The woman is picking up the knife with her right hand and holding a sweet potato in her left hand on the table."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2M_mheOleKA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 50, "npz_gt_video_start_frame": 50, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 50, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1598_0_2"}, {"texts": ["A woman wearing a white shirt is sitting on a black chair, holding an opened book and pointing at the book while showing it in front and speaking."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-XlUXlF_8sc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1600_0_0"}, {"texts": ["A person whose only hands are visible is folding the bank note into a triangular shape."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0-y-znu_-vw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1602_0_0"}, {"texts": ["A person whose hand is visible is holding a marker and writing on a white board."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1atLOEBiXzs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1604_0_0"}, {"texts": ["A baby wearing a red t-shirt is eating while sitting on a red chair while the woman is feeding the baby."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1OOkguyr8zw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1605_0_0"}, {"texts": ["The baby starts walking on a beige surface."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1OOkguyr8zw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 50, "npz_gt_video_start_frame": 50, "npz_gt_video_end_frame": 77, "skip_frames_after_generation": 50, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1605_0_1"}, {"texts": ["A woman wearing blue pants is sitting on a chair while a baby wearing a red t-shirt is sitting on another chair."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1OOkguyr8zw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 14, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1605_1_0"}, {"texts": ["The woman wearing blue pants is feeding something to a baby."], "durations": null, "exact_frames_per_prompt": [63], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1OOkguyr8zw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 14, "npz_gt_video_start_frame": 14, "npz_gt_video_end_frame": 77, "skip_frames_after_generation": 14, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1605_1_1"}, {"texts": ["A woman wearing black clothes is lying and laughing and talking."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-9Ccqyo9bzw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1607_0_0"}, {"texts": ["A man wrapped in a black sheet is eating a watermelon that is kept on a table with is mouth."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2VYtvaXujSE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_160_0_0"}, {"texts": ["A woman wearing a yellow t-shirt and brown tights is standing on a green grass field, holding a golf club."], "durations": null, "exact_frames_per_prompt": [70], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1fp_39s2cvg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 74, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1611_0_0"}, {"texts": ["The woman is moving it back to hit a golf ball."], "durations": null, "exact_frames_per_prompt": [6], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1fp_39s2cvg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 74, "npz_gt_video_start_frame": 74, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 74, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1611_0_1"}, {"texts": ["A man wearing a white t-shirt is standing and drinking."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/70_3beY6Boo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 17, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1612_0_0"}, {"texts": ["The man starts vomiting."], "durations": null, "exact_frames_per_prompt": [63], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/70_3beY6Boo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 17, "npz_gt_video_start_frame": 17, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 17, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1612_0_1"}, {"texts": ["A man wearing a blue shirt is sitting and tapping on the newspaper while holding a baby while the baby is turning the pages of news paper."], "durations": null, "exact_frames_per_prompt": [38], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1bxgd3_srgU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 42, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1615_0_0"}, {"texts": ["A woman sitting opposite person one is looking at the baby while the baby is turning the paper page."], "durations": null, "exact_frames_per_prompt": [38], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1bxgd3_srgU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 42, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1615_1_0"}, {"texts": ["A man wearing white clothes is holding a snake around his neck and he is at first looking in the left direction while speaking, then he looks at the snake."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5Rtkyr2T_Ro.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_161_0_0"}, {"texts": ["A greyish green colored snake is held by a man around his neck."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5Rtkyr2T_Ro.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_161_1_0"}, {"texts": ["A brown-white-black dog tied with a leash is walking on the green grass surface and on the grey road."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/08gIDD85azQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1623_0_0"}, {"texts": ["A fish is being caught while a boy whose head is visible is standing in front."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0QrJg_OGVfE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 48, "npz_gt_video_start_frame": 48, "npz_gt_video_end_frame": 72, "skip_frames_after_generation": 48, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1628_3_0"}, {"texts": ["The fish is being pulled out of the water."], "durations": null, "exact_frames_per_prompt": [8], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0QrJg_OGVfE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 72, "npz_gt_video_start_frame": 72, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 72, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1628_3_1"}, {"texts": ["A woman wearing a camouflage t-shirt is mixing a yellow liquid and speaking."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/21pDj2CR75M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1631_0_0"}, {"texts": ["A woman wearing a blue t-shirt is standing and holding the bottle with another girl."], "durations": null, "exact_frames_per_prompt": [45], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/324KYNOHS6Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 35, "npz_gt_video_start_frame": 35, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 35, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1633_1_0"}, {"texts": ["A girl whose only hands are visible is holding the bottle with the woman."], "durations": null, "exact_frames_per_prompt": [45], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/324KYNOHS6Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 35, "npz_gt_video_start_frame": 35, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 35, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1633_2_ms_0"}, {"texts": ["A woman wearing a gray t-shirt is applying makeup on her right eyebrow."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0YW9slPyVtU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1635_0_0"}, {"texts": ["A man wearing white clothes is juggling with bottles on the stage while a man wearing a white t-shirt is standing in front, holding a mic, a group of people is standing and watching him, and a few people are recording him."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2rEdUUvNYOs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1637_0_0"}, {"texts": ["A man wearing a black t-shirt is standing on the stage and holding a white object in his hand while another man wearing a white t-shirt is performing juggling with bottles on the stage and moving."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2rEdUUvNYOs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1637_1_0"}, {"texts": ["A man wearing a cap is speaking, standing, and holding a microphone in his hand while a man in a white t-shirt is performing bartending, a group of people are watching him and some of them are clapping."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2rEdUUvNYOs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1637_3_0"}, {"texts": ["A man wearing a white t-shirt is standing and recording the juggling performance while a man wearing a hat is standing while holding a microphone in his hand and speaking."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2rEdUUvNYOs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1637_4_0"}, {"texts": ["A man wearing a black sweatshirt, blue jeans and yellow-black hat is sitting near the table and eating the food."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-X094A_ynWs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1638_0_0"}, {"texts": ["A person whose hands are visible is scratching the packet."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1byIuPsTD4o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 27, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1642_0_0"}, {"texts": ["The person is holding the packet."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1byIuPsTD4o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 27, "npz_gt_video_start_frame": 27, "npz_gt_video_end_frame": 41, "skip_frames_after_generation": 27, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1642_0_1"}, {"texts": ["The person is putting their hands on it."], "durations": null, "exact_frames_per_prompt": [39], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1byIuPsTD4o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 41, "npz_gt_video_start_frame": 41, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 41, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1642_0_2"}, {"texts": ["A person wearing shorts puts a lid on the weber kettle grill."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2TUJ-ULecDE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1643_0_0"}, {"texts": ["The person lifts the lid and starts touching the sausage with a tong."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2TUJ-ULecDE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 50, "npz_gt_video_start_frame": 50, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 50, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1643_0_1"}, {"texts": ["A woman whose upper half-body is visible wearing a black tank-top is looking left and up while smiling."], "durations": null, "exact_frames_per_prompt": [74], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2LL6SXh_Cjk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 6, "npz_gt_video_start_frame": 6, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 6, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1644_1_ms_0"}, {"texts": ["A man wearing a black t-shirt and black jeans is standing and looking down while moving his body."], "durations": null, "exact_frames_per_prompt": [47], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2LL6SXh_Cjk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 6, "npz_gt_video_start_frame": 6, "npz_gt_video_end_frame": 53, "skip_frames_after_generation": 6, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1644_5_0"}, {"texts": ["A man wearing a white t-shirt is touching the tree, and plucking an apple from the tree while a girl wearing a black and white dress is standing on a grassy surface and putting apples into a plastic bag."], "durations": null, "exact_frames_per_prompt": [59], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-B14kmeX4EI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 63, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1646_0_0"}, {"texts": ["The man is giving apple to the girl."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-B14kmeX4EI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 63, "npz_gt_video_start_frame": 63, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 63, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1646_0_1"}, {"texts": ["A girl is standing, holding a carry bag full of apples while a man in brown shorts is standing and picking apples from the tree and giving them to the girl."], "durations": null, "exact_frames_per_prompt": [60], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-B14kmeX4EI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 64, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1646_1_0"}, {"texts": ["The girl is taking an apple from the man."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-B14kmeX4EI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 64, "npz_gt_video_start_frame": 64, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 64, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1646_1_1"}, {"texts": ["A man wearing a black t-shirt is standing."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3RFfz4X4SBg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1647_0_0"}, {"texts": ["The man is pouring a meat piece into the food and then pressing the meat piece."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3RFfz4X4SBg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 44, "npz_gt_video_start_frame": 44, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 44, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1647_0_1"}, {"texts": ["A person wearing a black t-shirt is standing and opening a yellow envelope."], "durations": null, "exact_frames_per_prompt": [47], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-a3lfKV4tEE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 33, "npz_gt_video_start_frame": 33, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 33, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1648_0_0"}, {"texts": ["A baby wearing a yellow cloth is lying on the baby bed."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/067FgZFiyNQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 31, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1649_0_0"}, {"texts": ["The baby starts crying."], "durations": null, "exact_frames_per_prompt": [49], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/067FgZFiyNQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 31, "npz_gt_video_start_frame": 31, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 31, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1649_0_1"}, {"texts": ["A man wearing a white-black t-shirt is sitting on a camel while another man in a white outfit is standing and holding a leash of the camel and then moves towards the right."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0yAa3oIB0TI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1652_0_0"}, {"texts": ["A brown camel is standing and moving while a man wearing a wearing a white cap is sitting on the camel back is speaking while showing thumps up and then the another man starts pulling the camel leash and walks toward the right."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0yAa3oIB0TI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1652_1_0"}, {"texts": ["A man wearing a white dishdasha is standing, holding the camel leash while a man wearing a black-white t-shirt is sitting on the back of the camel and showing his hand."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0yAa3oIB0TI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 30, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1652_2_0"}, {"texts": ["The man is moving."], "durations": null, "exact_frames_per_prompt": [50], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0yAa3oIB0TI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 30, "npz_gt_video_start_frame": 30, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 30, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1652_2_1"}, {"texts": ["A girl wearing white clothes is eating something."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2-slSV1Uakc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 25, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1653_0_0"}, {"texts": ["The girl is making faces."], "durations": null, "exact_frames_per_prompt": [55], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2-slSV1Uakc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 25, "npz_gt_video_start_frame": 25, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 25, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1653_0_1"}, {"texts": ["A man wearing a white chef coat is standing near cooked meat"], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0g-1i2ZSnwU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 20, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1655_0_0"}, {"texts": ["The man is showing thumbs up."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0g-1i2ZSnwU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 20, "npz_gt_video_start_frame": 20, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 20, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1655_0_1"}, {"texts": ["A person whose hand is visible is holding a bowl and putting egg yolk in a frying pan."], "durations": null, "exact_frames_per_prompt": [45], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/12_f_NEzN9o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 11, "npz_gt_video_start_frame": 11, "npz_gt_video_end_frame": 56, "skip_frames_after_generation": 11, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1656_0_0"}, {"texts": ["A woman wearing a white-blue checked shirt is standing on the left side of the horse and combing the hair of the horse."], "durations": null, "exact_frames_per_prompt": [54], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-wa9wu7bCJ0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1657_0_ms_0"}, {"texts": ["A brown horse is standing on the right side of the first woman and getting his hair combed by that woman."], "durations": null, "exact_frames_per_prompt": [54], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-wa9wu7bCJ0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1657_1_0"}, {"texts": ["A brown horse is standing on the soil surface with another woman who is sitting on his back.\n"], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-wa9wu7bCJ0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 58, "npz_gt_video_start_frame": 58, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 58, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1657_3_ms_0"}, {"texts": ["A person whose fingers are visible is deep frying the onion ring with the spatula and straining the onion ring from the spatula, then showing the onion ring on the frying steel strainer."], "durations": null, "exact_frames_per_prompt": [47], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/34Aj4geYWS4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 51, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_165_0_0"}, {"texts": ["A man wearing a light colored cap is sitting on a black horse."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4V_1792oiT4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 34, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1660_0_0"}, {"texts": ["The man wearing a light colored cap is throwing his cap while the black horse is jumping on the brown surface."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4V_1792oiT4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 34, "npz_gt_video_start_frame": 34, "npz_gt_video_end_frame": 43, "skip_frames_after_generation": 34, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1660_0_1"}, {"texts": ["A black horse is jumping while lifting man one on the back."], "durations": null, "exact_frames_per_prompt": [39], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4V_1792oiT4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 43, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1660_2_0"}, {"texts": ["A man wearing a striped t-shirt is hitting the golf ball with the golf stick."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-cIRzJUnZTw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 33, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1666_0_0"}, {"texts": ["The man is watching in the right direction."], "durations": null, "exact_frames_per_prompt": [32], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-cIRzJUnZTw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 33, "npz_gt_video_start_frame": 33, "npz_gt_video_end_frame": 65, "skip_frames_after_generation": 33, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1666_0_1"}, {"texts": ["A girl wearing a shirt and denim jeans is walking, putting a liquid on the horse."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0bnT_R9v4kk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 29, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1668_0_0"}, {"texts": ["The girl is wearing a glove while the horse is standing on the left side."], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0bnT_R9v4kk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 29, "npz_gt_video_start_frame": 29, "npz_gt_video_end_frame": 67, "skip_frames_after_generation": 29, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1668_0_1"}, {"texts": ["The girl starts rubbing the horse."], "durations": null, "exact_frames_per_prompt": [12], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0bnT_R9v4kk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 67, "npz_gt_video_start_frame": 67, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 67, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1668_0_2"}, {"texts": ["A white gray horse is standing, getting a liquid applied on the back while a girl is putting down something."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0bnT_R9v4kk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 29, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1668_1_0"}, {"texts": ["The white gray horse is getting rubbed by a girl on the brown surface."], "durations": null, "exact_frames_per_prompt": [51], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0bnT_R9v4kk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 29, "npz_gt_video_start_frame": 29, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 29, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1668_1_1"}, {"texts": ["A white-gray horse is standing while a woman wearing white shirt is squeezing a scrub bottle on the horse body then takes a hand towel put it in her hand and starts scrubbings to the horse."], "durations": null, "exact_frames_per_prompt": [63], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0bnT_R9v4kk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 67, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1669_1_0"}, {"texts": ["The horse is getting cleaned by the woman."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0bnT_R9v4kk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 67, "npz_gt_video_start_frame": 67, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 67, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1669_1_1"}, {"texts": ["A woman wearing a gray top is standing and peeling a potato with a knife while another woman wearing white vest, standing on the right side of first woman is also peeling a potato with a knife and third woman wearing white and blue outfit, standing on the right side of second woman is cutting something using a knife."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2nj2B4HiQ00.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_166_0_0"}, {"texts": ["A woman wearing a white vest is standing and peeling a potato with a knife while another woman wearing a gray t-shirt is also peeling a potato with a knife and the third woman in a white t-shirt is standing on the right and doing something."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2nj2B4HiQ00.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_166_2_0"}, {"texts": ["A man wearing a suit is sitting in front right seat of a car while watching backward and talking and holding money in his hand."], "durations": null, "exact_frames_per_prompt": [71], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0qTKgJZTU3U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 75, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1673_0_0"}, {"texts": ["The man turns into the front direction."], "durations": null, "exact_frames_per_prompt": [5], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0qTKgJZTU3U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 75, "npz_gt_video_start_frame": 75, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 75, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1673_0_1"}, {"texts": ["A man wearing a suit is sitting in the car and is looking behind while speaking."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0qTKgJZTU3U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1674_0_0"}, {"texts": ["A man wearing a black jacket is sitting on the grey surface and putting the air pressure gauge on the tyre."], "durations": null, "exact_frames_per_prompt": [56], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/06dCiDZV8MM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 60, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1675_0_0"}, {"texts": ["The man stands up. "], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/06dCiDZV8MM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 60, "npz_gt_video_start_frame": 60, "npz_gt_video_end_frame": 75, "skip_frames_after_generation": 60, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1675_0_1"}, {"texts": ["The man shows the air pressure gauge."], "durations": null, "exact_frames_per_prompt": [5], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/06dCiDZV8MM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 75, "npz_gt_video_start_frame": 75, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 75, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1675_0_2"}, {"texts": ["A girl wearing a green dress is standing in the middle and giving a piece of fruit to the other girl while a girl wearing pink clothes is walking to the right and other persons are standing behind."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1JzvBGskXRU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 31, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1677_0_0"}, {"texts": ["A girl wearing a light pink jacket is standing on the right side of the first girl."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1JzvBGskXRU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 19, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1677_1_ms_0"}, {"texts": ["The girl picks the piece of fruit from the first girl's hand "], "durations": null, "exact_frames_per_prompt": [7], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1JzvBGskXRU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 19, "npz_gt_video_start_frame": 19, "npz_gt_video_end_frame": 26, "skip_frames_after_generation": 19, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1677_1_ms_1"}, {"texts": ["The girl eats it."], "durations": null, "exact_frames_per_prompt": [5], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1JzvBGskXRU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 26, "npz_gt_video_start_frame": 26, "npz_gt_video_end_frame": 31, "skip_frames_after_generation": 26, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1677_1_ms_2"}, {"texts": ["A girl wearing a pink dress is standing on the left side of the first girl then walking on the right side."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1JzvBGskXRU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 31, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1677_2_0"}, {"texts": ["The girl picks a piece of fruit from the tray."], "durations": null, "exact_frames_per_prompt": [8], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1JzvBGskXRU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 31, "npz_gt_video_start_frame": 31, "npz_gt_video_end_frame": 39, "skip_frames_after_generation": 31, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1677_2_1"}, {"texts": ["The girl eats it."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1JzvBGskXRU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 39, "npz_gt_video_start_frame": 39, "npz_gt_video_end_frame": 62, "skip_frames_after_generation": 39, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1677_2_2"}, {"texts": ["A man wearing orange t-shirt and jeans is performing flair bartending with a bottle and glass on the stage."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0uDpU9YlPOI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1678_0_0"}, {"texts": ["A baby wearing white cloth is sitting on a baby chair and eating cake from a plate."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2DMxUUkDgFI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1679_0_0"}, {"texts": ["A person whose hand is visible is holding a watermelon cutter and a watermelon and cutting the watermelon while another person whose hand is visible holds the watermelon."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/aF95fp665tA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1680_0_0"}, {"texts": ["A person whose hand is visible is holding the watermelon while a person wearing a white t-shirt is cutting a watermelon with a knife."], "durations": null, "exact_frames_per_prompt": [64], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/aF95fp665tA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 16, "npz_gt_video_start_frame": 16, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 16, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1680_1_0"}, {"texts": ["A man on the right side wearing a black t-shirt and blue jeans is standing and puts his hand on his mouth while another boy wearing a gray t-shirt is sitting on a chair next to him and a boy wearing a black vest is sitting on the extreme left."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0eRNvk76Fhg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 23, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1682_0_0"}, {"texts": ["The man starts vomiting on the table while a few people are sitting at the front watching them and the second boy starts walking."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0eRNvk76Fhg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 23, "npz_gt_video_start_frame": 23, "npz_gt_video_end_frame": 63, "skip_frames_after_generation": 23, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1682_0_1"}, {"texts": ["A man wearing a black cloth is standing on the black surface, holding a drink in a glass with whipped cream on top in the left hand."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0GIc6gWGuhU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 29, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1683_0_0"}, {"texts": ["The man is about to drink the glass of drink with whipped cream and he starts laughing, while holding an empty jar in his right hand."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0GIc6gWGuhU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 29, "npz_gt_video_start_frame": 29, "npz_gt_video_end_frame": 52, "skip_frames_after_generation": 29, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1683_0_1"}, {"texts": ["The man starts drinking the drink with whipped cream."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0GIc6gWGuhU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 52, "npz_gt_video_start_frame": 52, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 52, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1683_0_2"}, {"texts": ["A man wearing black cloth is standing, holding a glass of drink and a white jar, and laughing."], "durations": null, "exact_frames_per_prompt": [50], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0GIc6gWGuhU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 54, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1684_0_0"}, {"texts": ["The man is drinking."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0GIc6gWGuhU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 54, "npz_gt_video_start_frame": 54, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 54, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1684_0_1"}, {"texts": ["A person whose upper half-body is visible wearing a gray-black t-shirt, is standing behind the counter, holding a pineapple with his left hand and is cutting the pineapple on both sides with a knife."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1Dc2ULdonIc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1685_0_0"}, {"texts": ["A woman wearing a pink top walks."], "durations": null, "exact_frames_per_prompt": [47], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0SDmcLjxbv8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 51, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1686_0_0"}, {"texts": ["The woman sits on the floor and starts feeding the goat."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0SDmcLjxbv8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 51, "npz_gt_video_start_frame": 51, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 51, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1686_0_1"}, {"texts": ["A person wearing a gray sweater is standing and shredding white paper sheets in a shredding machine."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4NaqD-MybQw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1687_0_0"}, {"texts": ["A person wearing black clothes is sitting holding a book while a cat is lying on the person's lap."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1dGXZKsXWyE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1688_0_0"}, {"texts": ["A black brown cat is sitting on the first person's lap."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1dGXZKsXWyE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1688_1_0"}, {"texts": ["A man whose hands are visible, wearing a black cloth, is holding a light-yellow sheet of sponge."], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/23HXVAwRjG0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 41, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1689_0_0"}, {"texts": ["The man starts spraying water on the sheet of sponge with a white-green spray bottle."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/23HXVAwRjG0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 41, "npz_gt_video_start_frame": 41, "npz_gt_video_end_frame": 66, "skip_frames_after_generation": 41, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1689_0_1"}, {"texts": ["The man is putting the sheet of sponge on a heat press machine."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/23HXVAwRjG0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 66, "npz_gt_video_start_frame": 66, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 66, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1689_0_2"}, {"texts": ["A person wearing a blue cloth is sitting and cutting a packet with a knife."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-Sc5LrF0pzY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 29, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1697_0_0"}, {"texts": ["The person wearing a blue cloth is taking out the parcel from the packet."], "durations": null, "exact_frames_per_prompt": [51], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-Sc5LrF0pzY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 29, "npz_gt_video_start_frame": 29, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 29, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1697_0_1"}, {"texts": ["A man whose half body is visible is wearing a blue shirt and jeans is sitting on his knee and tying a bandage on a horse's leg."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/03mk_KF1tEc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1698_0_0"}, {"texts": ["A horse whose legs are visible is standing and being bandaged by the man."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/03mk_KF1tEc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1698_1_0"}, {"texts": ["A man in a black printed t-shirt keeps one hand on the wall and a beer bottle in the other, first hitting the beer bottle on the wall."], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/ShngatsD30g.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 37, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1699_0_0"}, {"texts": ["The man in a black printed t-shirt opens the bottle cap."], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/ShngatsD30g.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 37, "npz_gt_video_start_frame": 37, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 37, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1699_0_1"}, {"texts": ["A girl wearing a pink jacket is standing and giving a carrot to a goat while some animals are standing behind the fence and some people are walking on the right side."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-MWEwChPyOA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1701_0_0"}, {"texts": ["A person whom hand is visible is holding the girl's hand then leaves her hand while a group of goats are standing and moving behind the metal bars."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-MWEwChPyOA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 62, "npz_gt_video_start_frame": 62, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 62, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1701_2_0"}, {"texts": ["A boy wearing a red t-shirt is sitting on a wooden chair, holding the noodles with a fork and eating them."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-skUKi4ItkA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1705_0_0"}, {"texts": ["A girl wearing a grey t-shirt is standing in front of the digital screen."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-uBdzh95I7E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1708_0_0"}, {"texts": ["A baby wearing white and green printed clothes is picking some socks one by one from the basket."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4zEkAv6Xfgw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_170_0_0"}, {"texts": ["A woman wearing a teal t-shirt and grey jeans is sitting on the horse and gripping the horse leash on the green grass surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-u70G5M13co.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1711_1_0"}, {"texts": ["A brown horse is walking on the green grass surface while a girl is sitting on the horse."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-u70G5M13co.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1711_2_0"}, {"texts": ["A man wearing gray pants is smoking and counting the notes while dancing."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/14l1iEa80Vk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1712_0_0"}, {"texts": ["A man wearing light brown pants is smoking and counting the notes with his hands while dancing on the brown surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/14l1iEa80Vk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1713_0_0"}, {"texts": ["A person whose hands are visible is taking an egg."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2BG2HElGz00.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 15, "npz_gt_video_start_frame": 15, "npz_gt_video_end_frame": 35, "skip_frames_after_generation": 15, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1714_0_0"}, {"texts": ["The person starts peeling egg."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2BG2HElGz00.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 35, "npz_gt_video_start_frame": 35, "npz_gt_video_end_frame": 75, "skip_frames_after_generation": 35, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1714_0_1"}, {"texts": ["The person breaks the egg in half."], "durations": null, "exact_frames_per_prompt": [5], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2BG2HElGz00.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 75, "npz_gt_video_start_frame": 75, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 75, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1714_0_2"}, {"texts": ["A girl wearing a green t-shirt, black shorts, and white-black sneakers is standing in the front while holding a newspaper, opening the newspaper with her hands and then looking at the newspaper."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4sVlcU4_Sws.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1715_3_0"}, {"texts": ["A woman wearing a white t-shirt is sitting on a bed and tearing paper into pieces.\n while a kid wearing a green t-shirt is sitting on the bed and laughing and a man lying on the bed at the backside is watching the kid."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2Qy9jLxRHSQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1718_1_0"}, {"texts": ["A baby wearing a green t-shirt is sitting on a bed, watching the woman and laughing a man wearing a gray t-shirt is watching while lying on the bed."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2Qy9jLxRHSQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1718_2_0"}, {"texts": ["A kid is standing on the floor while holding the dog leash, and starts walking while the dog is moving around"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0cK13Pf2Rx8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1730_0_0"}, {"texts": ["A dog is standing on the floor while the boy pulls the belt of the dog."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0cK13Pf2Rx8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1730_1_0"}, {"texts": ["The dog starts walking while the boy start walking by holding dog belt."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0cK13Pf2Rx8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 40, "npz_gt_video_start_frame": 40, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 40, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1730_1_1"}, {"texts": ["A girl wearing a grey top is giving training to a puppy."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-vztWUIq0y0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 8, "npz_gt_video_start_frame": 8, "npz_gt_video_end_frame": 48, "skip_frames_after_generation": 8, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1733_0_0"}, {"texts": ["The girl wearing a grey top is running on the soil surface."], "durations": null, "exact_frames_per_prompt": [32], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-vztWUIq0y0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 48, "npz_gt_video_start_frame": 48, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 48, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1733_0_1"}, {"texts": ["A baby wearing a white onesie is sitting on a white surface and playing with a tissue."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0HomhRSwTWA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1736_0_0"}, {"texts": ["A woman whose only half-body is visible is standing and cutting pineapple peel with a knife on a white chopping board."], "durations": null, "exact_frames_per_prompt": [55], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0s04hDiq_mY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 25, "npz_gt_video_start_frame": 25, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 25, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1738_0_0"}, {"texts": ["A person whose hand is visible is petting the cat."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0au5gb0jJos.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1740_0_0"}, {"texts": ["A cat is laying on the gray surface, yawning, and getting petted by a person."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0au5gb0jJos.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1740_1_0"}, {"texts": ["A boy wearing a white-blue t-shirt is leaning forward and eating watermelon.\n while another boy wearing a black t-shirt is on the right side and eating watermelon, a woman is coming from the right side holding a mic, and a group of people are looking at the boys."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-fk5STh-Obo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1749_0_0"}, {"texts": ["A boy wearing a black t-shirt is also leaning forward and eating watermelon while a boy wearing a blue-white t-shirt is eating water melon, a woman is pointing at them while holding a mic and a group of people are standing around them and watching."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-fk5STh-Obo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1749_1_0"}, {"texts": ["A woman is holding a microphone and moving her hands toward the boys while a group of people including children are standing around the boys and watching them."], "durations": null, "exact_frames_per_prompt": [68], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-fk5STh-Obo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 72, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1749_2_0"}, {"texts": ["A man wearing a blue shirt is holding a paper and starts the black paper shredding machine"], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/394uA9Eveag.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 37, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1751_0_0"}, {"texts": ["The man puts the paper in the paper shredding machine."], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/394uA9Eveag.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 37, "npz_gt_video_start_frame": 37, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 37, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1751_0_1"}, {"texts": ["A person whose only hands are visible is wearing a blue shirt and demonstrating how to use a paper shredder."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/394uA9Eveag.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1752_0_0"}, {"texts": ["A boy wearing a black t-shirt and black jeans is standing while holding a fry pan with a pancake."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-K_u_WQx1Ao.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 19, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1755_0_0"}, {"texts": ["The boy wearing a black t-shirt and black jeans is tossing the pancake and catching it."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-K_u_WQx1Ao.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 19, "npz_gt_video_start_frame": 19, "npz_gt_video_end_frame": 37, "skip_frames_after_generation": 19, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1755_0_1"}, {"texts": ["The boy wearing a black t-shirt and black jeans is keeping the fry pan on the gas stove."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-K_u_WQx1Ao.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 37, "npz_gt_video_start_frame": 37, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 37, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1755_0_2"}, {"texts": ["The boy wearing a black t-shirt and black jeans is speaking while putting his left hand on his waist."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-K_u_WQx1Ao.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 50, "npz_gt_video_start_frame": 50, "npz_gt_video_end_frame": 65, "skip_frames_after_generation": 50, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1755_0_3"}, {"texts": ["A woman wearing a black t-shirt and white shorts is standing on the right, moving a black pan while another woman wearing a  green and white top stands in front of her and  starts laughing."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2KWWogyb6zY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1760_0_0"}, {"texts": ["The woman is flipping something in it while a woman starts laughing and clapping."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2KWWogyb6zY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 40, "npz_gt_video_start_frame": 40, "npz_gt_video_end_frame": 61, "skip_frames_after_generation": 40, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1760_0_1"}, {"texts": ["A woman wearing a multi-color vest is standing on the left, moving, and laughing while a girl on the right side in a black t-shirt is flipping pancake then starts celebrating."], "durations": null, "exact_frames_per_prompt": [57], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2KWWogyb6zY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 61, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1760_1_0"}, {"texts": ["A girl wearing a black t-shirt is standing on the right side while another woman wearing an aqua vest is standing on the right side."], "durations": null, "exact_frames_per_prompt": [12], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2KWWogyb6zY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 16, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1761_0_0"}, {"texts": ["The girl wearing a black t-shirt is tossing the food in the frying pan and another woman starts clapping in joy."], "durations": null, "exact_frames_per_prompt": [45], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2KWWogyb6zY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 16, "npz_gt_video_start_frame": 16, "npz_gt_video_end_frame": 61, "skip_frames_after_generation": 16, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1761_0_1"}, {"texts": ["A girl wearing a sky-blue top is standing on the left side and laughing while another girl wearing black and white outfit, holding a pan in his hand and she is tossing something using the pan."], "durations": null, "exact_frames_per_prompt": [57], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2KWWogyb6zY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 61, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1761_1_0"}, {"texts": ["A woman wearing a blue jacket is sitting, holding a donut in her hand. "], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1pfKrQ-K6Pg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 31, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1762_1_0"}, {"texts": ["The woman is talking."], "durations": null, "exact_frames_per_prompt": [49], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1pfKrQ-K6Pg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 31, "npz_gt_video_start_frame": 31, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 31, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1762_1_1"}, {"texts": ["A man wearing a black jacket is standing on the left, holding an award and speaking on the microphone."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1592Amp57V4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1765_0_0"}, {"texts": ["A girl wearing a pink frock is standing and keeping a snake in her palm while a women in black pink dress standing holding that girl."], "durations": null, "exact_frames_per_prompt": [70], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3AAPiiHuQQ0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 74, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1767_0_0"}, {"texts": ["A woman wearing a black top is bending and holding the hand of the girl while holding a bottle in her hand."], "durations": null, "exact_frames_per_prompt": [70], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3AAPiiHuQQ0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 74, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1767_1_0"}, {"texts": ["A girl wearing a blue top is standing and holding her hand in the front direction while a woman in black top is standing, leaning forward, holding the hands of the girl in pink frock and that girl is holding a snake in her hand, later another kid is touching the snake, and the person stopped the kid then lifts the snake up."], "durations": null, "exact_frames_per_prompt": [70], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3AAPiiHuQQ0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 74, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1767_2_0"}, {"texts": ["A girl wearing a white top is standing while a girl wearing a pink outfit is standing on a green grass surface, holding a snake, a woman wearing black and white is standing on a green grass surface, holding the girl's hands, and another girl wearing a pink outfit is standing at the back."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3AAPiiHuQQ0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 11, "npz_gt_video_start_frame": 11, "npz_gt_video_end_frame": 30, "skip_frames_after_generation": 11, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1767_3_0"}, {"texts": ["The girl is touching the snake while a person whose hand is visible is pulling the girl's hand."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3AAPiiHuQQ0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 30, "npz_gt_video_start_frame": 30, "npz_gt_video_end_frame": 46, "skip_frames_after_generation": 30, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1767_3_1"}, {"texts": ["A girl wearing a printed dress is standing on the green grass surface while group of people are standing on the green grass surface."], "durations": null, "exact_frames_per_prompt": [70], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3AAPiiHuQQ0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 74, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1767_5_0"}, {"texts": ["A boy wearing a light green t-shirt is sitting on the left side behind the counter top and speaking."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-snAHpMtWlc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_176_0_0"}, {"texts": ["A boy wearing a dark green t-shirt is sitting in the middle behind the counter-top while in his left the boy talking about the some topic."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-snAHpMtWlc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_176_1_0"}, {"texts": ["A girl wearing a black printed t-shirt is sitting on the right side behind the counter-top a boy in a light blue t-shirt is speaking on the left side."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-snAHpMtWlc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_176_2_0"}, {"texts": ["A person whose fingers are visible holding a spoon is moving the spoon and mixing the detox water."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5FHcdooAqUs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1772_0_0"}, {"texts": ["A person of whom only hands are visible is holding an egg and a white bowl."], "durations": null, "exact_frames_per_prompt": [52], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1nCfCIkbUPA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 28, "npz_gt_video_start_frame": 28, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 28, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1773_0_0"}, {"texts": ["A man whose hands are visible is holding a white bowl in left hand and holding an egg in right hand, pointing his right hand to the right and keeping the egg in the bowl."], "durations": null, "exact_frames_per_prompt": [51], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1nCfCIkbUPA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 29, "npz_gt_video_start_frame": 29, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 29, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1774_0_0"}, {"texts": ["A woman wearing a black t-shirt, black jeans, and black boots is sitting on the horse's back while holding the harness, and riding a horse on the soil surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-QqZCwEJ7g4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1778_0_0"}, {"texts": ["A brown horse is carrying a woman on its back and walking on the soil surface towards the right side a woman wearing a black headgear riding a horse"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-QqZCwEJ7g4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1778_1_0"}, {"texts": ["A person wearing a gray top is standing and peeling an apple with a black apple peeling machine."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0cKRYGwRxp4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1779_0_0"}, {"texts": ["A man wearing a cap is at first standing near the car and watching the fuel dispenser machine."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2zlPP1ChaZA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 34, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1784_1_0"}, {"texts": ["The man turns and takes out the nozzle."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2zlPP1ChaZA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 34, "npz_gt_video_start_frame": 34, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 34, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1784_1_1"}, {"texts": ["A woman wearing a blue dress is dancing while holding a griddle and starts touching the round grill grate line."], "durations": null, "exact_frames_per_prompt": [61], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0EFxOj0mLF0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 65, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1791_0_0"}, {"texts": ["A person wearing a grey t-shirt is standing on the left side and pushing meat into the meat grinder with a stuffer filler stick."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0109TNvx7RY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1795_0_0"}, {"texts": ["A big girl wearing clothes and a helmet is performing horse show jumping with horse riding."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-xuVfmYKSsE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1803_0_0"}, {"texts": ["A horse is performing show jumping while a girl is riding on him."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-xuVfmYKSsE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1803_1_0"}, {"texts": ["A baby wearing a red-blue t-shirt is eating food with the spoon by the woman."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-ZSLez_Qtc4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1806_1_0"}, {"texts": ["A person wearing red clothes is standing and holding a big knife and cutting a watermelon."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/8Ro1fiH4DrU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1812_0_0"}, {"texts": ["A woman is standing on the left side while holding a golf stick."], "durations": null, "exact_frames_per_prompt": [8], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-2KvnLMnrA0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 12, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1815_0_0"}, {"texts": ["The woman is playing golf while hitting the golf ball with a golf stick."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-2KvnLMnrA0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 12, "npz_gt_video_start_frame": 12, "npz_gt_video_end_frame": 26, "skip_frames_after_generation": 12, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1815_0_1"}, {"texts": ["The woman is looking at the ball while standing and touching her hair with her left hand."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-2KvnLMnrA0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 26, "npz_gt_video_start_frame": 26, "npz_gt_video_end_frame": 39, "skip_frames_after_generation": 26, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1815_0_2"}, {"texts": ["A man wearing a t-shirt is standing under a car's undercarriage, opening a part of the car with a wrench."], "durations": null, "exact_frames_per_prompt": [58], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/14fEMSt8ZK4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 62, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1817_0_0"}, {"texts": ["The man wearing a t-shirt is fitting a new part."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/14fEMSt8ZK4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 62, "npz_gt_video_start_frame": 62, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 62, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1817_0_1"}, {"texts": ["A man wearing a grey-black t-shirt is standing, opening the bolt with the wrench."], "durations": null, "exact_frames_per_prompt": [12], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/14fEMSt8ZK4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 16, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1818_0_0"}, {"texts": ["The man is taking out the bolt."], "durations": null, "exact_frames_per_prompt": [52], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/14fEMSt8ZK4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 16, "npz_gt_video_start_frame": 16, "npz_gt_video_end_frame": 68, "skip_frames_after_generation": 16, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1818_0_1"}, {"texts": ["The man is putting it."], "durations": null, "exact_frames_per_prompt": [12], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/14fEMSt8ZK4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 68, "npz_gt_video_start_frame": 68, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 68, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1818_0_2"}, {"texts": ["A woman wearing white-yellow clothes and tying a black strap."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-RnwS8FlLEE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1823_0_0"}, {"texts": ["A man wearing a black t-shirt is smelling a bottle."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2cvS39tCMtg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 30, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1824_0_0"}, {"texts": ["The man starts pouring some liquid from the bottle in a glass."], "durations": null, "exact_frames_per_prompt": [50], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2cvS39tCMtg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 30, "npz_gt_video_start_frame": 30, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 30, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1824_0_1"}, {"texts": ["A person whose hands are visible is rubbing a piece of paper a baby wearing white clothes sitting on a chair watching the person hand"], "durations": null, "exact_frames_per_prompt": [63], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2hecxkR6nIQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 67, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1829_0_0"}, {"texts": ["The person is tearing the paper while A baby wearing white clothes starts laugh"], "durations": null, "exact_frames_per_prompt": [11], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2hecxkR6nIQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 67, "npz_gt_video_start_frame": 67, "npz_gt_video_end_frame": 78, "skip_frames_after_generation": 67, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1829_0_1"}, {"texts": ["A baby wearing white printed clothes is lying on a baby bed and watching the first person."], "durations": null, "exact_frames_per_prompt": [50], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2hecxkR6nIQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 54, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1829_1_0"}, {"texts": ["A baby wearing white printed clothes is laughing."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2hecxkR6nIQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 54, "npz_gt_video_start_frame": 54, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 54, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1829_1_1"}, {"texts": ["A baby wearing white printed clothes is lying on a baby bed and watching the first person and laughing."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2hecxkR6nIQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1830_1_0"}, {"texts": ["A man wearing a black tracksuit is playing golf."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1EmxAHGtgG8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 39, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1839_0_0"}, {"texts": ["The man starts walking."], "durations": null, "exact_frames_per_prompt": [12], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1EmxAHGtgG8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 39, "npz_gt_video_start_frame": 39, "npz_gt_video_end_frame": 51, "skip_frames_after_generation": 39, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1839_0_1"}, {"texts": ["A woman wearing black clothes is standing and is speaking."], "durations": null, "exact_frames_per_prompt": [69], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-F8lZfpwp0Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 11, "npz_gt_video_start_frame": 11, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 11, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1841_0_ms_0"}, {"texts": ["A man wearing a black shirt on the right is also standing and is doing american sign language."], "durations": null, "exact_frames_per_prompt": [48], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-F8lZfpwp0Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 32, "npz_gt_video_start_frame": 32, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 32, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1841_1_0"}, {"texts": ["A man wearing blue clothes is holding a peeler and drilling machine attach with an apple."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-GvB7aLrCqQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 22, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1847_0_0"}, {"texts": ["The man wearing blue clothes takes it in other hand."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-GvB7aLrCqQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 22, "npz_gt_video_start_frame": 22, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 22, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1847_0_1"}, {"texts": ["The man wearing blue clothes starts rotating and peeling the apple."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-GvB7aLrCqQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 50, "npz_gt_video_start_frame": 50, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 50, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1847_0_2"}, {"texts": ["A man wearing an aqua green t-shirt, a blue woolen cap, black pants, and black shoes is standing in a golf stance position while holding a golf stick."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0T5E-XoI5Zg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 19, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1848_0_0"}, {"texts": ["The man is playing golf while hitting the golf ball with a golf stick. "], "durations": null, "exact_frames_per_prompt": [6], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0T5E-XoI5Zg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 19, "npz_gt_video_start_frame": 19, "npz_gt_video_end_frame": 25, "skip_frames_after_generation": 19, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1848_0_1"}, {"texts": ["The man is standing in a straight position while holding a golf stick."], "durations": null, "exact_frames_per_prompt": [55], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0T5E-XoI5Zg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 25, "npz_gt_video_start_frame": 25, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 25, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1848_0_2"}, {"texts": ["A person wearing a black jacket with white stripes is standing on the right and tapping on a dough."], "durations": null, "exact_frames_per_prompt": [32], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2QJJFZNpENI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 36, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1853_0_0"}, {"texts": ["The person starts removing flour from the counter top in the hand."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2QJJFZNpENI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 36, "npz_gt_video_start_frame": 36, "npz_gt_video_end_frame": 56, "skip_frames_after_generation": 36, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1853_0_1"}, {"texts": ["The person takes a purple bowl."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2QJJFZNpENI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 56, "npz_gt_video_start_frame": 56, "npz_gt_video_end_frame": 67, "skip_frames_after_generation": 56, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1853_0_2"}, {"texts": ["The person starts removing flour from the counter-top to the bowl."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2QJJFZNpENI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 67, "npz_gt_video_start_frame": 67, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 67, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1853_0_3"}, {"texts": ["A baby wearing a multicolored dress is sitting on a table eating food with his hand while a man in a blue sweatshirt is sitting on the left and looking at the baby."], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4-AdR_vw8A8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 35, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1854_0_0"}, {"texts": ["The baby starts looking at the table."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4-AdR_vw8A8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 35, "npz_gt_video_start_frame": 35, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 35, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1854_0_1"}, {"texts": ["A man wearing a blue sweater is sitting on a chair looking at the baby while speaking and smiling while a baby on the right side wearing a multicoloured outfit is sitting on a table and eating food with hand."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4-AdR_vw8A8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1854_1_0"}, {"texts": ["A man wearing a white shirt, black coat and black pants is standing on the left side of the other man and tying a tie around his own neck while a baby in blue t-shirt is moving on brown surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-RdPsVc6psA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1856_0_0"}, {"texts": ["A man wearing a white shirt, gray sweater, and dark blue jeans is standing on the right side of the first man and tying a tie around his own neck while the baby crawls towards them."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-RdPsVc6psA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1856_1_0"}, {"texts": ["The man is bending."], "durations": null, "exact_frames_per_prompt": [8], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-RdPsVc6psA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 45, "npz_gt_video_start_frame": 45, "npz_gt_video_end_frame": 53, "skip_frames_after_generation": 45, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1856_1_1"}, {"texts": ["The man is stopping the baby with his hand."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-RdPsVc6psA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 53, "npz_gt_video_start_frame": 53, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 53, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1856_1_2"}, {"texts": ["A baby wearing a dark blue cloth is crawling towards the both men on the dark brown surface."], "durations": null, "exact_frames_per_prompt": [55], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-RdPsVc6psA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 59, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1856_2_0"}, {"texts": ["A man wearing a black coat and white shirt is standing, holding a microphone and trophy and speaking."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0lg1stFRF4A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1860_0_0"}, {"texts": ["A girl wearing black clothes is standing, touching and cleaning a white horse with a brush."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-MldnTjJ-zE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1865_0_0"}, {"texts": ["A boy wearing a red t-shirt is sitting on the floor, holding a jewel case."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1ei-0k9VJZQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 27, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1866_0_0"}, {"texts": ["The boy puts the jewel case on the floor and takes a red gift in his hand while a woman wearing black outfit is sitting on the right side and a brown dog is standing on the floor beside the woman."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1ei-0k9VJZQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 27, "npz_gt_video_start_frame": 27, "npz_gt_video_end_frame": 55, "skip_frames_after_generation": 27, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1866_0_1"}, {"texts": ["A woman wearing a black jacket is sitting on the wooden floor while the boy in red top checks the presents and the dog behind her sniffs the Christmas tree."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1ei-0k9VJZQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 44, "npz_gt_video_start_frame": 44, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 44, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1866_1_0"}, {"texts": ["A boy wearing a red t-shirt is sitting and riding a camel while the woman holds the reins and takes to the direction."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/15iug-PHLAk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 40, "npz_gt_video_start_frame": 40, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 40, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_186_0_0"}, {"texts": ["A woman wearing a black top is holding the camel harness and is walking in front of the camel."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/15iug-PHLAk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 41, "npz_gt_video_start_frame": 41, "npz_gt_video_end_frame": 57, "skip_frames_after_generation": 41, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_186_1_ms_0"}, {"texts": ["A camel is walking on the brown surface, while making a boy sit on his back while the woman holds the reins"], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/15iug-PHLAk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 40, "npz_gt_video_start_frame": 40, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 40, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_186_2_0"}, {"texts": ["A girl wearing a green top is eating a yellow crackle."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-tR1hivzl_U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1870_0_0"}, {"texts": ["A man wearing a black t-shirt is doing flair bar-tending.\n while the man in ash colour vest is looking at him and  encouraging."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-RLhbQpFa1s.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1871_0_0"}, {"texts": ["A man in grey and white clothing is cheering the man in a black t-shirt by lifting his one hand while a group of people is looking in the direction of the man in a black t-shirt and cheering."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-RLhbQpFa1s.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1871_1_0"}, {"texts": ["A man wearing a black jacket is shaving a white sheep."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/15o6ZISRJPo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 12, "npz_gt_video_start_frame": 12, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 12, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1872_3_ms_0"}, {"texts": ["A white sheep is laying on the floor and being shaved by the third man while a man is standing and giving something to him and a group of sheep in which some sheep standing and some sheep are walking."], "durations": null, "exact_frames_per_prompt": [54], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/15o6ZISRJPo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1872_4_ms_0"}, {"texts": ["A person whose hands are visible on the left is scratching the wool while another person on the right side is scratching the wool."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/15o6ZISRJPo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 59, "npz_gt_video_start_frame": 59, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 59, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1872_5_0"}, {"texts": ["Another person whose hands are visible on the right is scratching the wool."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/15o6ZISRJPo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 59, "npz_gt_video_start_frame": 59, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 59, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1872_6_ms_0"}, {"texts": ["A man wearing a blue t-shirt standing in the kitchen is flipping a pancake on a plate."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/01ZrQnMruig.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1879_0_0"}, {"texts": ["A man wearing a black t-shirt is standing and is speaking."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-xxpyScg_vY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 18, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1888_0_0"}, {"texts": ["A person whom hands are visible is milking the white cow."], "durations": null, "exact_frames_per_prompt": [62], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-xxpyScg_vY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 18, "npz_gt_video_start_frame": 18, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 18, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1888_1_0"}, {"texts": ["A white cow is standing and is being milked by person two."], "durations": null, "exact_frames_per_prompt": [62], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-xxpyScg_vY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 18, "npz_gt_video_start_frame": 18, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 18, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1888_3_0"}, {"texts": ["A man wearing a sky-blue t-shirt, blue jeans, and a dark blue cap is holding a big horse by a rope and then starts walking towards the right side ahead of the big horse and the small horse follows them"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0VOxfdWK6mw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1890_0_0"}, {"texts": ["A big brown horse is tied to the rope held by the man and is walking along with the man on the green grass surface while the other horse follows them."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0VOxfdWK6mw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1890_1_0"}, {"texts": ["A baby brown horse is walking along with the big horse towards the right side on the green grass surface while a man wearing blue outfit is walking on green grass surface towards the right side, holding a rope in his hand that is attached to the big horse."], "durations": null, "exact_frames_per_prompt": [56], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0VOxfdWK6mw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 24, "npz_gt_video_start_frame": 24, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 24, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1890_2_0"}, {"texts": ["A man wearing a sky-blue t-shirt is walking ahead while holding a horse rope while a baby horse is also walking along with the horse."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0VOxfdWK6mw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1891_0_0"}, {"texts": ["A brown horse is tied with the rope and walking along with the man on the green grass surface while another small brown horse is also walking along on the green grass surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0VOxfdWK6mw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1891_1_0"}, {"texts": ["A baby brown horse is walking along with the big horse on the green grass surface while the man holding the rope tied with a big horse is walking"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0VOxfdWK6mw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1891_2_0"}, {"texts": ["A woman wearing a blue hoodie is making a sandwich."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5xIfmiRGQdw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1894_0_0"}, {"texts": ["The woman is opening the mustard sauce bottle cap."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5xIfmiRGQdw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 45, "npz_gt_video_start_frame": 45, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 45, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1894_0_1"}, {"texts": ["A girl wearing a blue hoodie with written words is pressing chicken slices on a slice of bread."], "durations": null, "exact_frames_per_prompt": [32], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5xIfmiRGQdw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 36, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1895_0_0"}, {"texts": ["The girl takes a yellow bottle and opens the cap of the yellow bottle then lifts the bottle to pour."], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5xIfmiRGQdw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 36, "npz_gt_video_start_frame": 36, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 36, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1895_0_1"}, {"texts": ["A baby wearing a white printed romper is lying on the yellow-blue-green printed chair, holding a carrot and trying to eat the carrot."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3kavSc71JM8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1896_0_0"}, {"texts": ["A man wearing a black suit is standing on the right, clapping and watching the first man while two men are standing and shaking hands and a woman is holding a tray while standing then walks away."], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1idvXPxy3pk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 41, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1897_2_0"}, {"texts": ["The man is shaking hands with the first man."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1idvXPxy3pk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 41, "npz_gt_video_start_frame": 41, "npz_gt_video_end_frame": 62, "skip_frames_after_generation": 41, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1897_2_1"}, {"texts": ["A woman wearing a golden saree is standing on the backside, holding a tray of award then the award is picked by the second man.  while a man wearing a red shirt is taking the award and another man wearing black clothes is standing on the right side and clapping."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1idvXPxy3pk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 14, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1897_3_0"}, {"texts": ["The woman walks towards the left while the man wearing a red shirt is shaking hands with the man wearing a white shirt."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1idvXPxy3pk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 14, "npz_gt_video_start_frame": 14, "npz_gt_video_end_frame": 36, "skip_frames_after_generation": 14, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1897_3_1"}, {"texts": ["A girl wearing a cap is sitting on the left side and eating something while another girl on the right side is moving her hand and looking in the front."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1DANNB6_6RI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1898_0_0"}, {"texts": ["A woman wearing a maroon t-shirt and blue jeans is sitting on the horse, holding the bridle and riding from the right side to the left side on the soil surface."], "durations": null, "exact_frames_per_prompt": [57], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0A_ivMQ1Cz4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 61, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1900_0_0"}, {"texts": ["A white horse is running on the soil surface and a woman is sitting on its back."], "durations": null, "exact_frames_per_prompt": [57], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0A_ivMQ1Cz4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 61, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1900_1_0"}, {"texts": ["A boy wearing a white t-shirt is sitting on the wooden floor and removing the gift wrap from a book."], "durations": null, "exact_frames_per_prompt": [54], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1Dz1FGJ1huE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1912_0_0"}, {"texts": ["The boy wearing a white t-shirt puts the book on the floor."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1Dz1FGJ1huE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 58, "npz_gt_video_start_frame": 58, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 58, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1912_0_1"}, {"texts": ["A man wearing a blue t-shirt is standing and putting the fishes in the meat grinder."], "durations": null, "exact_frames_per_prompt": [54], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5rvOuIYg3yk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1920_0_0"}, {"texts": ["A person whose hands are visible is holding a peeler and an apple and peeling the apple."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2uzt0eAalss.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1924_0_0"}, {"texts": ["A woman wearing a green-white top is standing and making sushi by rolling a bamboo sushi mat on the wooden board."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0PM667FvXQI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1925_0_0"}, {"texts": ["A man wearing a white shirt and black pants is making a bed."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/Hyh3D6U5ezo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1930_0_0"}, {"texts": ["A man wearing a gray t-shirt and black trousers is standing and making a bed."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/Hyh3D6U5ezo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1931_0_0"}, {"texts": ["A woman, whose hand is visible, is cleaning the gas stove with white tissue paper while a boy on the right side is standing."], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3qCcdAlYf1A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 28, "npz_gt_video_start_frame": 28, "npz_gt_video_end_frame": 71, "skip_frames_after_generation": 28, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1932_0_0"}, {"texts": ["A boy whose upper half-body is visible, wearing a blue printed sky blue t-shirt, is standing on the right side of the surface and is speaking and then blowing through his mouth on the gas stove."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3qCcdAlYf1A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1932_1_0"}, {"texts": ["A boy wearing a black t-shirt is sitting and chewing."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/030KGXn4hy4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 30, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1935_0_0"}, {"texts": ["The boy wearing a black t-shirt takes something from the person."], "durations": null, "exact_frames_per_prompt": [50], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/030KGXn4hy4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 30, "npz_gt_video_start_frame": 30, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 30, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1935_0_1"}, {"texts": ["A man wearing a white shirt is standing."], "durations": null, "exact_frames_per_prompt": [38], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0fEPjC7XGqE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 42, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_193_0_0"}, {"texts": ["The man is putting the green rope on the hook."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0fEPjC7XGqE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 42, "npz_gt_video_start_frame": 42, "npz_gt_video_end_frame": 62, "skip_frames_after_generation": 42, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_193_0_1"}, {"texts": ["The man starts pulling the rope."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0fEPjC7XGqE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 62, "npz_gt_video_start_frame": 62, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 62, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_193_0_2"}, {"texts": ["A woman wearing a purple suit is standing, holding a wok and mixing the vegetables in the wok."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/6cCRuEzXIl8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1945_0_0"}, {"texts": ["A baby wearing a white orange sweatshirt is sitting on the first person's lap."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-TpohjiPMSE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 17, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_194_1_0"}, {"texts": ["The baby is pulling the newspaper while the first person holds the newspaper back."], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-TpohjiPMSE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 17, "npz_gt_video_start_frame": 17, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 17, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_194_1_1"}, {"texts": ["A man, whom hands are visible only, is holding a knotted rope, rotating and stretching it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/02iWPRcCQ94.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1952_0_0"}, {"texts": ["A child wearing a gray hoodie, white jeans, and gray-white woolen cap is standing while plucking the red apple from the tree."], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-4Zkoocadr0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 41, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1953_0_0"}, {"texts": ["The child starts walking towards the man."], "durations": null, "exact_frames_per_prompt": [39], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-4Zkoocadr0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 41, "npz_gt_video_start_frame": 41, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 41, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1953_0_1"}, {"texts": ["A man whose only hands and legs are visible wearing a black sweatshirt is sitting on the green grass surface on the left side and is pointing his hand towards the child while the child comes towards the man."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-4Zkoocadr0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 55, "npz_gt_video_start_frame": 55, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 55, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1953_1_0"}, {"texts": ["A brown dog is walking on the road and is being held by a white metal chain."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0dI9nksFKUA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1956_0_0"}, {"texts": ["A man wearing a brown-orange jacket is sitting on a chair, holding a knife in his hand and moving his hands."], "durations": null, "exact_frames_per_prompt": [71], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/35Fa6wloUMA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 75, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1957_0_0"}, {"texts": ["The man turns his head to the left."], "durations": null, "exact_frames_per_prompt": [5], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/35Fa6wloUMA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 75, "npz_gt_video_start_frame": 75, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 75, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1957_0_1"}, {"texts": ["A person whose hand is visible is showing the food to the blue bird."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0lxzjBKsQlg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1960_0_0"}, {"texts": ["A blue jay bird is hopping here and there to snatch away the food from the person's hand while the person is giving the food to the bird."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0lxzjBKsQlg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1960_1_0"}, {"texts": ["A person whose hands are visible is holding a glass jar of onions."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4CJ_gPNUzF4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 21, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1961_0_0"}, {"texts": ["The person is putting it in glass bowl."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4CJ_gPNUzF4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 21, "npz_gt_video_start_frame": 21, "npz_gt_video_end_frame": 56, "skip_frames_after_generation": 21, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1961_0_1"}, {"texts": ["The person is mixing it. "], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4CJ_gPNUzF4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 56, "npz_gt_video_start_frame": 56, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 56, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1961_0_2"}, {"texts": ["A woman wearing a black tank top is sitting and applying butter with a knife on the slices of bread."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/38GhvJu7jhc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1965_0_0"}, {"texts": ["A woman wearing a black outfit is sitting with a butter knife in her right hand and buttering bread on the table."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/38GhvJu7jhc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1966_0_0"}, {"texts": ["A lady wearing a green-purple saree is sitting with another lady and milking milk from a buffalo in a bucket on a brown soil surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1E-twOFAPfw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1967_0_0"}, {"texts": ["A kid wearing a peach color t-shirt is giggling and sitting on a white baby high chair."], "durations": null, "exact_frames_per_prompt": [68], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0S20SCkkeFA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 72, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1968_0_0"}, {"texts": ["The kid stops giggling."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0S20SCkkeFA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 72, "npz_gt_video_start_frame": 72, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 72, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1968_0_1"}, {"texts": ["A woman wearing a grey t-shirt is carrying a baby and feeding by the bottle."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/16PHEw_PsSk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1973_0_0"}, {"texts": ["A baby wearing a light pink cloth is fed by the woman."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/16PHEw_PsSk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1973_1_0"}, {"texts": ["A person is feeding a baby with a pink spoon."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/47sZcVTD3KY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1975_0_0"}, {"texts": ["A baby wearing white clothes is sitting on a baby dining chair and eating food.\n while a woman sitting and feeding food with a spoon."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/47sZcVTD3KY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1975_1_0"}, {"texts": ["A woman wearing a black hoodie is standing."], "durations": null, "exact_frames_per_prompt": [11], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-VG42OzQzHc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 15, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1976_0_0"}, {"texts": ["The woman opens a carry bag."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-VG42OzQzHc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 15, "npz_gt_video_start_frame": 15, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 15, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1976_0_1"}, {"texts": ["The woman puts something in it."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-VG42OzQzHc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 45, "npz_gt_video_start_frame": 45, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 45, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1976_0_2"}, {"texts": ["A white cat is sitting on a chair in the back while a woman wearing a black outfit is standing, holding, and opening a carry bag."], "durations": null, "exact_frames_per_prompt": [39], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-VG42OzQzHc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 43, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1976_1_0"}, {"texts": ["A woman wearing a black jacket is standing. "], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-VG42OzQzHc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 14, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1977_0_0"}, {"texts": ["The woman is opening a printed carry bag."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-VG42OzQzHc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 14, "npz_gt_video_start_frame": 14, "npz_gt_video_end_frame": 36, "skip_frames_after_generation": 14, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1977_0_1"}, {"texts": ["The woman is putting it on the table."], "durations": null, "exact_frames_per_prompt": [39], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-VG42OzQzHc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 36, "npz_gt_video_start_frame": 36, "npz_gt_video_end_frame": 75, "skip_frames_after_generation": 36, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1977_0_2"}, {"texts": ["The woman is starting to put a black object inside the carry bag."], "durations": null, "exact_frames_per_prompt": [5], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-VG42OzQzHc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 75, "npz_gt_video_start_frame": 75, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 75, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1977_0_3"}, {"texts": ["A man is standing, moving his head and eating a piece of food."], "durations": null, "exact_frames_per_prompt": [74], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1QbXSzC_MQY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 78, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1981_0_0"}, {"texts": ["A woman wearing red clothes whose only hands are visible is making a doll with a white cloth."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0nWBr2nZ9xs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1983_0_0"}, {"texts": ["A man wearing a black-blue t-shirt, black shorts, black shoes, and a black hat is sitting on the horse's back while holding the horse harness and riding a horse on the soil surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5tI9jC_onR0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1984_0_0"}, {"texts": ["A white horse is walking on the soil surface while carrying a man on its back."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5tI9jC_onR0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1984_1_0"}, {"texts": ["A girl wearing a white purple dress is walking on a brown surface and putting clothes in washing machines."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/7fRljoi32nU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1986_0_0"}, {"texts": ["A person wearing a black jacket, black gloves, brown jeans, and black shoes is pulling the string with their hands from the hole while standing on the snow surface."], "durations": null, "exact_frames_per_prompt": [72], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3ZXDdqJr7Jg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 8, "npz_gt_video_start_frame": 8, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 8, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_198_1_0"}, {"texts": ["A woman wearing black shades is sitting on the green grass surface and is reading a book while a man is lying on the ground and reading a book,\u00a0 and other people are standing in a statue position."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-htY-hAxcKM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1990_0_0"}, {"texts": ["A man wearing a cap is lying on the green grass surface and is also reading a book while a group of people are standing around."], "durations": null, "exact_frames_per_prompt": [57], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-htY-hAxcKM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 23, "npz_gt_video_start_frame": 23, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 23, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1990_1_0"}, {"texts": ["A person whose only hands are visible is at first holding a cardboard box and points on the receipt attached on the box."], "durations": null, "exact_frames_per_prompt": [34], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Db7KIPFyPY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 38, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1996_0_0"}, {"texts": ["The person puts the box on the wooden surface."], "durations": null, "exact_frames_per_prompt": [12], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Db7KIPFyPY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 38, "npz_gt_video_start_frame": 38, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 38, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1996_0_1"}, {"texts": ["The person turns the box."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Db7KIPFyPY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 50, "npz_gt_video_start_frame": 50, "npz_gt_video_end_frame": 70, "skip_frames_after_generation": 50, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1996_0_2"}, {"texts": ["The person opens the box."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Db7KIPFyPY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 70, "npz_gt_video_start_frame": 70, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 70, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1996_0_3"}, {"texts": ["A man whose hands are visible."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Db7KIPFyPY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 20, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1997_0_0"}, {"texts": ["The man is pointing at a carton."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Db7KIPFyPY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 20, "npz_gt_video_start_frame": 20, "npz_gt_video_end_frame": 42, "skip_frames_after_generation": 20, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1997_0_1"}, {"texts": ["The man is putting it on the wooden table."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Db7KIPFyPY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 42, "npz_gt_video_start_frame": 42, "npz_gt_video_end_frame": 62, "skip_frames_after_generation": 42, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1997_0_2"}, {"texts": ["The man is turning it."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Db7KIPFyPY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 62, "npz_gt_video_start_frame": 62, "npz_gt_video_end_frame": 71, "skip_frames_after_generation": 62, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1997_0_3"}, {"texts": ["The man is opening it."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Db7KIPFyPY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 71, "npz_gt_video_start_frame": 71, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 71, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1997_0_4"}, {"texts": ["A woman wearing a white top and a yellow apron is standing and making noodles while another woman wearing a white top and a yellow apron is standing and packing the food, and a group of people is standing and moving at the back."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0_Jn6lRpV-4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1998_0_0"}, {"texts": ["A woman wearing a white t-shirt and a yellow apron is standing on the left side of the first woman and packing the noodles."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0_Jn6lRpV-4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1998_1_0"}, {"texts": ["A woman wearing a white t-shirt and yellow apron is standing and making noodles while another woman on the left side wearing a white t-shirt and yellow apron is filling the noodles in a box and put the box in the bag."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0_Jn6lRpV-4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1999_0_0"}, {"texts": ["A woman wearing a white t-shirt, yellow apron is standing on the left side is packing the noodles while another woman on the right side is preparing the noodles and a group of people are moving and working at the back."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0_Jn6lRpV-4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_1999_1_0"}, {"texts": ["A person on the right side wearing white clothes is sitting near another person."], "durations": null, "exact_frames_per_prompt": [55], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0pDZwCFDUwc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 59, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2006_0_0"}, {"texts": ["A person on the left side wearing pink gloves is scraping a wall with a silver tool while another person wearing white clothes and a white hat is sitting on the right and holding a white plastic bag in their hands."], "durations": null, "exact_frames_per_prompt": [55], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0pDZwCFDUwc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 59, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2006_1_0"}, {"texts": ["A man wearing brown clothes is tearing the wrapping of the sausages and putting it in an electric cooker."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2FEwrS4jMBo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2013_0_0"}, {"texts": ["A person wearing a green t-shirt and cream pants is standing on the left side of the countertop, opening a container and taking out some slices of meat and putting it on the bread."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0ppo_8sZM7U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2014_0_0"}, {"texts": ["A person whose only lower body is visible is making a chicken sandwich."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0ppo_8sZM7U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2015_0_0"}, {"texts": ["A man wearing a black suit is standing outside."], "durations": null, "exact_frames_per_prompt": [58], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0QNaUcfF-Ak.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 62, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2016_0_ms_0"}, {"texts": ["The man is standing inside, behind the podium and holding a microphone, and then starts talking to another man."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0QNaUcfF-Ak.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 62, "npz_gt_video_start_frame": 62, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 62, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2016_0_ms_1"}, {"texts": ["A group of people is sitting, and a few are standing at the corner."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0QNaUcfF-Ak.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 37, "npz_gt_video_start_frame": 37, "npz_gt_video_end_frame": 62, "skip_frames_after_generation": 37, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2016_1_ms_0"}, {"texts": ["A man wearing a green t-shirt and jeans is taking out clothes from the washing machine and putting them into a basket."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/6fI9oGwmYaI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2017_0_0"}, {"texts": ["A girl wearing a white top is sitting and eating something while watching something on the green tablet."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2K0T_s36MwQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_201_0_0"}, {"texts": ["A man wearing a blue check shirt is at first lifting the car with a jack tool machine"], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4F2J-ESGoxY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 31, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2027_0_0"}, {"texts": ["The man loses the wheel nut with a wrench."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4F2J-ESGoxY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 31, "npz_gt_video_start_frame": 31, "npz_gt_video_end_frame": 55, "skip_frames_after_generation": 31, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2027_0_1"}, {"texts": ["The man removes the nut with his hand."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4F2J-ESGoxY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 55, "npz_gt_video_start_frame": 55, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 55, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2027_0_2"}, {"texts": ["A person is sitting and holding a tattoo pen and making a tattoo on the hand of a person."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2dc8r8yYnjA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_202_0_0"}, {"texts": ["A person is sitting and getting a tattoo on his hand by the first person."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2dc8r8yYnjA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 18, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_202_1_0"}, {"texts": ["And showing middle finger."], "durations": null, "exact_frames_per_prompt": [62], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2dc8r8yYnjA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 18, "npz_gt_video_start_frame": 18, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 18, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_202_1_1"}, {"texts": ["A girl whom upper half-body is visible wearing a yellow-printed black top is sitting on a chair and is cleaning her lips with a napkin and her hand."], "durations": null, "exact_frames_per_prompt": [32], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3seboaPCM6E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 36, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2033_0_0"}, {"texts": ["The girl starts speaking while eating the yellow bread."], "durations": null, "exact_frames_per_prompt": [45], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3seboaPCM6E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 36, "npz_gt_video_start_frame": 36, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 36, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2033_0_1"}, {"texts": ["A person whose hands are visible wearing a white shirt is tying a bow tie on a mannequin."], "durations": null, "exact_frames_per_prompt": [72], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/6pd92GSVcF8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 8, "npz_gt_video_start_frame": 8, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 8, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2040_1_0"}, {"texts": ["A man wearing a black-white striped sweatshirt is sitting on the left side of the third man while putting his hands on the table and looking in front then looking to the right while a man in a black shirt sitting in the middle is talking to them."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2MfVgeSj0EA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2041_0_0"}, {"texts": ["A man wearing a black shirt is sitting on the right side of the third man while holding a glass of beer and talking while another man wearing a black shirt is sitting and drinking."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2MfVgeSj0EA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2041_1_0"}, {"texts": ["A man wearing a black shirt is sitting in between the man wearing green-white hoodie and the man wearing black shirt, while holding a glass of beer."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2MfVgeSj0EA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2041_2_0"}, {"texts": ["A man on the left side wearing a printed hoodie is sitting with other men."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2MfVgeSj0EA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2042_0_0"}, {"texts": ["A man in the middle of the first and second man is speaking while holding a glass of beer."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2MfVgeSj0EA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2042_2_0"}, {"texts": ["A girl on the left is holding a shot glass in her hand then moves her hands while two other girls are also sitting on the right and holding shot glasses."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/63zXr8TfSFE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2045_0_0"}, {"texts": ["The girl starts eating a piece of lemon while two other girls also start eating a piece of lemon."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/63zXr8TfSFE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 44, "npz_gt_video_start_frame": 44, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 44, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2045_0_1"}, {"texts": ["The girl moves her hands."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/63zXr8TfSFE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 58, "npz_gt_video_start_frame": 58, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 58, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2045_0_2"}, {"texts": ["A girl wearing a cap on the right is moving her hands while two women are raising a toast with the drinks and enjoying themselves."], "durations": null, "exact_frames_per_prompt": [32], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/63zXr8TfSFE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 36, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2045_2_0"}, {"texts": ["The woman wearing a cap takes a shot glass in her hand while two women start eating something."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/63zXr8TfSFE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 36, "npz_gt_video_start_frame": 36, "npz_gt_video_end_frame": 57, "skip_frames_after_generation": 36, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2045_2_1"}, {"texts": ["The woman wearing a cap puts it on the table."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/63zXr8TfSFE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 57, "npz_gt_video_start_frame": 57, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 57, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2045_2_2"}, {"texts": ["A person wearing a brown bracelet is sitting inside a car, tearing a piece of paper."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-t3DBRyt35s.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 14, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2048_0_0"}, {"texts": ["The person making a Christians cross then showing the Christians cross."], "durations": null, "exact_frames_per_prompt": [66], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-t3DBRyt35s.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 14, "npz_gt_video_start_frame": 14, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 14, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2048_0_1"}, {"texts": ["A person wearing a grey shirt is driving the car while another person is tearing a paper and making a cross from it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-t3DBRyt35s.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2048_1_0"}, {"texts": ["A boy wearing a black-gray t-shirt and black jeans, is standing on the right side and is making a sandwich while spreading the brown sandwich cream on the white bread with the sandwich spatula and speaking."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5DYznLZymFw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_204_0_0"}, {"texts": ["A boy wearing a green-black t-shirt is sitting on a white chair and unwrapping a gift.\n"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-W1d_vhMasw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2050_0_0"}, {"texts": ["A man whose only hands are visible is showing different types of small spice bottles while holding them in his hands."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0vl1EYfOJnI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2052_0_0"}, {"texts": ["A person wearing a brown jacket whose hand is visible is pulling a fishing hook from the ice fishing hole while a person wearing black gloves is sitting on the snow surface and bending towards the ice fishing hole."], "durations": null, "exact_frames_per_prompt": [57], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/20VZNYJoI8Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 61, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2053_0_0"}, {"texts": ["The person puts hand in the ice fishing hole and catches a grey fish from the ice fishing hole while a person wearing black gloves is sitting on the snow surface on its knees and then stands up."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/20VZNYJoI8Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 61, "npz_gt_video_start_frame": 61, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 61, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2053_0_1"}, {"texts": ["A person wearing black shoes is standing on the snow surface while a man wearing olive green clothes is sitting near the ice hole and doing something."], "durations": null, "exact_frames_per_prompt": [50], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/20VZNYJoI8Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 54, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2053_1_0"}, {"texts": ["The person sits on knee and starts removing the snow while a person wearing a olive-green clothes is catching something out from the hole."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/20VZNYJoI8Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 54, "npz_gt_video_start_frame": 54, "npz_gt_video_end_frame": 73, "skip_frames_after_generation": 54, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2053_1_1"}, {"texts": ["The person stands up while the person wearing olive-green clothes is taking a big fish out from the hole."], "durations": null, "exact_frames_per_prompt": [5], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/20VZNYJoI8Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 73, "npz_gt_video_start_frame": 73, "npz_gt_video_end_frame": 78, "skip_frames_after_generation": 73, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2053_1_2"}, {"texts": ["A woman wearing a red t-shirt and blue jeans is standing and washing the dog while the dog turns his head and puts the tongue out"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-q_pKf-eLyE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2055_0_0"}, {"texts": ["A black dog is standing in a bathing tub and being washed by the woman."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-q_pKf-eLyE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2055_1_0"}, {"texts": ["A person whose hands and legs are visible, wearing a white-black t-shirt and blue jeans is sitting on the black surface, folding the white cloth with their hands and then ghosting the cloth."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0CSuK4stBPw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2056_0_0"}, {"texts": ["A woman wearing a black dress is sitting on a chair, speaking, laughing and moving her right hand."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3FUreUTGmFY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 39, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2058_0_0"}, {"texts": ["A woman wearing a blue dress is sitting on a black chair."], "durations": null, "exact_frames_per_prompt": [38], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3FUreUTGmFY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 42, "npz_gt_video_start_frame": 42, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 42, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2058_1_0"}, {"texts": ["A person wearing a black t-shirt whose only hands are visible is peeling a potato with a black peeler."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5-EI0-8WOqo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_205_0_0"}, {"texts": ["A man wearing a black t-shirt is standing"], "durations": null, "exact_frames_per_prompt": [11], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/smVeU71ZpDE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 15, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_206_0_0"}, {"texts": ["The man is pulling cork from the bottle with a plier."], "durations": null, "exact_frames_per_prompt": [65], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/smVeU71ZpDE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 15, "npz_gt_video_start_frame": 15, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 15, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_206_0_1"}, {"texts": ["A man wearing a dark green t-shirt is grinding meat in the black meat grinder."], "durations": null, "exact_frames_per_prompt": [53], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/02Vl8JcqbAE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 57, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2077_0_0"}, {"texts": ["A man wearing a red t-shirt is riding on an elephant while holding a stick a man whose half body visible recording the video"], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-SeJQZQSt0M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 47, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2078_0_0"}, {"texts": ["A man is also riding on an elephant while sitting behind the man in a red t-shirt."], "durations": null, "exact_frames_per_prompt": [39], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-SeJQZQSt0M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 8, "npz_gt_video_start_frame": 8, "npz_gt_video_end_frame": 47, "skip_frames_after_generation": 8, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2078_1_0"}, {"texts": ["An elephant is walking in a straight direction with the two men riding on its back."], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-SeJQZQSt0M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 47, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2078_2_0"}, {"texts": ["A person wearing black clothes whose left hand is visible is turning the pages of a magazine and a brown cat is sitting on the table under the magazine and then starts moving."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0qV2fTbgXAQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_207_0_0"}, {"texts": ["A brown cat is lying while a person whose hand is visible is flipping the pages of a magazine."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0qV2fTbgXAQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 32, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_207_1_0"}, {"texts": ["The brown cat starts moving under the magazine while the person is moving the magazine over the cat."], "durations": null, "exact_frames_per_prompt": [48], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0qV2fTbgXAQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 32, "npz_gt_video_start_frame": 32, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 32, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_207_1_1"}, {"texts": ["A man wearing a black jacket is standing and drinking."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5EeJQ99bVvc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 25, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2083_0_0"}, {"texts": ["The man wipes his mouth with a tissue while the person wearing a black t-shirt is filming it."], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5EeJQ99bVvc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 25, "npz_gt_video_start_frame": 25, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 25, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2083_0_1"}, {"texts": ["The man holds the glass while others look at him."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5EeJQ99bVvc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 58, "npz_gt_video_start_frame": 58, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 58, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2083_0_2"}, {"texts": ["A man wearing camouflage clothes is walking in the green field holding a gun while there are white and black dog on the ground and running and the white dog fetches the bird  and run towards left"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1K4FIaiPL6I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2084_0_0"}, {"texts": ["A man wearing a brown cap is shaking hands with the third dog."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1K4FIaiPL6I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 28, "npz_gt_video_start_frame": 28, "npz_gt_video_end_frame": 43, "skip_frames_after_generation": 28, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2084_2_0"}, {"texts": ["The man walks."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1K4FIaiPL6I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 43, "npz_gt_video_start_frame": 43, "npz_gt_video_end_frame": 56, "skip_frames_after_generation": 43, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2084_2_1"}, {"texts": ["A black dog is running in the green field while a beige colored dog is moving on the grass surface, and two men are walking on the grass while holding shotguns."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1K4FIaiPL6I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 28, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2084_3_0"}, {"texts": ["A white dog is running in the green field while the black dog comes towards the white dog and the man in orange vest is walking towards them."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1K4FIaiPL6I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 27, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2084_4_0"}, {"texts": ["A pigeon is getting picked by the third dog in its mouth."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1K4FIaiPL6I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 60, "npz_gt_video_start_frame": 60, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 60, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2084_6_0"}, {"texts": ["A woman wearing a white-dark blue dress and some jewellery is holding a spatula and melting the butter in a pan on the stove."], "durations": null, "exact_frames_per_prompt": [44], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-JRT9aCAVsA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 48, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2085_0_0"}, {"texts": ["The woman wearing a white-dark blue dress and some jewellery is breaking the shell of an egg into the pan."], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-JRT9aCAVsA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 48, "npz_gt_video_start_frame": 48, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 48, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2085_0_1"}, {"texts": ["A woman wearing a black top is defying her eyebrow with a tweezer."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0R0Aklb0X3Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2087_0_0"}, {"texts": ["A man whose hand is visible pulls the bed sheet."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/j08arN8v1jM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 20, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2088_0_0"}, {"texts": ["The man starts moving his hand."], "durations": null, "exact_frames_per_prompt": [60], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/j08arN8v1jM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 20, "npz_gt_video_start_frame": 20, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 20, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2088_0_1"}, {"texts": ["A person with only their hands visible is frying an omelette in a black pan with a spatula."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1niNKup9egs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 50, "npz_gt_video_start_frame": 50, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 50, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2091_0_0"}, {"texts": ["A woman wearing black clothes is standing and is caressing the black horse on the road."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Mv1_ZvyBfU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 39, "npz_gt_video_start_frame": 39, "npz_gt_video_end_frame": 67, "skip_frames_after_generation": 39, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2097_0_0"}, {"texts": ["A woman wearing a white top is walking on the road with her right arm up and is holding a rope."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Mv1_ZvyBfU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 67, "npz_gt_video_start_frame": 67, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 67, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2097_1_ms_0"}, {"texts": ["A white horse is standing on the grey road."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Mv1_ZvyBfU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2097_2_ms_0"}, {"texts": ["A black horse is also standing on the gray road and is being caressed by person one."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Mv1_ZvyBfU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 39, "npz_gt_video_start_frame": 39, "npz_gt_video_end_frame": 66, "skip_frames_after_generation": 39, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2097_3_0"}, {"texts": ["A lady wearing a grey top and pink shorts is riding on a brown camel while a man wearing a white cloth is holding a leash of the camel and walking ahead."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0TFD222QOOw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2098_0_0"}, {"texts": ["A man wearing white clothes is walking in front and holding the camel rope on which the lady is riding."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0TFD222QOOw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 11, "npz_gt_video_start_frame": 11, "npz_gt_video_end_frame": 29, "skip_frames_after_generation": 11, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2098_1_0"}, {"texts": ["A white camel is walking while carrying a lady on his back while a man wearing white outfit is walking along with the camel and he is holding a rope that is attached to the camel."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0TFD222QOOw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2098_2_0"}, {"texts": ["A child wearing a pink top and red pants is held by a boy on his back while the boy released the girl on the floor"], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1-9KSslytrk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 27, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2099_0_0"}, {"texts": ["The child gets down and walks towards the front and falls down on the red-cream carpet while crying."], "durations": null, "exact_frames_per_prompt": [53], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1-9KSslytrk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 27, "npz_gt_video_start_frame": 27, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 27, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2099_0_1"}, {"texts": ["A boy wearing a gray t-shirt and blue jeans is holding a child on his back and walking, then putting the child down on the red-cream carpet while a child wearing a pink top is crying and after putting him down by a boy child starts running."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1-9KSslytrk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 34, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2099_2_0"}, {"texts": ["A kid wearing a pink cloth is sitting on the wooden stool on the left side and watching in right side the girl give pose to photo while eating."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3xssCibHYe0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2101_0_0"}, {"texts": ["A kid wearing green cloth is sitting on the wooden chair on the right side and moving his body and holding a red toy while the other kid sits along with her"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3xssCibHYe0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2101_1_0"}, {"texts": ["A woman on the left side, wearing a blue jacket and grey pants, is sitting on the chair. She stands and walks towards the right side, near the table a man wearing a red shirt sitting on chair."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/24cKLt2hz6Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2105_0_0"}, {"texts": ["A man on the right side, wearing a red-black shirt and blue jeans is sitting on the chair.\n while a woman wearing grey pants is sitting then moves towards the right and picks up something."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/24cKLt2hz6Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2105_1_0"}, {"texts": ["A lady wearing a blue jacket is standing on a brown muddy surface and combing the tail of a brown pony."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0qP7PEmZwQw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2107_0_0"}, {"texts": ["A brown pony is standing on a brown muddy surface and tied with ropes and a lady is combing its tail."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0qP7PEmZwQw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2107_1_0"}, {"texts": ["A woman wearing a black cloth is sitting and drinking from the glass while a group of people are sitting and standing at the back."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/6UihMjZSmYY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2108_0_0"}, {"texts": ["A woman wearing a white top is standing and doing hand gestures.\n"], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4EoWG3ltIzw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 52, "npz_gt_video_start_frame": 52, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 52, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2109_0_0"}, {"texts": ["A man wearing a black jacket is sitting and eating noodles."], "durations": null, "exact_frames_per_prompt": [51], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1Ge5azXYS3k.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 55, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2110_0_0"}, {"texts": ["A man wearing a black jacket, brown pants and a brown cap is sitting on the back of the horse and riding from left to right."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-gRuiW2S6kM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2115_0_0"}, {"texts": ["A grayish-white horse is walking from left to right while carrying a man on his back."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-gRuiW2S6kM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2115_1_0"}, {"texts": ["A man wearing a blue t-shirt is sitting on a horse and riding it on a soil surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-gRuiW2S6kM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2116_0_0"}, {"texts": ["A gray horse is walking on a soil surface with a man sitting on it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-gRuiW2S6kM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2116_1_0"}, {"texts": ["A man wearing a brown cap is riding a horse in the right direction on a brown soil surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-gRuiW2S6kM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2117_0_0"}, {"texts": ["A grey horse taking a man on its back is moving in the right direction on a brown soil surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-gRuiW2S6kM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2117_1_0"}, {"texts": ["A person whose only hand is visible is pouring the white batter into a black utensil."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2hXdCr316is.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2119_0_0"}, {"texts": ["A person wearing a gray black striped t-shirt is standing on the right side and pushing meat in the meat grinder machine."], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/41PGTc3XKEY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 41, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_211_0_0"}, {"texts": ["A woman whose hand is visible is pouring batter into a black tray with a jug."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2hXdCr316is.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2120_0_0"}, {"texts": ["A person whose only hand and legs are visible is switching on the paper shredder."], "durations": null, "exact_frames_per_prompt": [39], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/6JeRGeHkpDg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 43, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2125_0_0"}, {"texts": ["The person is shedding a white paper."], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/6JeRGeHkpDg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 43, "npz_gt_video_start_frame": 43, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 43, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2125_0_1"}, {"texts": ["A person whose hand is visible is holding a piece of paper, touching the shredder machine and turning it on."], "durations": null, "exact_frames_per_prompt": [48], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/6JeRGeHkpDg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 52, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2126_0_0"}, {"texts": ["The man is putting the paper inside the shredder machine."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/6JeRGeHkpDg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 52, "npz_gt_video_start_frame": 52, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 52, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2126_0_1"}, {"texts": ["A man wearing a bee veil is standing on the right side and watching the other man on the left side while holding a mike."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/8uCkXKBWxfo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2128_1_0"}, {"texts": ["A girl wearing light green clothes is sitting on the white kitchen counter-top and then pushing the stuffer filler stick into the grinder while a woman wearing a maroon top is standing on the right side and cutting meat."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-RP8pbG-JpI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 32, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2131_0_0"}, {"texts": ["The girl is looking in the meat grinder machine while the woman wearing a maroon top is putting the meat in the grinder machine."], "durations": null, "exact_frames_per_prompt": [48], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-RP8pbG-JpI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 32, "npz_gt_video_start_frame": 32, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 32, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2131_0_1"}, {"texts": ["A woman wearing a purple top is standing and cutting the meat while a girl is taking out the black object and peeking at the hole of the meat grinder."], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-RP8pbG-JpI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 35, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2131_1_0"}, {"texts": ["The woman is putting the meat into the meat grinder."], "durations": null, "exact_frames_per_prompt": [44], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-RP8pbG-JpI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 35, "npz_gt_video_start_frame": 35, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 35, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2131_1_1"}, {"texts": ["A person wearing a black cap is shearing a white sheep with a sheep shearing scissor and a sheep is moving while a person standing on the right moves."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0NeDA66NvCw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2135_0_0"}, {"texts": ["A white sheep is lying on a brown canvas while the man shearing the wool from sheep."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0NeDA66NvCw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2135_2_0"}, {"texts": ["A baby girl wearing a red top is sitting and eating an ice cream from a person."], "durations": null, "exact_frames_per_prompt": [74], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0vldOeJCp0E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 78, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2138_0_0"}, {"texts": ["A person whose hands are visible is holding an ice cream and feeding a baby girl."], "durations": null, "exact_frames_per_prompt": [74], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0vldOeJCp0E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 78, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2138_1_0"}, {"texts": ["A man standing on a green grass surface is speaking and swinging the golf stick."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0oxvvCfe8ws.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2139_0_0"}, {"texts": ["A man wearing a purple-white t-shirt and gray trousers is teaching how to hit a golf ball shot."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0oxvvCfe8ws.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2140_0_0"}, {"texts": ["A woman wearing a black top is standing and moving in a fuel station, while speaking on her phone."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/54LV_Bx_O2Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2143_0_0"}, {"texts": ["A woman wearing a black top is standing and moving in a fuel station while speaking on her phone."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/54LV_Bx_O2Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2144_0_0"}, {"texts": ["A person wearing a light blue shirt tear the packet"], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3jADp5mXnAM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 32, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2146_0_0"}, {"texts": ["The person puts the piece of meat on a bread slice."], "durations": null, "exact_frames_per_prompt": [48], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3jADp5mXnAM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 32, "npz_gt_video_start_frame": 32, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 32, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2146_0_1"}, {"texts": ["A lady wearing an orange t-shirt is sitting on the white surface, holding a girl, and helping her to pick something from the water with an aquarium fish net while a group of people are moving around them."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2UxokcqnsFk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2157_0_0"}, {"texts": ["A girl wearing white shirt is picking something from the water with an aquarium fish net and is being helped by a lady."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2UxokcqnsFk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2157_1_0"}, {"texts": ["A boy wearing grey clothes is holding a plier and removing the lid of a glass bottle."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/QXxzSmC2g5s.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2159_0_0"}, {"texts": ["A boy, sitting in a man's lap while raising his hands then a man wearing a black jacket is giving a piece of bread the boy."], "durations": null, "exact_frames_per_prompt": [53], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-ZEG-ZimwJg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 57, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2162_0_0"}, {"texts": ["The boy takes a doughnut piece from the man."], "durations": null, "exact_frames_per_prompt": [11], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-ZEG-ZimwJg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 57, "npz_gt_video_start_frame": 57, "npz_gt_video_end_frame": 68, "skip_frames_after_generation": 57, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2162_0_1"}, {"texts": ["The boy starts eating it."], "durations": null, "exact_frames_per_prompt": [12], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-ZEG-ZimwJg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 68, "npz_gt_video_start_frame": 68, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 68, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2162_0_2"}, {"texts": ["A man wearing a dark blue jacket is giving a piece of doughnut to the boy while holding him with one hand on his lap."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-ZEG-ZimwJg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2162_1_0"}, {"texts": ["A person wearing a black shirt and black pants is putting the golf stick near the golf ball."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0mze20DX6Mw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 18, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2163_0_0"}, {"texts": ["The person hitting the golf ball in its left direction on the green carpet."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0mze20DX6Mw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 18, "npz_gt_video_start_frame": 18, "npz_gt_video_end_frame": 48, "skip_frames_after_generation": 18, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2163_0_1"}, {"texts": ["A person whose hand is visible only, is picking up a fish from the fish net."], "durations": null, "exact_frames_per_prompt": [44], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-yTIisA8eNI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 48, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2165_0_0"}, {"texts": ["A bird is standing far on the wooden dock and a person throws something towards the bird."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-yTIisA8eNI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 54, "npz_gt_video_start_frame": 54, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 54, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2165_2_0"}, {"texts": ["A boy on the left side wearing a printed blue t-shirt is laughing and speaking while a woman is at the back and the boy in the right t-shirt is on the right, they are laughing."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/14Sph2O9VtQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2166_0_0"}, {"texts": ["A boy on the right side wearing a red t-shirt is laughing with the first boy while a woman also started laughing."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/14Sph2O9VtQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2166_1_0"}, {"texts": ["A woman wearing a pink sweater is laughing and sitting behind the boy wearing red t-shirt while the boys are also laughing."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/14Sph2O9VtQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2166_2_0"}, {"texts": ["A person wearing purple clothes is standing and grinding the meat in a grinder and collecting in a white bag.\n"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4ZFGw0DSHlo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2170_0_0"}, {"texts": ["A man, whose upper half-body is visible, wearing a purple t-shirt, is standing on the left side and is holding a white pouch in his left hand with the meat grinder machine and he is pouring the meat into the meat grinder machine"], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4ZFGw0DSHlo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 47, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2171_0_0"}, {"texts": ["The man is pushing the meat into the meat grinder machine with the stuffer filler stick while holding the stuffer filler stick in his right hand."], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4ZFGw0DSHlo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 47, "npz_gt_video_start_frame": 47, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 47, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2171_0_1"}, {"texts": ["A man wearing a gray suit is sitting, holding a bottle of wine, moving his other hand, and speaking."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1QSLrffPCvc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 32, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2172_0_ms_0"}, {"texts": ["A baby wearing a white-pink top is sitting in a baby feeding chair, holding a spoon."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-ZnCh1h0pbo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 34, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2173_0_0"}, {"texts": ["The baby wearing a white-pink top is moving its hand."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-ZnCh1h0pbo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 34, "npz_gt_video_start_frame": 34, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 34, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2173_0_1"}, {"texts": ["A person of whom only hands are visible is mixing the melon in a glass bowl with a fork while a boy wearing a t-shirt is standing and talking."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-96BKD_JX_0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2175_0_0"}, {"texts": ["A boy wearing a black t-shirt is moving and speaking while a woman is mixing the food in a bowl with the help of the spoon."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-96BKD_JX_0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2175_1_0"}, {"texts": ["A boy wearing a printed black t-shirt is standing behind the glass bowl while another person is mixing the fruit salad."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-96BKD_JX_0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2176_1_0"}, {"texts": ["A woman wearing a green top and black pants is sitting on the cream chair and doing something on the right side while a person wearing black clothes is rotating the handle of the peeler."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-T5t3u6xYK4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2185_0_0"}, {"texts": ["A person wearing a black t-shirt is standing."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-T5t3u6xYK4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 30, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2186_1_0"}, {"texts": ["The person is peeling an apple with an apple peeling machine."], "durations": null, "exact_frames_per_prompt": [50], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-T5t3u6xYK4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 30, "npz_gt_video_start_frame": 30, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 30, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2186_1_1"}, {"texts": ["A baby wearing yellow clothes is being held by a person while the baby is trying to touch the cat which is lying on the bed while a person whom hand is visible is caressing the cat."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-iMQ2D3ES7c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2191_0_0"}, {"texts": ["A black cat is lying on the bed while being touched by the baby."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-iMQ2D3ES7c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2191_1_0"}, {"texts": ["The cat is being caressed by the person on the right side."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-iMQ2D3ES7c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 50, "npz_gt_video_start_frame": 50, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 50, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2191_1_1"}, {"texts": ["A person of whom only hands are visible is lying on the bed near the baby and holding the baby while a black cat is sitting in front of the baby and being petted by another person whose hand is visible."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-iMQ2D3ES7c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2191_2_0"}, {"texts": ["A man wearing a blue t-shirt and blue jeans is riding a horse while the woman holds the umbrella and walks along with the horse."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-cMKlmFfK5c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2195_0_0"}, {"texts": ["A brown horse is walking forward.  while the man wearing blue t-shirt is riding the horse and the person wearing black t-shirt is holding the umbrella and walking beside the horse"], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-cMKlmFfK5c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 20, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2195_1_0"}, {"texts": ["The horse turns backward."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-cMKlmFfK5c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 20, "npz_gt_video_start_frame": 20, "npz_gt_video_end_frame": 39, "skip_frames_after_generation": 20, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2195_1_1"}, {"texts": ["The horse starts walking while attached to a drum."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-cMKlmFfK5c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 39, "npz_gt_video_start_frame": 39, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 39, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2195_1_2"}, {"texts": ["A woman wearing a black top and black trousers is walking holding an umbrella while a man wearing blue t-shirt riding horse"], "durations": null, "exact_frames_per_prompt": [75], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-cMKlmFfK5c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 5, "npz_gt_video_start_frame": 5, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 5, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2195_2_0"}, {"texts": ["A man wearing a checkered shirt is standing on the right side and blow drying a dog with a blow dryer."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2jLbjc1My-Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2197_0_0"}, {"texts": ["A brown dog is standing on a green chair and getting blow dried by the man."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2jLbjc1My-Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2197_1_0"}, {"texts": ["A kid wearing a white vest and gray shorts is standing and feeding a carrot to a goat while a man wearing a white t-shirt is giving a carrot to a goat, a group of kids are sitting, standing, and looking at the goats. A group of cars are moving at the back."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1FpAg9qA5AY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2198_0_0"}, {"texts": ["A man wearing a white t-shirt and brown shorts is standing and feeding a carrot to another goat while a boy wearing a white vest is standing and feeding a carrot to the goat, a girl wearing a multicolored top is sitting in a pram on the right side and watching, a person wearing a blue top is coming from the backside and taking a carry bag from the man, a group of goats are standing behind the fencing, and a grey car is moving from right to left on the road in the backside."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1FpAg9qA5AY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2198_1_0"}, {"texts": ["A boy wearing a brown t-shirt is riding an elephant and raising his hands while other boy wearing black shirt sitting behind him and other boy wearing blue shirt and gray jeans is walking along them."], "durations": null, "exact_frames_per_prompt": [45], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0eSFmX-NTIU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 49, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2199_0_0"}, {"texts": ["A boy wearing a black shirt is riding on the elephant while the man with blue t-shirt is holding the elephant and walking along with it"], "durations": null, "exact_frames_per_prompt": [45], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0eSFmX-NTIU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 49, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2199_1_0"}, {"texts": ["A boy wearing a blue t-shirt is walking on the soil path and holding the rope of the elephant while the other two people sit on the elephant's back and enjoy the ride."], "durations": null, "exact_frames_per_prompt": [44], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0eSFmX-NTIU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 48, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2199_2_0"}, {"texts": ["A brown elephant is walking on the soil path and carrying people on its back while a man in a blue T-shirt walking along with them."], "durations": null, "exact_frames_per_prompt": [45], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0eSFmX-NTIU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 49, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2199_3_0"}, {"texts": ["A woman wearing a purple top and gray jeans is bending over and doing something while a woman wearing a purple-white shirt is sorting clothes."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1bn4BAJa0ws.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2202_0_0"}, {"texts": ["The woman is getting up."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1bn4BAJa0ws.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 45, "npz_gt_video_start_frame": 45, "npz_gt_video_end_frame": 54, "skip_frames_after_generation": 45, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2202_0_1"}, {"texts": ["The woman is putting some clothes in front."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1bn4BAJa0ws.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 54, "npz_gt_video_start_frame": 54, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 54, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2202_0_2"}, {"texts": ["A woman wearing a purple-gray top and blue jeans is standing, taking out some clothes from the bucket and throwing them here and there while another woman wearing a purple top is leaning forward and picking up some clothes and throwing it on the front."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1bn4BAJa0ws.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2202_1_0"}, {"texts": ["A girl wearing a blue check top and shorts is riding on a brown horse on the green grass surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-CQ7GWxuEUc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2208_0_0"}, {"texts": ["A brown horse is walking while carrying a girl on his back on a green grass surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-CQ7GWxuEUc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2208_1_0"}, {"texts": ["A girl whose upper half-body is visible wearing a dark blue t-shirt is standing on the left side, holding a milk bottle and pouring milk into the food mixer machine from the bottle."], "durations": null, "exact_frames_per_prompt": [58], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4QBzHC4eUEk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 62, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2209_0_0"}, {"texts": ["The girl is keeping the bottle on the countertop."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4QBzHC4eUEk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 62, "npz_gt_video_start_frame": 62, "npz_gt_video_end_frame": 72, "skip_frames_after_generation": 62, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2209_0_1"}, {"texts": ["The girl is smiling."], "durations": null, "exact_frames_per_prompt": [8], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4QBzHC4eUEk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 72, "npz_gt_video_start_frame": 72, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 72, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2209_0_2"}, {"texts": ["A person wearing a graphic blue t-shirt is folding a black t-shirt on the bed."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0p_xMShcYuY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_220_0_0"}, {"texts": ["A baby wearing white clothes is sitting, laughing."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0AaQpoTDKmI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2216_0_0"}, {"texts": ["The baby is eating something."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0AaQpoTDKmI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 44, "npz_gt_video_start_frame": 44, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 44, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2216_0_1"}, {"texts": ["A person whose upper half-body is visible, wearing a blue t-shirt and is folding a black t-shirt on the bed with their hands."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0p_xMShcYuY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_221_0_0"}, {"texts": ["A woman wearing a brown top is folding a yellow napkin on the white table."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0N9X4WX7x5E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2220_0_0"}, {"texts": ["A person wearing blue jeans is sitting and pressing the black white bird while another person wearing black pants is sitting at the back."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0NxxH7g8O5s.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2222_0_0"}, {"texts": ["A black white bird is sitting in the first person's lap while a person wearing white shoes is standing on the white surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0NxxH7g8O5s.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2222_2_0"}, {"texts": ["A bending person wearing a t-shirt is shearing a brown sheep with a sheep shearing scissor."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0zFbaHxfruk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2223_0_0"}, {"texts": ["A brown sheep is lying on a brown canvas.\n while a man wearing a white and black t-shirt is shearing the wool from the sheep."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0zFbaHxfruk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2223_2_0"}, {"texts": ["A child wearing a purple cloth is sitting on the chair, her one hand on the white table, and eating cake with her fingers."], "durations": null, "exact_frames_per_prompt": [62], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/27_oTba7mik.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 66, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2224_0_0"}, {"texts": ["A man wearing a yellow outfit is sitting."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1QbngReum84.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 34, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2225_1_0"}, {"texts": ["The man is drinking from the glass and looking here and there."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1QbngReum84.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 34, "npz_gt_video_start_frame": 34, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 34, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2225_1_1"}, {"texts": ["A woman wearing a pink-black top is wrapping a bandage on the hand of the person."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0tIzlcEDrFw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2227_0_0"}, {"texts": ["The woman wearing a pink-black top is unwrapping it and the person moves its arm."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0tIzlcEDrFw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 45, "npz_gt_video_start_frame": 45, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 45, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2227_0_1"}, {"texts": ["A person wearing a white coat is standing and getting a bandage wrapped by the woman wearing a white coat on the left side."], "durations": null, "exact_frames_per_prompt": [42], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0tIzlcEDrFw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 46, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2227_1_0"}, {"texts": ["The person's bandage is unwrapped by the woman."], "durations": null, "exact_frames_per_prompt": [34], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0tIzlcEDrFw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 46, "npz_gt_video_start_frame": 46, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 46, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2227_1_1"}, {"texts": ["A lady wearing pink clothes is trimming the fur of white bichon frise."], "durations": null, "exact_frames_per_prompt": [55], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0tLEOKc-gto.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 59, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2234_0_0"}, {"texts": ["The lady is wearing a pink dress to white bichon frise."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0tLEOKc-gto.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 59, "npz_gt_video_start_frame": 59, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 59, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2234_0_1"}, {"texts": ["A white bichon frise is sitting on a table and the lady is trimming his fur and wearing a pink dress."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0tLEOKc-gto.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2234_1_0"}, {"texts": ["A woman wearing a pink outfit with a glove in her right hand, is standing."], "durations": null, "exact_frames_per_prompt": [45], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3rzHClxEVqE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 49, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2239_0_0"}, {"texts": ["The woman is opening the packet."], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3rzHClxEVqE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 49, "npz_gt_video_start_frame": 49, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 49, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2239_0_1"}, {"texts": ["A person whom hands are visible is unfolding a paper."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-YnkBKzWZsA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_223_0_0"}, {"texts": ["A man whose only hand is visible is adding coconut milk to the vegetables in a pan"], "durations": null, "exact_frames_per_prompt": [44], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1wt9JVR9v1E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 48, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2241_0_0"}, {"texts": ["A man whose only hand is visible is mixing them with a spoon."], "durations": null, "exact_frames_per_prompt": [32], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1wt9JVR9v1E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 48, "npz_gt_video_start_frame": 48, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 48, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2241_0_1"}, {"texts": ["A man wearing a white t-shirt standing on the right is eating food in a food-eating competition."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2-Tq5LvwJIc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2242_0_0"}, {"texts": ["A man wearing a blue-red jacket is standing and holding a fish in his hand while another man wearing a brown-green jacket is sitting while holding a fishing rod."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2EwWdFZmsQA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 24, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_224_0_0"}, {"texts": ["A man wearing a camouflage jacket is sitting.\n while another man wearing a red-black jacket is picking a fish."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2EwWdFZmsQA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 18, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_224_1_0"}, {"texts": ["The man is holding a fishing rod in his hand and the other man throws the fish away."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2EwWdFZmsQA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 18, "npz_gt_video_start_frame": 18, "npz_gt_video_end_frame": 34, "skip_frames_after_generation": 18, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_224_1_1"}, {"texts": ["A man wearing a grey t-shirt and blue jeans is sitting on the brown horse and riding."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/06kWYuf1qrU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 22, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2252_0_0"}, {"texts": ["The man wearing a grey t-shirt and blue jeans falls on the soil surface, gets up."], "durations": null, "exact_frames_per_prompt": [11], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/06kWYuf1qrU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 22, "npz_gt_video_start_frame": 22, "npz_gt_video_end_frame": 34, "skip_frames_after_generation": 22, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2252_0_1"}, {"texts": ["The man wearing a grey t-shirt and blue jeans walks back towards the fence the brown horse also starts walking ."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/06kWYuf1qrU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 34, "npz_gt_video_start_frame": 34, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 34, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2252_0_2"}, {"texts": ["A brown horse is walking on the soil surface and starts jumping while carrying a man wearing blue jeans on its back, and another black-white horse is standing on the soil surface on the right."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/06kWYuf1qrU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 26, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2252_1_0"}, {"texts": ["The brown horse walks towards the left side while the man stands up and walks towards the front."], "durations": null, "exact_frames_per_prompt": [54], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/06kWYuf1qrU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 26, "npz_gt_video_start_frame": 26, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 26, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2252_1_1"}, {"texts": ["A boy wearing a black t-shirt is sitting on a red sofa while a boy wearing red t-shirt is sitting on a red sofa and eating noodles."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-a4MRN79j9I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 14, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2254_0_0"}, {"texts": ["The boy is eating noodles from a white plate with a fork while the boy wearing red t-shirt is drinking a black drinks from the glass."], "durations": null, "exact_frames_per_prompt": [65], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-a4MRN79j9I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 14, "npz_gt_video_start_frame": 14, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 14, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2254_0_1"}, {"texts": ["A boy wearing a red-blue t-shirt is sitting on the red sofa and eating noodles while a boy wearing a black t-shirt is sitting on the right side of the sofa and eating noodles, and other people are sitting in the back."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-a4MRN79j9I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 39, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2254_1_0"}, {"texts": ["The boy takes a glass from the table."], "durations": null, "exact_frames_per_prompt": [34], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-a4MRN79j9I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 39, "npz_gt_video_start_frame": 39, "npz_gt_video_end_frame": 73, "skip_frames_after_generation": 39, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2254_1_1"}, {"texts": ["The boy starts drinking."], "durations": null, "exact_frames_per_prompt": [7], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-a4MRN79j9I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 73, "npz_gt_video_start_frame": 73, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 73, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2254_1_2"}, {"texts": ["A man wearing a black suit is standing and moving his hand while talking."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/52kQfr25NXw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2255_0_0"}, {"texts": ["A man wearing a black cloth on the left side is standing and hugging the second man and keeping his head on the shoulder of the second man."], "durations": null, "exact_frames_per_prompt": [55], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1EzJU1Ks9NU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 59, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2258_0_0"}, {"texts": ["A man wearing a black cloth on the right side is standing and hugging the first man and tapping his back."], "durations": null, "exact_frames_per_prompt": [55], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1EzJU1Ks9NU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 59, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2258_1_0"}, {"texts": ["A man wearing a yellow-orange t-shirt is sitting on a grey chair and speaking on the microphone."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5fdoTliqIoM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 34, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2260_0_0"}, {"texts": ["A man wearing a grey jacket is sitting behind a wooden counter while another man wearing a black suit is walking towards the first man, holding a paper."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5fdoTliqIoM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 36, "npz_gt_video_start_frame": 36, "npz_gt_video_end_frame": 49, "skip_frames_after_generation": 36, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2260_1_0"}, {"texts": ["The man starts looking at a file shown by the other man while a group of people are sitting."], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5fdoTliqIoM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 49, "npz_gt_video_start_frame": 49, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 49, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2260_1_1"}, {"texts": ["A man wearing a grey shirt is sitting on a grey chair while a man wearing a black suit is walking towards him and another man wearing a black suit is sitting besides him."], "durations": null, "exact_frames_per_prompt": [45], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5fdoTliqIoM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 35, "npz_gt_video_start_frame": 35, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 35, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2260_5_0"}, {"texts": ["A girl wearing a blue top is sitting and eating food."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0K82C4cGttw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2262_0_0"}, {"texts": ["A woman in the ocean, wearing a black swimming suit with an oxygen cylinder on her back, holding a bottle and inserting a knife near the neck and a group of people wearing scuba diving gear are swimming in the ocean."], "durations": null, "exact_frames_per_prompt": [48], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5fHpBJKDecs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 52, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2269_0_0"}, {"texts": ["The woman starts drinking from the bottle."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5fHpBJKDecs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 52, "npz_gt_video_start_frame": 52, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 52, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2269_0_1"}, {"texts": ["A man wearing a gray cloth is in the ocean holding a bottle."], "durations": null, "exact_frames_per_prompt": [48], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5fHpBJKDecs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 52, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2269_1_0"}, {"texts": ["The man is drinking from it."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5fHpBJKDecs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 52, "npz_gt_video_start_frame": 52, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 52, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2269_1_1"}, {"texts": ["A person wearing red clothes is sitting and drawing on a white paper."], "durations": null, "exact_frames_per_prompt": [74], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1N5e1bYo63g.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 6, "npz_gt_video_start_frame": 6, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 6, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_226_0_0"}, {"texts": ["A person wearing a gray vest and blue shorts is jumping around."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-1QHAHq6DnE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 33, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2271_0_0"}, {"texts": ["The person cracks and opens an egg."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-1QHAHq6DnE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 33, "npz_gt_video_start_frame": 33, "npz_gt_video_end_frame": 69, "skip_frames_after_generation": 33, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2271_0_1"}, {"texts": ["The person starts jumping again."], "durations": null, "exact_frames_per_prompt": [11], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-1QHAHq6DnE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 69, "npz_gt_video_start_frame": 69, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 69, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2271_0_2"}, {"texts": ["A person wearing a red t-shirt and blue jeans is sitting behind the group of kids and holding a bottle."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-6ABBKUFtOY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2272_1_0"}, {"texts": ["A boy wearing a black-white-red striped t-shirt is standing on the carpet and counting money."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0ZPwjqS38CA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 32, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2274_0_0"}, {"texts": ["A man wearing a yellow t-shirt is sitting on the right side of the person and holding a bunch of notes and arranging them properly."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2jVmiP1x1G8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2275_1_0"}, {"texts": ["A woman wearing a black-white top is holding a packet of popcorn and eating from the packet."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-RL4cP38DpU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2276_0_0"}, {"texts": ["A girl wearing a light blue jacket is standing and pouring hot water from the kettle onto the green cup."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/37t1CfrPzJM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2277_0_0"}, {"texts": ["A woman wearing a green top is standing while making an omelet."], "durations": null, "exact_frames_per_prompt": [57], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-IVX-ERJDqE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 61, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2279_0_0"}, {"texts": ["The woman is holding the handle of the pan and cutting the omelet with the spoon."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-IVX-ERJDqE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 61, "npz_gt_video_start_frame": 61, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 61, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2279_0_1"}, {"texts": ["A person whose hands are visible is folding a piece of green cloth."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1gTLnnFf13o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2282_0_0"}, {"texts": ["A person whose hands are visible is folding a green cloth."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1gTLnnFf13o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2283_0_0"}, {"texts": ["A person wearing a brown sweatshirt is standing."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-ibEWRNi1Cc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2285_0_0"}, {"texts": ["The person is folding a light green cloth."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-ibEWRNi1Cc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 44, "npz_gt_video_start_frame": 44, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 44, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2285_0_1"}, {"texts": ["A man wearing a gray t-shirt and black pants is standing on the left side, holding a drill machine with his left hand on the counter, and holding a vegetable peeler in his right hand and peeling a green apple attached to the drill machine with a vegetable peeler."], "durations": null, "exact_frames_per_prompt": [60], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1-_nzW98f0M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 64, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2288_0_0"}, {"texts": ["The man is pulling out the apple from the drill machine."], "durations": null, "exact_frames_per_prompt": [7], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1-_nzW98f0M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 64, "npz_gt_video_start_frame": 64, "npz_gt_video_end_frame": 71, "skip_frames_after_generation": 64, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2288_0_1"}, {"texts": ["A man whose hands are visible is holding a tiny wire."], "durations": null, "exact_frames_per_prompt": [55], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0u5R1JMjTeQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 59, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_228_0_0"}, {"texts": ["The man starts folding the wire."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0u5R1JMjTeQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 59, "npz_gt_video_start_frame": 59, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 59, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_228_0_1"}, {"texts": ["A boy wearing a yellow t-shirt is sitting and holding a transparent plastic bag."], "durations": null, "exact_frames_per_prompt": [8], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-3vKpQQMYbE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 12, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2292_0_ms_0"}, {"texts": ["A boy wearing a light blue t-shirt is standing and holding an apple in his hand."], "durations": null, "exact_frames_per_prompt": [34], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-3vKpQQMYbE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 46, "npz_gt_video_start_frame": 46, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 46, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2292_1_0"}, {"texts": ["A woman wearing a black cloth and a watch is standing behind the ironing board and ironing a white cloth."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1Kpq4cRd6mQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2293_0_0"}, {"texts": ["A kid is standing next to the dog and eating ice-cream while other people are sitting on the bench."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-a8fUUZyEIA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2297_0_0"}, {"texts": ["A brown dog, next to the kid, is sitting on the gray surface while a kid wearing a brown jacket is touches the brown dog while eating an ice-cream."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-a8fUUZyEIA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2297_5_0"}, {"texts": ["A man wearing a grey t-shirt at first pours the whiskey in the glasses while a man wearing a striped shirt is sitting on the right side and looking at the whiky while speaking."], "durations": null, "exact_frames_per_prompt": [32], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0NIzLI3uk-A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 36, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2298_0_0"}, {"texts": ["The man closes the lid of the bottle, and put the bottle on the wooden surface while a man wearing a striped shirt is holding the glass of whisky."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0NIzLI3uk-A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 36, "npz_gt_video_start_frame": 36, "npz_gt_video_end_frame": 57, "skip_frames_after_generation": 36, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2298_0_1"}, {"texts": ["The man bangs his glass with the other man's."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0NIzLI3uk-A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 57, "npz_gt_video_start_frame": 57, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 57, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2298_0_2"}, {"texts": ["A man wearing a striped shirt is at first looking at the bottle of whiskey while another man wearing gray outfit is sitting on the left side of first man and he is first pouring whiskey in the glasses then puts the bottle on the table."], "durations": null, "exact_frames_per_prompt": [49], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0NIzLI3uk-A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 53, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2298_1_0"}, {"texts": ["The man picks up his glass."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0NIzLI3uk-A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 53, "npz_gt_video_start_frame": 53, "npz_gt_video_end_frame": 69, "skip_frames_after_generation": 53, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2298_1_1"}, {"texts": ["The man bangs it."], "durations": null, "exact_frames_per_prompt": [11], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0NIzLI3uk-A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 69, "npz_gt_video_start_frame": 69, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 69, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2298_1_2"}, {"texts": ["A man wearing a black t-shirt and grey jeans is sitting with one knee on the soil surface, holding a black bottle and filling water in the other bottle."], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/26YQBBZEk-k.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 41, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2303_0_0"}, {"texts": ["The man starts drinking water."], "durations": null, "exact_frames_per_prompt": [38], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/26YQBBZEk-k.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 41, "npz_gt_video_start_frame": 41, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 41, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2303_0_1"}, {"texts": ["A woman wearing black clothes is standing and holding an iron and ironing a cloth."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5GOspMRYUQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 26, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2304_0_0"}, {"texts": ["The woman is putting an iron."], "durations": null, "exact_frames_per_prompt": [3], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5GOspMRYUQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 26, "npz_gt_video_start_frame": 26, "npz_gt_video_end_frame": 29, "skip_frames_after_generation": 26, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2304_0_1"}, {"texts": ["A woman wearing a black shirt and black pants is standing on the gray surface, steaming the tie with the steam iron."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5GOspMRYUQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 31, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2305_0_0"}, {"texts": ["The woman is fixing it with a suction function."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5GOspMRYUQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 31, "npz_gt_video_start_frame": 31, "npz_gt_video_end_frame": 49, "skip_frames_after_generation": 31, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2305_0_1"}, {"texts": ["The woman is pulling the tie and putting the white rod into the tie."], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5GOspMRYUQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 49, "npz_gt_video_start_frame": 49, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 49, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2305_0_2"}, {"texts": ["A woman wearing a dark blue t-shirt is opening a mayonnaise jar."], "durations": null, "exact_frames_per_prompt": [38], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0O8gaQW6RBc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 10, "npz_gt_video_start_frame": 10, "npz_gt_video_end_frame": 48, "skip_frames_after_generation": 10, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2308_0_0"}, {"texts": ["The woman picks up a butter knife."], "durations": null, "exact_frames_per_prompt": [32], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0O8gaQW6RBc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 48, "npz_gt_video_start_frame": 48, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 48, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2308_0_1"}, {"texts": ["A man whose only upper half-body is visible wearing a white t-shirt is standing and pouring drinks into the glass while moving his body."], "durations": null, "exact_frames_per_prompt": [55], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2--cyRBwKig.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 59, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_230_1_0"}, {"texts": ["The man is picking bottles, then begins juggling with a bottle."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2--cyRBwKig.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 59, "npz_gt_video_start_frame": 59, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 59, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_230_1_1"}, {"texts": ["A man wearing a greyish-blue shirt is holding the ends of a red tie."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1fQZ7pBjBRU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 23, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2312_0_0"}, {"texts": ["The man is tying a tie."], "durations": null, "exact_frames_per_prompt": [57], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1fQZ7pBjBRU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 23, "npz_gt_video_start_frame": 23, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 23, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2312_0_1"}, {"texts": ["\\A woman whose upper body is visible wearing a black tank-top and specs, is sitting and speaking and is black-coating her eyebrows with the eyebrow brush."], "durations": null, "exact_frames_per_prompt": [63], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0JSUpFxrBCY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 67, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2313_0_0"}, {"texts": ["The woman is picking up the eyebrow kit in her hands and showing the eyebrow kit."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0JSUpFxrBCY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 67, "npz_gt_video_start_frame": 67, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 67, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2313_0_1"}, {"texts": ["A man wearing white clothes is standing and holding someone cheats and talking with another man while a man wearing a striped t-shirt is standing on the right side and talking to the man wearing a red t-shirt and exchanging cheats, a man wearing a white t-shirt moves to the right side, and a group of people are sitting backwards."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0RnnCnghS84.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2318_0_0"}, {"texts": ["A man wearing black clothes is standing and holding a mic while a man wearing a white t-shirt is speaking and standing behind the podium. Another man wearing a white t-shirt is standing on the right side along with another man in a red t-shirt and is also talking with the man in a red-black t-shirt who is coming from the left side."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0RnnCnghS84.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 14, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2318_1_0"}, {"texts": ["The man is talking with the first man a group of people are sitting and watching at the stage."], "durations": null, "exact_frames_per_prompt": [66], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0RnnCnghS84.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 14, "npz_gt_video_start_frame": 14, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 14, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2318_1_1"}, {"texts": ["A girl wearing a top and jeans is riding a mule in front of another mule and moving in a forward direction."], "durations": null, "exact_frames_per_prompt": [73], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/21VI-zTTnHc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 7, "npz_gt_video_start_frame": 7, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 7, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2320_0_0"}, {"texts": ["A black-brown mule is walking on the road while carrying a girl on his back and another mule is walking behind the first mule."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/21VI-zTTnHc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2320_1_0"}, {"texts": ["A black-brown mule is walking behind the first mule on the road while a girl is riding the mule and turning back."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/21VI-zTTnHc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2320_2_0"}, {"texts": ["A man wearing black-white clothes is sitting and watching the woman while the woman is wearing a pink blazer reading the news in front  of the camera."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/35BMgXpxoZ4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2324_0_0"}, {"texts": ["A woman wearing pink clothes is sitting and speaking while the man in black suit looking at her and  turn his head into the normal position."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/35BMgXpxoZ4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2324_1_0"}, {"texts": ["A woman wearing black coat is sitting and massaging her face."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4OQ0M_3dUYA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2328_0_0"}, {"texts": ["A woman, whose hands are visible only, is holding the thread of a bracelet."], "durations": null, "exact_frames_per_prompt": [53], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0NN9loNl9PA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 57, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2331_0_0"}, {"texts": ["The woman, whose hands are visible only, is tying a knot."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0NN9loNl9PA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 57, "npz_gt_video_start_frame": 57, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 57, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2331_0_1"}, {"texts": ["A man whose upper half-body is visible wearing a red t-shirt and a white apron is standing on the left side, picking out the cheese with his hands from the container."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/15eB6lgwnzs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 29, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2335_0_0"}, {"texts": ["The man is dropping it on the pizza base."], "durations": null, "exact_frames_per_prompt": [51], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/15eB6lgwnzs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 29, "npz_gt_video_start_frame": 29, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 29, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2335_0_1"}, {"texts": ["A man wearing a light gray jacket, white shirt and spectacles is standing behind the lectern and speaking on the mic while looking down."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Es9zrEHL84.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_233_1_0"}, {"texts": ["A man whose only hands are visible is tying a thread into the fish hook."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-NTVZAZ0xQA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 28, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2344_0_0"}, {"texts": ["A girl wearing a green top is sitting on the backside with her hand on the counter top while a person wearing blue clothes is standing on the right side and cutting a pineapple."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/31Cv9o3MPng.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 39, "npz_gt_video_start_frame": 39, "npz_gt_video_end_frame": 54, "skip_frames_after_generation": 39, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2346_1_0"}, {"texts": ["The girl puts her head on her hand while the person wearing blue clothes takes the slice of pineapple."], "durations": null, "exact_frames_per_prompt": [8], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/31Cv9o3MPng.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 54, "npz_gt_video_start_frame": 54, "npz_gt_video_end_frame": 63, "skip_frames_after_generation": 54, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2346_1_1"}, {"texts": ["The girl starts looking at the pineapple while the person wearing blue clothes cuts the slice of pineapple."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/31Cv9o3MPng.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 63, "npz_gt_video_start_frame": 63, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 63, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2346_1_2"}, {"texts": ["A person whose hands are visible is holding a funnel and pouring something into the machine from a bottle.\n"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-157wqwwtAo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2347_0_0"}, {"texts": ["A man wearing a jacket is standing and speaking on the mic."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Es9zrEHL84.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_234_0_0"}, {"texts": ["A man wearing a gray suit is sitting in a chair, holding papers, and speaking."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4lxvVcMpka0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2353_0_0"}, {"texts": ["A man wearing a white hat is standing behind the podium and sprechstimme while holding a mike."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3U82HTyQZZI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2356_0_0"}, {"texts": ["A woman wearing a white shirt is standing on the left side. She at first throws the bed sheet towards the other woman and then starts spreading the bed sheet on the bed."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/hzooUrk_3_Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2358_0_0"}, {"texts": ["A woman wearing a white shirt is standing on the right side and spreading the bed sheet on the bed with the woman on the left side."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/hzooUrk_3_Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2358_1_0"}, {"texts": ["A girl on the right, standing on the stage is spreading the bed sheet on the bed while the other girl on the left is also spreading the bed sheet, and a group of people in which some people are screaming on them and the two people are standing on the backside and speaking on the mic."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/hzooUrk_3_Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2359_0_0"}, {"texts": ["A girl on the left is also spreading the bed sheet on the bed with person one while a group of people stands behind the bed and some in front of the bed."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/hzooUrk_3_Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2359_1_0"}, {"texts": ["A girl wearing a pink-gray top and purple shorts is sitting while holding doughnut."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/38qB3KzurOA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 23, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2362_0_0"}, {"texts": ["The girl wearing a pink-gray top and purple shorts is eating the doughnut and keeping the doughnut on the table."], "durations": null, "exact_frames_per_prompt": [57], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/38qB3KzurOA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 23, "npz_gt_video_start_frame": 23, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 23, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2362_0_1"}, {"texts": ["A girl wearing a red-grey dress is sitting on the bench, holding a donut and eating it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/38qB3KzurOA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2363_0_0"}, {"texts": ["A woman wearing a gray-black cloth is standing, holding a bowl."], "durations": null, "exact_frames_per_prompt": [67], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-1MXpPymXFU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 71, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2365_0_0"}, {"texts": ["The woman is pouring sauce over the cookies."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-1MXpPymXFU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 71, "npz_gt_video_start_frame": 71, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 71, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2365_0_1"}, {"texts": ["A person whose hands are only visible is mixing a black coffee in a glass mug with the help of a spoon."], "durations": null, "exact_frames_per_prompt": [67], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0INHWJX9G0o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 13, "npz_gt_video_start_frame": 13, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 13, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2366_0_0"}, {"texts": ["A kid wearing a t-shirt with written words is sitting on a grey baby high chair, putting hand on the green-blue bottle and drinking water from the green-blue bottle."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/162ro8sHvXM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_236_0_0"}, {"texts": ["A girl wearing a blue t-shirt is standing."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0b9xWsXdp0Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 17, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2372_0_0"}, {"texts": ["The girl wearing a blue t-shirt is playing golf on the grass surface."], "durations": null, "exact_frames_per_prompt": [63], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0b9xWsXdp0Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 17, "npz_gt_video_start_frame": 17, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 17, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2372_0_1"}, {"texts": ["A woman wearing a black blazer is sitting on a grey chair, speaking then moves her hand while a man wearing a black blazer is sitting next to the woman."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/50HF2b-570o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 33, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2375_0_ms_0"}, {"texts": ["A man wearing a black blazer is sitting next to the woman while a woman on the left side wearing a black blazer is sitting and speaking while moving her hand."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/50HF2b-570o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 33, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2375_1_ms_0"}, {"texts": ["A man wearing a green t-shirt is standing in the front and putting a hive frame in the beehive box while a man wearing a grey shirt is standing near the fence and looking at the bee hive."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/50HF2b-570o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 34, "npz_gt_video_start_frame": 34, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 34, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2375_2_ms_0"}, {"texts": ["A man wearing a brown shirt is standing on the backside while another man wearing green and blue outfit, holding an artificial bee hive and he is bending forward and put the bee hive in between other bee hives."], "durations": null, "exact_frames_per_prompt": [38], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/50HF2b-570o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 34, "npz_gt_video_start_frame": 34, "npz_gt_video_end_frame": 72, "skip_frames_after_generation": 34, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2375_3_ms_0"}, {"texts": ["A person wearing green shirt whose head is visible is on the backside."], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/50HF2b-570o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 34, "npz_gt_video_start_frame": 34, "npz_gt_video_end_frame": 67, "skip_frames_after_generation": 34, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2375_5_ms_0"}, {"texts": ["A person wearing a white t-shirt is holding the red collar belts of the group of dogs and walking in a straight direction along with them."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0hSgEonuekA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 32, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2376_0_0"}, {"texts": ["A man wearing a black suit is walking towards the mic."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0_r87O-US2E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 13, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2378_1_0"}, {"texts": ["The man is holding a mic with his left hand and holding a trophy in his right hand."], "durations": null, "exact_frames_per_prompt": [4], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0_r87O-US2E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 13, "npz_gt_video_start_frame": 13, "npz_gt_video_end_frame": 17, "skip_frames_after_generation": 13, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2378_1_1"}, {"texts": ["The man starts speaking on the mic."], "durations": null, "exact_frames_per_prompt": [63], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0_r87O-US2E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 17, "npz_gt_video_start_frame": 17, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 17, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2378_1_2"}, {"texts": ["A woman wearing a white-black top and a black blazer is walking while holding a black diary behind the wooden table."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/53VSF1OS7Mo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 30, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2379_0_0"}, {"texts": ["The woman is sitting and putting that black diary on the wooden table."], "durations": null, "exact_frames_per_prompt": [32], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/53VSF1OS7Mo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 30, "npz_gt_video_start_frame": 30, "npz_gt_video_end_frame": 62, "skip_frames_after_generation": 30, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2379_0_1"}, {"texts": ["A woman wearing a purple top and leggings is riding a horse in a forward direction on the soil surface."], "durations": null, "exact_frames_per_prompt": [73], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0d5Y3zRJJkw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 77, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_237_0_0"}, {"texts": ["A light brown horse is walking on the soil surface with a woman sitting on its back."], "durations": null, "exact_frames_per_prompt": [73], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0d5Y3zRJJkw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 77, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_237_1_0"}, {"texts": ["A man wearing a black suit is speaking."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0OgsfR4qDMs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 31, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2382_0_0"}, {"texts": ["The man is walking."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0OgsfR4qDMs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 31, "npz_gt_video_start_frame": 31, "npz_gt_video_end_frame": 48, "skip_frames_after_generation": 31, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2382_0_1"}, {"texts": ["The man is moving his hands towards the glass screen."], "durations": null, "exact_frames_per_prompt": [32], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0OgsfR4qDMs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 48, "npz_gt_video_start_frame": 48, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 48, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2382_0_2"}, {"texts": ["A woman wearing a blue dress is standing and combing a dog's fur."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2H6koOMfDr0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 33, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2386_0_0"}, {"texts": ["The woman puts the sprayer aside after spraying on it."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2H6koOMfDr0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 33, "npz_gt_video_start_frame": 33, "npz_gt_video_end_frame": 61, "skip_frames_after_generation": 33, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2386_0_1"}, {"texts": ["The woman is holding the dog's ear."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2H6koOMfDr0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 61, "npz_gt_video_start_frame": 61, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 61, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2386_0_2"}, {"texts": ["A black dog is standing on a table and getting combed by the woman."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2H6koOMfDr0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 34, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2386_1_0"}, {"texts": ["A person wearing a blue t-shirt is standing, holding and combing a black dog with a comb."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2H6koOMfDr0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 31, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2387_0_0"}, {"texts": ["A black dog is standing and getting combed by a person."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2H6koOMfDr0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2387_1_0"}, {"texts": ["A woman is sitting, closing her eyes, and getting her eyebrows welded by a woman."], "durations": null, "exact_frames_per_prompt": [44], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-gqrlbkjaaA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 48, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_238_1_0"}, {"texts": ["A child whose hands and legs are visible is sitting while holding a green book with both hands."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-grY2svgF3o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 28, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2390_0_0"}, {"texts": ["The child starts turning the pages of a book with his hands."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-grY2svgF3o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 28, "npz_gt_video_start_frame": 28, "npz_gt_video_end_frame": 37, "skip_frames_after_generation": 28, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2390_0_1"}, {"texts": ["A man wearing a cap is standing and holding a snake in his left hand and around his neck while a man in a blue t-shirt is helping him, some people are standing and walking near him, and a group of people at the back are moving here and there."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2LAs3iohl6E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2393_0_0"}, {"texts": ["A man wearing a blue shirt is standing on the right side and giving the snake in the first man's hand while another man wearing white clothes is coming from the right and taking something."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2LAs3iohl6E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2393_1_0"}, {"texts": ["The man starts moving.  while a group of people are standing and moving at the back."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2LAs3iohl6E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 45, "npz_gt_video_start_frame": 45, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 45, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2393_1_1"}, {"texts": ["A man, wearing a white top, is walking behind the first man while a man wearing purple shirt and white cap holding a snake around his neck and hands"], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2LAs3iohl6E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 9, "npz_gt_video_start_frame": 9, "npz_gt_video_end_frame": 36, "skip_frames_after_generation": 9, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2393_2_0"}, {"texts": ["The man stands while a man wearing blue shirt touches the snake and stood aside"], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2LAs3iohl6E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 36, "npz_gt_video_start_frame": 36, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 36, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2393_2_1"}, {"texts": ["The man puts something in his pocket while the other man in blue t-shirt and black pant is standing and seeing the snake."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2LAs3iohl6E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 58, "npz_gt_video_start_frame": 58, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 58, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2393_2_2"}, {"texts": ["A snake is laying around the first man's neck while a man wearing a blue shirt is trying to touch the snake and then turning to the left, a man wearing a white kurta is coming on the left, putting something in his pocket, and standing near the man holding a snake,\u00a0 a man wearing a blue shirt is standing right next to the first man, and a group of people are standing in the backside."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2LAs3iohl6E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2393_4_0"}, {"texts": ["A man wearing a striped shirt is sitting on a stool, near the boy in a blue t-shirt while the boy was hit by the tail of the cow."], "durations": null, "exact_frames_per_prompt": [12], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-tjARoxdBJw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 16, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2396_0_0"}, {"texts": ["The man puts his hand in front of the cow."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-tjARoxdBJw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 16, "npz_gt_video_start_frame": 16, "npz_gt_video_end_frame": 42, "skip_frames_after_generation": 16, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2396_0_1"}, {"texts": ["The man starts milking the cow."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-tjARoxdBJw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 42, "npz_gt_video_start_frame": 42, "npz_gt_video_end_frame": 59, "skip_frames_after_generation": 42, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2396_0_2"}, {"texts": ["The boy comes near him for milking the cow."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-tjARoxdBJw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 59, "npz_gt_video_start_frame": 59, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 59, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2396_0_3"}, {"texts": ["A man whose only upper body is visible wearing a black shirt and a silver watch is holding a black bean sauce pouch in his right hand."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/58g6Qx7alp0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 29, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2397_0_0"}, {"texts": ["The man is putting the black bean sauce in the pan and then holding the sauce pouch in his left hand."], "durations": null, "exact_frames_per_prompt": [34], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/58g6Qx7alp0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 29, "npz_gt_video_start_frame": 29, "npz_gt_video_end_frame": 63, "skip_frames_after_generation": 29, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2397_0_1"}, {"texts": ["The man is holding a wooden spatula in his right hand and starts moving the wooden spatula in the pan."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/58g6Qx7alp0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 63, "npz_gt_video_start_frame": 63, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 63, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2397_0_2"}, {"texts": ["A kid wearing a dark blue t-shirt is sitting on a white baby chair. He is playing with a blue spoon."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-XKwRCwbjvA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 22, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_23_0_0"}, {"texts": ["The kid is being fed by a person."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-XKwRCwbjvA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 22, "npz_gt_video_start_frame": 22, "npz_gt_video_end_frame": 41, "skip_frames_after_generation": 22, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_23_0_1"}, {"texts": ["A person whose only hand is visible is feeding the baby."], "durations": null, "exact_frames_per_prompt": [50], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-XKwRCwbjvA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 54, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_23_1_0"}, {"texts": ["A person whose hands are visible wearing a purple woolen cloth is standing while holding a transparent bag with apples on the left side and another person whose also hand is visible is showing an apple in his hand and then putting it into the bag."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-lvzCHLAEtQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2404_0_0"}, {"texts": ["A man wearing a white t-shirt first inserts the breaker bar in the studs."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3loaf7qu6og.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 33, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2408_0_0"}, {"texts": ["The man starts rotating the rim down to tighten the studs."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3loaf7qu6og.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 33, "npz_gt_video_start_frame": 33, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 33, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2408_0_1"}, {"texts": ["A man wearing black clothes is participating in a bed setting competition while a woman is also participating in a bed-setting competition, two men are standing at the back and watching the competition."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/j3kn3UKNep4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2416_0_0"}, {"texts": ["A woman on the right is also participating in a bed setting competition while a man wearing black clothes is spreading the bed sheet on the bed, a man wearing a black-and-white striped t-shirt moves forward towards the woman, and other people are looking in the direction of the man and the woman."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/j3kn3UKNep4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2416_1_0"}, {"texts": ["A boy wearing a blue t-shirt is standing and putting the cookies on the white paper with a spatula."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0acHgv8A6U8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 21, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2419_0_0"}, {"texts": ["A baby wearing blue and black clothes is picking a red cloth."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4esUZKQooEM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 27, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_241_0_0"}, {"texts": ["The baby putting it inside a washing machine."], "durations": null, "exact_frames_per_prompt": [53], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4esUZKQooEM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 27, "npz_gt_video_start_frame": 27, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 27, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_241_0_1"}, {"texts": ["A woman whose hands are visible is wearing a white full-sleeve t-shirt is spreading the white cream on the bread."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1U1ojuY5nPg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 13, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2420_0_0"}, {"texts": ["The woman is putting the chocolate pieces on the white cream bread."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1U1ojuY5nPg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 13, "npz_gt_video_start_frame": 13, "npz_gt_video_end_frame": 23, "skip_frames_after_generation": 13, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2420_0_1"}, {"texts": ["The woman is putting the other bread on the chocolate."], "durations": null, "exact_frames_per_prompt": [4], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1U1ojuY5nPg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 23, "npz_gt_video_start_frame": 23, "npz_gt_video_end_frame": 27, "skip_frames_after_generation": 23, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2420_0_2"}, {"texts": ["The woman is again putting the cream on the other bread, and then spreading the cream with the knife."], "durations": null, "exact_frames_per_prompt": [53], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1U1ojuY5nPg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 27, "npz_gt_video_start_frame": 27, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 27, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2420_0_3"}, {"texts": ["A woman wearing a pink t-shirt and a white cap is sitting on the back of the elephant and feeding a banana to the elephant."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0ACji4353Go.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 20, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2425_0_0"}, {"texts": ["A gray elephant is being fed a banana by a woman."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0ACji4353Go.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 20, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2425_1_0"}, {"texts": ["A girl wearing black pants is sitting on a bench, holding a yellow python around her neck and in her hands."], "durations": null, "exact_frames_per_prompt": [53], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-JehxiVQQ_w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 57, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2431_0_0"}, {"texts": ["A yellow python snake is wrapping around a girl's body."], "durations": null, "exact_frames_per_prompt": [53], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-JehxiVQQ_w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 57, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2431_1_0"}, {"texts": ["A man, whose hand is visible, wearing blue gloves, is touching the engine parts of the vehicle."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1gkPZP0iHsU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2435_0_0"}, {"texts": ["A man whose hand is visible, is repairing the engine oil tank."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1gkPZP0iHsU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2436_0_0"}, {"texts": ["A man wearing spectacles is showing a metal part of a vehicle."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1gkPZP0iHsU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2437_1_0"}, {"texts": ["A man wearing a red t-shirt is standing and cleaning an artificial beehive while a man wearing a white t-shirt is moving left and right and picking something from the beehives."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5o8kbzRUGX4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2444_0_0"}, {"texts": ["A man wearing a white t-shirt is moving an artificial beehive box with a man wearing a red shirt."], "durations": null, "exact_frames_per_prompt": [39], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5o8kbzRUGX4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 43, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2444_1_0"}, {"texts": ["The man is lifting something from the ground."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5o8kbzRUGX4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 43, "npz_gt_video_start_frame": 43, "npz_gt_video_end_frame": 60, "skip_frames_after_generation": 43, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2444_1_1"}, {"texts": ["The man leans forward."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5o8kbzRUGX4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 60, "npz_gt_video_start_frame": 60, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 60, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2444_1_2"}, {"texts": ["A man wearing a white shirt and gray trousers is shaking hands with another man."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0PsBN0n4LLU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 18, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2445_0_0"}, {"texts": ["The man is walking and receiving an award.  "], "durations": null, "exact_frames_per_prompt": [62], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0PsBN0n4LLU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 18, "npz_gt_video_start_frame": 18, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 18, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2445_0_1"}, {"texts": ["A woman wearing a printed red shirt is sitting inside a car and peeling a red apple with a knife."], "durations": null, "exact_frames_per_prompt": [61], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-tRfLelwyNU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 65, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2447_0_0"}, {"texts": ["A woman wearing a cherry colored top is standing in the kitchen and doing something while a girl in the red top watches her and makes hand gestures ."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2nochCAHa3c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 39, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2448_0_0"}, {"texts": ["A girl wearing a red top is looking at the beater while a woman wearing a black t-shirt is standing on the left side and shaking something."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2nochCAHa3c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 22, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2448_1_0"}, {"texts": ["The girl is eating something while a woman wearing a black t-shirt then walks away."], "durations": null, "exact_frames_per_prompt": [58], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2nochCAHa3c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 22, "npz_gt_video_start_frame": 22, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 22, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2448_1_1"}, {"texts": ["A woman wearing a gray t-shirt and black trousers is sitting on the floor and setting up the clothes and a brown cat is moving here and there."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-zjeY-7fXJw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2451_0_0"}, {"texts": ["A brown cat is walking here and there while a girl wearing a grey t-shirt is sitting on the brown surface and arranging the clothes ."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-zjeY-7fXJw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2451_1_0"}, {"texts": ["A man wearing a blue t-shirt is coming from the left side and looking in front while speaking then smiling and going back in the left again."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3-lYrM9FzsA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 30, "npz_gt_video_start_frame": 30, "npz_gt_video_end_frame": 48, "skip_frames_after_generation": 30, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2452_0_0"}, {"texts": ["A man wearing a blue t-shirt is standing and speaking."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3-lYrM9FzsA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 30, "npz_gt_video_start_frame": 30, "npz_gt_video_end_frame": 48, "skip_frames_after_generation": 30, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2453_0_0"}, {"texts": ["A man wearing a brown t-shirt is holding a baby and touching a plant."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-QXKPOgbPno.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2455_0_0"}, {"texts": ["A woman wearing a grey printed t-shirt is standing, holding a bowl and mixing the salad with the spoon while other man wearing blue t-shirt is standing on the right."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3MkJXn3YsF0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2461_0_0"}, {"texts": ["A man wearing a blue t-shirt is standing and touching the capsicum in the white plate as a woman wearing a grey floral top is mixing sprouts in a bowl with a spoon."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3MkJXn3YsF0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2461_1_0"}, {"texts": ["A woman whose hand is visible is applying the corn flour to the meat slices"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/233Vj6YHJps.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2463_0_0"}, {"texts": ["A woman wearing a sleeveless top is standing near the counter, holding a drink."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2MXHBy-veBc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2468_0_0"}, {"texts": ["The woman is speaking."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2MXHBy-veBc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 45, "npz_gt_video_start_frame": 45, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 45, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2468_0_1"}, {"texts": ["A woman wearing a brown top is standing on the left side holding a glass of drink.\n while a man in front of her is standing and using his phone."], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2MXHBy-veBc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 41, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2469_0_0"}, {"texts": ["A man wearing a white gray t-shirt is standing on the right side holding a glass of drink and using his mobile with his left hand while a woman wearing a brown dress is standing on the left side holding a wine glass, and a group of people are sitting."], "durations": null, "exact_frames_per_prompt": [58], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2MXHBy-veBc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 62, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2469_1_0"}, {"texts": ["A man wearing a grey suit is standing in front of the podium and speaking on the mic while other man in black suit stands beside him."], "durations": null, "exact_frames_per_prompt": [72], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4NEFN0EOp5c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 8, "npz_gt_video_start_frame": 8, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 8, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2475_1_0"}, {"texts": ["A woman wearing a light pink t-shirt and gray jeans is standing on the left side and speaking while holding the horse's tail in her hands."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/10Dr44B7XYs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 30, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2480_0_0"}, {"texts": ["The woman is then tilting her body to pick up the spray bottle."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/10Dr44B7XYs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 30, "npz_gt_video_start_frame": 30, "npz_gt_video_end_frame": 49, "skip_frames_after_generation": 30, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2480_0_1"}, {"texts": ["The woman is standing while holding a spray bottle in her right hand and holding the horse's tail with her left hand"], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/10Dr44B7XYs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 49, "npz_gt_video_start_frame": 49, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 49, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2480_0_2"}, {"texts": ["A brown horse whose only hip and tail are visible is standing on the right side while the woman explains the procedure."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/10Dr44B7XYs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2480_1_0"}, {"texts": ["A man wearing a blue t-shirt is sitting and holding the leg of the horse on his thigh on the grey surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2z2bb1syxjU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2481_0_0"}, {"texts": ["A brown horse is standing and keeping its leg on the man's thigh while a man wearing blue t-shirt is holding a horse leg and speaking."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2z2bb1syxjU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2481_1_0"}, {"texts": ["A boy wearing a black jacket and gray jeans is standing and fishing with the fishing rod while rolling the fishing rod handle while the fish with the fishing rod moves its tail"], "durations": null, "exact_frames_per_prompt": [32], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0-MHr4N9ooI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 15, "npz_gt_video_start_frame": 15, "npz_gt_video_end_frame": 47, "skip_frames_after_generation": 15, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2488_0_0"}, {"texts": ["The boy is speaking while the fish waves its tail"], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0-MHr4N9ooI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 47, "npz_gt_video_start_frame": 47, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 47, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2488_0_1"}, {"texts": ["A white fish is hanging with the fishing rod hook.\n and the boy wearing black jacket is holding the fishing rod"], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0-MHr4N9ooI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2488_1_0"}, {"texts": ["A man on the backside wearing a maroon-white striped t-shirt is walking on the backside and a group of people in which some are sitting, some are standing, and one is walking to the left side."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0f66UEeLLeM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 14, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2489_3_ms_0"}, {"texts": ["A white sheep is caught by a person and gets rimmed while a herd of sheep is standing on the right side and two people are standing and watching the man."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0HOlEUzjESo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_248_0_0"}, {"texts": ["A person wearing a gray t-shirt and blue pants is trimming the hairs of sheep while bending then a woman on the right is watching the person and a group of sheep is standing in the cage."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0HOlEUzjESo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_248_1_0"}, {"texts": ["A black-brown cat is sitting and getting caressed by a person."], "durations": null, "exact_frames_per_prompt": [57], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1mBYF0v9A-A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 61, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2493_0_0"}, {"texts": ["A person whose half body is visible is caressing the cat with his hand."], "durations": null, "exact_frames_per_prompt": [57], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1mBYF0v9A-A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 61, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2493_1_0"}, {"texts": ["A baby wearing a white diaper is sitting, holding a book, turning the pages and looking at it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1g11NL3V2-g.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2497_0_0"}, {"texts": ["A baby wearing a yellow bib is at first spilling the food from his mouth."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3W3bGkkFjnY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 22, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2498_0_0"}, {"texts": ["The person wipes the food from a spoon and insert it into the baby's mouth."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3W3bGkkFjnY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 22, "npz_gt_video_start_frame": 22, "npz_gt_video_end_frame": 51, "skip_frames_after_generation": 22, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2498_0_1"}, {"texts": ["The baby eats the food."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3W3bGkkFjnY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 51, "npz_gt_video_start_frame": 51, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 51, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2498_0_2"}, {"texts": ["A person whose only a hand is visible is holding a spoon and wipes the food that is spilled out of the baby's mouth and then feeds the spilled food to the baby."], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3W3bGkkFjnY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 19, "npz_gt_video_start_frame": 19, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 19, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2498_1_0"}, {"texts": ["A baby boy wearing a blue t-shirt is tapping a spoon in a bowl."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-XKwRCwbjvA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 26, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_24_0_0"}, {"texts": ["The baby is eating from another spoon."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-XKwRCwbjvA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 26, "npz_gt_video_start_frame": 26, "npz_gt_video_end_frame": 54, "skip_frames_after_generation": 26, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_24_0_1"}, {"texts": ["A person whose hand is visible holding a spoon is feeding a baby bird."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/08DWvdZkfAw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2500_0_0"}, {"texts": ["A brown baby bird is eating food from the spoon while a person whose hand is visible is holding the spoon."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/08DWvdZkfAw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2500_1_0"}, {"texts": ["A kid wearing blue clothes is standing on the soil surface and feeding a baby goat from a bottle while a white color puppy first comes towards the kid then moves towards the right side and a black and white dog moves towards the boy."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-h0pXulZaPg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2506_0_0"}, {"texts": ["A brown baby goat is moving around the kid and drinking from the bottle while a boy wearing the blue jacket is holding the bottle and two other dogs comes around."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-h0pXulZaPg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2506_1_0"}, {"texts": ["A white puppy is coming towards the kid as a brown dog is eating something from kid's hand."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-h0pXulZaPg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 56, "npz_gt_video_start_frame": 56, "npz_gt_video_end_frame": 69, "skip_frames_after_generation": 56, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2506_2_0"}, {"texts": ["The white puppy walks away on the right side a black and white dog is also coming toward the kid."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-h0pXulZaPg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 69, "npz_gt_video_start_frame": 69, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 69, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2506_2_1"}, {"texts": ["A man wearing a blue t-shirt is sitting on a brown sofa and holding a kid."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-oSKT0KuI3I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 19, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_250_0_0"}, {"texts": ["The man is looking at the kid."], "durations": null, "exact_frames_per_prompt": [61], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-oSKT0KuI3I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 19, "npz_gt_video_start_frame": 19, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 19, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_250_0_1"}, {"texts": ["A kid wearing a multicolored printed romper is sitting in the front of the man, being held by the man, laughing."], "durations": null, "exact_frames_per_prompt": [51], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-oSKT0KuI3I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 55, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_250_1_0"}, {"texts": ["The kid is lying on the man."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-oSKT0KuI3I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 55, "npz_gt_video_start_frame": 55, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 55, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_250_1_1"}, {"texts": ["A person whose hands are visible is holding a white box and moving."], "durations": null, "exact_frames_per_prompt": [60], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0gO3FmnKD8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 64, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2514_0_0"}, {"texts": ["The person is shaking the box."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0gO3FmnKD8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 64, "npz_gt_video_start_frame": 64, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 64, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2514_0_1"}, {"texts": ["A person whose only hands are visible is pumping out some red liquid with a pump."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1eHzetBUA1A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 13, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2518_0_ms_0"}, {"texts": ["A person on the right is holding the pump pipe into a yellow container while a person wearing black clothes is on the left side and holds the opening of the yellow container and pump pipe."], "durations": null, "exact_frames_per_prompt": [66], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1eHzetBUA1A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 14, "npz_gt_video_start_frame": 14, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 14, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2518_2_ms_0"}, {"texts": ["A girl wearing a pink dress is standing, hitting the red spoon."], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1XtdtLcNCt8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 47, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2521_0_0"}, {"texts": ["The girl wearing a pink dress is putting her hand in the bowl."], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1XtdtLcNCt8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 47, "npz_gt_video_start_frame": 47, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 47, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2521_0_1"}, {"texts": ["A man wearing a blue denim jacket is standing and cooking and stirring food with the help of a wooden spatula."], "durations": null, "exact_frames_per_prompt": [57], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0M8-82fq7oY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 61, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2524_0_0"}, {"texts": ["The man serve into another white bowl."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0M8-82fq7oY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 61, "npz_gt_video_start_frame": 61, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 61, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2524_0_1"}, {"texts": ["A person wearing a red t-shirt is standing and making sushi using a bamboo mat on a black counter-top."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2Fc1ehZsbiw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2526_0_0"}, {"texts": ["A woman on the left side wearing a black top is sitting on a bed while a woman wearing a blue top is sitting on the right side on a bed."], "durations": null, "exact_frames_per_prompt": [8], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2qxd5BDn0t8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 12, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2532_0_0"}, {"texts": ["The woman is drinking from the cup while a woman wearing a blue top is drinking from the cup."], "durations": null, "exact_frames_per_prompt": [42], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2qxd5BDn0t8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 12, "npz_gt_video_start_frame": 12, "npz_gt_video_end_frame": 54, "skip_frames_after_generation": 12, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2532_0_1"}, {"texts": ["A woman on the right side wearing a blue top is sitting while other woman is looking at her"], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2qxd5BDn0t8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 18, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2532_1_0"}, {"texts": ["The woman is drinking from the cup while the other woman is drinking"], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2qxd5BDn0t8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 18, "npz_gt_video_start_frame": 18, "npz_gt_video_end_frame": 46, "skip_frames_after_generation": 18, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2532_1_1"}, {"texts": ["The woman is moving her hand in the front."], "durations": null, "exact_frames_per_prompt": [8], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2qxd5BDn0t8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 46, "npz_gt_video_start_frame": 46, "npz_gt_video_end_frame": 54, "skip_frames_after_generation": 46, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2532_1_2"}, {"texts": ["A man wearing a light-grey t-shirt is sitting on a wooden chair, holding a glass and looking to the right side while some people are sitting, laughing, and talking."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3WL0y2LA-q4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2533_0_0"}, {"texts": ["A man wearing a dark-grey t-shirt is sitting next to the first man, holding a glass then raises his hand while a woman wearing a black top is sitting on the left and is smiling, another man is sitting on the left of the woman."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3WL0y2LA-q4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2533_1_0"}, {"texts": ["A woman wearing black top is riding a brown horse in the right direction while the other person moves forward."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1B_d3HxMGMs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2534_1_0"}, {"texts": ["A brown horse, taking a woman on its back moving in the right direction on a grass surface while a man wearing a cap is walking on the grass surface towards the back."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1B_d3HxMGMs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2534_2_0"}, {"texts": ["A girl on the right lying on the floor is holding a phone and is speaking and laughing while a girl is lying on the floor on the left side talking to the other girl and smiling."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/79CsWzgZI58.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2535_0_0"}, {"texts": ["A woman on the left also laying on the floor is looking at the phone and is speaking while another girl looked into her phone and laughed."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/79CsWzgZI58.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2535_1_0"}, {"texts": ["A man wearing a red jacket is standing while another man wearing a grey jacket is standing on the right side."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/67OWWENrUFg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2536_0_0"}, {"texts": ["The man starts the meat grinding machine with the help of a electric drill machine while the other man standing on the right is putting his hands over the meat grinding machine."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/67OWWENrUFg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 44, "npz_gt_video_start_frame": 44, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 44, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2536_0_1"}, {"texts": ["A man wearing a gray jacket is standing.\n while another man wearing a red jacket is also standing and holding a silver colored object."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/67OWWENrUFg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2536_1_0"}, {"texts": ["The man starts pressing the meat into the grinder and also smoking a cigarette while the man wearing a red jacket starts moving the silver colored object."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/67OWWENrUFg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 40, "npz_gt_video_start_frame": 40, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 40, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2536_1_1"}, {"texts": ["A person whose hand is visible wearing blue cloth is holding a grinding machine and grinding the chicken."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0BxSSwxuqWg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2540_0_0"}, {"texts": ["A person whose hand is visible is tying a knot in the rope."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-Y__PsM58V8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2541_0_0"}, {"texts": ["A girl wearing a pink dress is sitting and unwrapping a gift."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-ygjTvEdGJ0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2548_0_0"}, {"texts": ["A man is wearing white cloth is holding a golf stick."], "durations": null, "exact_frames_per_prompt": [50], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-YBrw6cDVEE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 54, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2549_0_0"}, {"texts": ["The man is hitting a golf ball with his golf stick."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-YBrw6cDVEE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 54, "npz_gt_video_start_frame": 54, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 54, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2549_0_1"}, {"texts": ["A man wearing a black suit is standing and moving his hands in sign language."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/70szp6HioeU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2550_0_0"}, {"texts": ["A man wearing a black t-shirt is standing behind the first man."], "durations": null, "exact_frames_per_prompt": [68], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/70szp6HioeU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 72, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2550_1_0"}, {"texts": ["The man is moving his hand while speaking in sign language."], "durations": null, "exact_frames_per_prompt": [8], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/70szp6HioeU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 72, "npz_gt_video_start_frame": 72, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 72, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2550_1_1"}, {"texts": ["A person whose hands are visible is tearing the paper."], "durations": null, "exact_frames_per_prompt": [49], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2HBKBssNyqM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 53, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2554_0_0"}, {"texts": ["The person is showing the pieces of paper in his hand"], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2HBKBssNyqM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 53, "npz_gt_video_start_frame": 53, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 53, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2554_0_1"}, {"texts": ["A man wearing a white shirt is standing, he ties a blue bow tie, shows it, and starts talking."], "durations": null, "exact_frames_per_prompt": [59], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1HJI_Issf0w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 63, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2557_0_0"}, {"texts": ["A lady wearing a purple dress is standing and presenting the weather forecasting through a digital screen.\n"], "durations": null, "exact_frames_per_prompt": [65], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-g25DqskpqU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 16, "npz_gt_video_start_frame": 16, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 16, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2558_0_0"}, {"texts": ["A kid wearing a green t-shirt is feeding milk to a baby goat from a milk bottle while a person wearing a black top is assisting the kid."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0ETrTlZQ2uo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2559_0_0"}, {"texts": ["A person wearing blue jeans is also feeding milk to the baby goat with the kid."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0ETrTlZQ2uo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2559_1_0"}, {"texts": ["A baby goat is being fed milk by the kid and the person."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0ETrTlZQ2uo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2559_2_0"}, {"texts": ["A man wearing a grey t-shirt is speaking while moaning."], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0O3S2OqHDKE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 37, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_255_0_0"}, {"texts": ["The man is clapping his hands."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0O3S2OqHDKE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 37, "npz_gt_video_start_frame": 37, "npz_gt_video_end_frame": 65, "skip_frames_after_generation": 37, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_255_0_1"}, {"texts": ["A man wearing blue clothes is wrapping the gauze on the legs of a person."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0LpGDkiyvaQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2561_0_0"}, {"texts": ["A man wearing a blue t-shirt is standing and leaning forward and applying and rubbing a medical tape on another man leg."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0LpGDkiyvaQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2562_0_0"}, {"texts": ["A person whose thumb is visible is holding a steel bowl.\n"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-NRNRutEk40.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2569_0_0"}, {"texts": ["A boy wearing a black t-shirt and dark gray pants is standing and holding a golf stick."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1d7QuWpicJg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 24, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2570_0_0"}, {"texts": ["The boy is hitting a golf shot in a golf artificial game."], "durations": null, "exact_frames_per_prompt": [56], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1d7QuWpicJg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 24, "npz_gt_video_start_frame": 24, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 24, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2570_0_1"}, {"texts": ["A man wearing a black full-sleeve t-shirt, brown pants, and white shoes is standing while holding a golf stick."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1d7QuWpicJg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 24, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2571_0_0"}, {"texts": ["The man is hitting the golf ball with a golf stick. "], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1d7QuWpicJg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 24, "npz_gt_video_start_frame": 24, "npz_gt_video_end_frame": 57, "skip_frames_after_generation": 24, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2571_0_1"}, {"texts": ["The man again hitting the ball with a golf stick on the backside, and then standing."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1d7QuWpicJg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 57, "npz_gt_video_start_frame": 57, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 57, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2571_0_2"}, {"texts": ["A man wearing an olive green t-shirt is standing behind the table."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1RU9q4lx3go.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 27, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2572_0_0"}, {"texts": ["The man is flipping the box."], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1RU9q4lx3go.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 27, "npz_gt_video_start_frame": 27, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 27, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2572_0_1"}, {"texts": ["The man is opening the box."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1RU9q4lx3go.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 58, "npz_gt_video_start_frame": 58, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 58, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2572_0_2"}, {"texts": ["A man whose legs and hands are visible, wearing black shoes and a black watch, is standing on the left side, holding a wooden cover and opening the wooden box."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/8TeayjSoz_E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 14, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2573_0_0"}, {"texts": ["A boy wearing a printed white t-shirt and green shorts is standing on the left side on the green grass surface and is holding a brown snake in his hands."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/50BOKCH-Tz8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2579_0_0"}, {"texts": ["A brown snake is held in the boy's hand."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/50BOKCH-Tz8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2579_4_0"}, {"texts": ["A dark green snake is visible while the boy is holding it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/50BOKCH-Tz8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2579_5_0"}, {"texts": ["A person whom hand is visible, holding books and opening it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0gRu8EC_L9o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2582_0_0"}, {"texts": ["A girl wearing a black t-shirt is sitting on a bed and opening a bottle of champagne."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/Q_ErmJZysmA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2583_0_0"}, {"texts": ["A woman wearing a black coat is standing just behind the podium."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1Bt4ADs-kG4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2586_0_0"}, {"texts": ["A man wearing a black t-shirt is holding the leash of the camel and walking in front of it while a brown camel is moving towards the front side and a kid wearing white outfit is sitting on top of it and a woman wearing blue outfit and a cap is also sitting on the camel behind the kid."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-wHLbRfZPWM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 34, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_258_0_0"}, {"texts": ["A girl wearing a white t-shirt is sitting on the back of the camel while a man is walking on the grass surface along with the camels in a right direction."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-wHLbRfZPWM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_258_1_0"}, {"texts": ["A woman wearing a blue shirt is sitting on the back of the camel behind the girl while a man wearing black sweatshirt is walking and pulling the rope of the camel."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-wHLbRfZPWM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_258_2_0"}, {"texts": ["A brown camel is walking from right to left on the green grass surface while other person directing the brown camel"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-wHLbRfZPWM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_258_4_0"}, {"texts": ["A woman wearing a green top is standing and peeing the papaya with a knife."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4Hecs1_f5yc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2591_0_0"}, {"texts": ["A boy is standing in the river while another boy is walking out of the river."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0zu0S6ttK3w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 14, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2594_0_0"}, {"texts": ["The boy is pulling an object from the river while another boy moves to the side."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0zu0S6ttK3w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 14, "npz_gt_video_start_frame": 14, "npz_gt_video_end_frame": 37, "skip_frames_after_generation": 14, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2594_0_1"}, {"texts": ["The boy stands near the shore on the left side and holding an object while another boy is also holding an object then lifts is leg."], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0zu0S6ttK3w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 37, "npz_gt_video_start_frame": 37, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 37, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2594_0_2"}, {"texts": ["A boy is walking near the shore while the other boy is in the water."], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0zu0S6ttK3w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 37, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2594_1_0"}, {"texts": ["The boy is standing on the right side and holding an object with other boy."], "durations": null, "exact_frames_per_prompt": [42], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0zu0S6ttK3w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 37, "npz_gt_video_start_frame": 37, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 37, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2594_1_1"}, {"texts": ["A man wearing a black t-shirt is standing, holding a slice of the watermelon."], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-fkVMf-qLEI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 41, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2595_0_ms_0"}, {"texts": ["While eating the watermelon, he breaks the slice into two parts."], "durations": null, "exact_frames_per_prompt": [39], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-fkVMf-qLEI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 41, "npz_gt_video_start_frame": 41, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 41, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2595_0_ms_1"}, {"texts": ["A white bird is flying above the pond."], "durations": null, "exact_frames_per_prompt": [47], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-fkVMf-qLEI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 51, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2595_1_0"}, {"texts": ["A woman on the left is handing over the black snake to the man on the right while two person are standing and watching the snake."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-n0PW0qMNpY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 32, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2596_0_0"}, {"texts": ["A man on the right is taking the snake from the hands of person one while a woman wearing red t-shirt is coming from the left with a girl wearing a green top and looking towards the jungle."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-n0PW0qMNpY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 32, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2596_1_0"}, {"texts": ["A black snake is being held by person one and is being handed over to person two while two girls are moving forward and watching the snake."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-n0PW0qMNpY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 32, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2596_4_0"}, {"texts": ["A man wearing a green t-shirt with a print is standing on the right and taking the snake from the woman while in opposite of them the girls are watching."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-n0PW0qMNpY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 32, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2597_1_0"}, {"texts": ["A black snake is held by the woman and given in the arms of the man while two people approach them"], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-n0PW0qMNpY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 32, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2597_4_0"}, {"texts": ["A girl wearing a white top is lying while facing the wall."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1A191XqZSQw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 34, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2599_0_0"}, {"texts": ["The girl turns around turns around, holding a cushion and then lying straight on the bed."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1A191XqZSQw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 34, "npz_gt_video_start_frame": 34, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 34, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2599_0_1"}, {"texts": ["A woman wearing a black-white dress is sitting on the back of the mule and riding in the stable while the mule stops riding and turns back."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4hwQbVmw4jo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_259_0_0"}, {"texts": ["A brown mule is walking in the stable while carrying a woman on his back."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4hwQbVmw4jo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_259_1_0"}, {"texts": ["A girl wearing a peach colour t-shirt is in the bending position, holding the back leg of the horse and scraping the hoof of the horse with a hoof knife."], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/34-UQmVjQ-Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 37, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_25_0_0"}, {"texts": ["The girl stands up and starts moving her hand while the horse is standing at the back."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/34-UQmVjQ-Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 37, "npz_gt_video_start_frame": 37, "npz_gt_video_end_frame": 61, "skip_frames_after_generation": 37, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_25_0_1"}, {"texts": ["A brown horse is standing on the soil surface and getting its back leg scraped by the girl."], "durations": null, "exact_frames_per_prompt": [57], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/34-UQmVjQ-Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 61, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_25_1_0"}, {"texts": ["A man wearing a multi-color shirt is sitting, watching, and touching the back tire of a car."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-8Smxrww8a0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2604_0_0"}, {"texts": ["A woman whose fingers are visible is holding a carrot and moving the carrot towards the right side a kid is coming from the right side and smiling and taking the carrot."], "durations": null, "exact_frames_per_prompt": [54], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0qFPNlKijPs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2606_0_0"}, {"texts": ["A kid wearing a grey t-shirt is standing on the right side."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0qFPNlKijPs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 17, "npz_gt_video_start_frame": 17, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 17, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2606_1_0"}, {"texts": ["The kid takes the carrot."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0qFPNlKijPs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 44, "npz_gt_video_start_frame": 44, "npz_gt_video_end_frame": 73, "skip_frames_after_generation": 44, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2606_1_1"}, {"texts": ["The kid starts eating the carrot."], "durations": null, "exact_frames_per_prompt": [7], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0qFPNlKijPs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 73, "npz_gt_video_start_frame": 73, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 73, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2606_1_2"}, {"texts": ["A girl in green clothing is standing on a muddy surface and folds her hands while speaking."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-oCrtpjHIDs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 39, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2607_0_0"}, {"texts": ["The girl takes the food from the woman's hand and then drops it on the floor while a black colour goat ate the food"], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-oCrtpjHIDs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 39, "npz_gt_video_start_frame": 39, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 39, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2607_0_1"}, {"texts": ["A woman whose only a hand is visible is giving the food to the girl and a black goat eats the fallen food from a grey surface."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-oCrtpjHIDs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 39, "npz_gt_video_start_frame": 39, "npz_gt_video_end_frame": 75, "skip_frames_after_generation": 39, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2607_1_0"}, {"texts": ["A black goat is looking in the right side while the man beside it gives an object to the girl"], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-oCrtpjHIDs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 39, "npz_gt_video_start_frame": 39, "npz_gt_video_end_frame": 61, "skip_frames_after_generation": 39, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2607_3_0"}, {"texts": ["The black goat is eating the food on the floor and the girl gets scared and moves backward"], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-oCrtpjHIDs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 61, "npz_gt_video_start_frame": 61, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 61, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2607_3_1"}, {"texts": ["A woman wearing a green shirt is squeezing something into the bowl."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1M1yw4BBliE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 34, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2608_0_0"}, {"texts": ["The woman wearing a green shirt is mixing the food in the bowl."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1M1yw4BBliE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 34, "npz_gt_video_start_frame": 34, "npz_gt_video_end_frame": 56, "skip_frames_after_generation": 34, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2608_0_1"}, {"texts": ["The woman wearing a green shirt is serving the dish into a green leaf."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1M1yw4BBliE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 56, "npz_gt_video_start_frame": 56, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 56, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2608_0_2"}, {"texts": ["A woman squeezing a lemon inside a bowl on some stuff."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1M1yw4BBliE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 31, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2609_0_0"}, {"texts": ["The woman starts mixing the stuff."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1M1yw4BBliE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 31, "npz_gt_video_start_frame": 31, "npz_gt_video_end_frame": 52, "skip_frames_after_generation": 31, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2609_0_1"}, {"texts": ["The woman is putting that stuff on a cabbage leaf."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1M1yw4BBliE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 52, "npz_gt_video_start_frame": 52, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 52, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2609_0_2"}, {"texts": ["A dark brown elephant is walking on the gray surface with a group of people \nwho are sitting on its back."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-FmjJcrLs14.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_260_2_0"}, {"texts": ["A girl wearing a white top is standing, brushing her eyebrows with an eyebrow brush."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-lzh38dpuQU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 34, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2610_0_0"}, {"texts": ["The girl doing hand gestures."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-lzh38dpuQU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 34, "npz_gt_video_start_frame": 34, "npz_gt_video_end_frame": 56, "skip_frames_after_generation": 34, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2610_0_1"}, {"texts": ["A man wearing a white shirt is standing and tying a pattern black tie."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1ZTCs_44yz0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2611_0_0"}, {"texts": ["A boy wearing a brown-blue hoodie is standing on the grey surface and playing a doughnut on a string game as Another boy wearing a grey sweater is eating donut which tied on a string and then it falls down, then he bends for picks it up."], "durations": null, "exact_frames_per_prompt": [68], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/35e4rrJkn4c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 72, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2615_0_0"}, {"texts": ["The boy starts tossing the doughnut with his thigh."], "durations": null, "exact_frames_per_prompt": [8], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/35e4rrJkn4c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 72, "npz_gt_video_start_frame": 72, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 72, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2615_0_1"}, {"texts": ["A boy wearing a grey t-shirt is standing on the grey surface and playing a doughnut on a string game while a boy wearing a grey-black t-shirt is eating doughnuts on a string ."], "durations": null, "exact_frames_per_prompt": [52], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/35e4rrJkn4c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 56, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2615_1_0"}, {"texts": ["The boy starts walking on the grey surface while the doughnut falls in the boy's hand who is wearing grey-black t-shirt and he kicks the doughnut from his left knee."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/35e4rrJkn4c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 56, "npz_gt_video_start_frame": 56, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 56, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2615_1_1"}, {"texts": ["A man wearing a blue shirt is caressing the udder of the cow, then standing with one knee on the straw surface and holding the pipes of the milking machine."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-2LiVPczCr8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2616_0_0"}, {"texts": ["A black-white calf is standing behind the cow while a man wearing a blue shirt is sitting on his one knee and holding a pipe that is connected to the cow, and the man is speaking."], "durations": null, "exact_frames_per_prompt": [49], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-2LiVPczCr8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 31, "npz_gt_video_start_frame": 31, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 31, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2616_2_0"}, {"texts": ["A elephant is walking behind the baby elephant on a soil surface while a big elephant is walking in front of the baby elephant and carrying a group of people."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-_sZfHi_G7c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_261_1_0"}, {"texts": ["A baby elephant is walking behind the first elephant on a soil surface while the three person is sitting on the back of the first elephant."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-_sZfHi_G7c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_261_2_0"}, {"texts": ["A baby wearing a cream colored t-shirt is being held by a person and is laughing."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1dDzG1Z0tUI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2620_0_0"}, {"texts": ["A baby wearing a white t-shirt is sitting, held by a person and moving his head and laughing."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1dDzG1Z0tUI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2621_0_0"}, {"texts": ["A boy wearing blue clothes is sitting on a red chair and eating food."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2W0luVW5qek.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2625_0_0"}, {"texts": ["A person whom hand is visible is pointing towards the food that is being cooked over the grill."], "durations": null, "exact_frames_per_prompt": [52], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-CTvtfED6Ak.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 56, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2627_0_0"}, {"texts": ["A boy wearing red clothes is standing and holding a cup and a bottle and pouring some powder in the cup."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/196rNdL2Kqc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2631_0_0"}, {"texts": ["A man standing on the right side is holding a glass bottle in his hand while the other person ties the knot on the bottle"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/8GayAm3WYNM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2634_0_0"}, {"texts": ["A man on the left side is picking up a thread."], "durations": null, "exact_frames_per_prompt": [12], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/8GayAm3WYNM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 33, "npz_gt_video_start_frame": 33, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 33, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2634_1_0"}, {"texts": ["The man is trying it on a glass bottle, held by the other man on the right side."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/8GayAm3WYNM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 45, "npz_gt_video_start_frame": 45, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 45, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2634_1_1"}, {"texts": ["A man wearing a patterned black shirt is standing and pouring a liquid inside a transparent glass."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2ZH0n5EAJVY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2640_0_0"}, {"texts": ["A man wearing a white shirt is adjusting the tie knot.\n"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-a6SxoCScCg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2641_0_0"}, {"texts": ["A man wearing a black sweatshirt is at first sitting in a restaurant and holding a food and shouts and eats the food while a group of people sit around the tables and eating foods."], "durations": null, "exact_frames_per_prompt": [61], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1Ih4HSzwGK4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 65, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2644_0_0"}, {"texts": ["The man is standing in a shopping complex and looking the girls and shouts while another girls shocked and look at the man."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1Ih4HSzwGK4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 65, "npz_gt_video_start_frame": 65, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 65, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2644_0_1"}, {"texts": ["A group of people is sitting in a restaurant and looking to the man shouting while a man wearing black outfits scream loudly and start eating something"], "durations": null, "exact_frames_per_prompt": [60], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1Ih4HSzwGK4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 64, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2644_1_ms_0"}, {"texts": ["A group of people are looking here and there in the shopping complex and then they looks at the man shouting."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1Ih4HSzwGK4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 65, "npz_gt_video_start_frame": 65, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 65, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2644_2_ms_0"}, {"texts": ["A man wearing a black hoodie and black trousers is sitting, he screams, and eats something."], "durations": null, "exact_frames_per_prompt": [60], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1Ih4HSzwGK4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 64, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2645_0_0"}, {"texts": ["The man wearing a black hoodie and black trousers is standing in a store, holding something, and starts screaming."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1Ih4HSzwGK4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 64, "npz_gt_video_start_frame": 64, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 64, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2645_0_1"}, {"texts": ["A man wearing a blue dress is standing and milking the udder of the cow and then smiling while looking in front."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5d8Q_ca7bM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2646_0_0"}, {"texts": ["A whitish cow is standing on the gray ramp and letting the first man milking from her udders."], "durations": null, "exact_frames_per_prompt": [53], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5d8Q_ca7bM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 57, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2646_1_0"}, {"texts": ["A man wearing a blue hoodie is touching the udder of a cow."], "durations": null, "exact_frames_per_prompt": [56], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5d8Q_ca7bM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 60, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2647_0_0"}, {"texts": ["The man moves back while a man in white t-shirt started laughing."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5d8Q_ca7bM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 60, "npz_gt_video_start_frame": 60, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 60, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2647_0_1"}, {"texts": ["A brown cow is standing on a grey surface, moving its leg and getting its udder touched by the first man while the man in the blue starts milking the cow"], "durations": null, "exact_frames_per_prompt": [54], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-5d8Q_ca7bM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2647_2_0"}, {"texts": ["A man wearing a black t-shirt is eating an orange carrot with his hand."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1t6qClHwXq0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2648_0_0"}, {"texts": ["A woman wearing a blue denim jacket is wearing a pearl chain."], "durations": null, "exact_frames_per_prompt": [50], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1G-stgsuk0w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 54, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2649_0_0"}, {"texts": ["The woman wearing a blue denim jacket is making a knot, while sitting on a white sofa."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1G-stgsuk0w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 54, "npz_gt_video_start_frame": 54, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 54, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2649_0_1"}, {"texts": ["A person whom hand is visible holding food for the fishes."], "durations": null, "exact_frames_per_prompt": [42], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-jJvz1Ul23o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 38, "npz_gt_video_start_frame": 38, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 38, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2650_1_0"}, {"texts": ["A white black cat is holded by a woman."], "durations": null, "exact_frames_per_prompt": [49], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3-P1OtsVgfs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 53, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2651_1_0"}, {"texts": ["The white black cat is caressing by her."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3-P1OtsVgfs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 53, "npz_gt_video_start_frame": 53, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 53, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2651_1_1"}, {"texts": ["A man wearing a light grey checked shirt is standing and doing fishing with the help of a fishing rod while a person wearing a blue shirt is standing on the grass surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1IX1Sl456TI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2652_0_0"}, {"texts": ["A fish is fished by a man with a fishing rod and then she starts moving and a person wearing a white shirt is standing while recording a video on a green grass surface."], "durations": null, "exact_frames_per_prompt": [54], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1IX1Sl456TI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 26, "npz_gt_video_start_frame": 26, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 26, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2652_2_0"}, {"texts": ["A man wearing a green t-shirt is at first feeding the white dog."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1U5necmvquE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 26, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2657_0_0"}, {"texts": ["The man is showing the food to the other dog."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1U5necmvquE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 26, "npz_gt_video_start_frame": 26, "npz_gt_video_end_frame": 41, "skip_frames_after_generation": 26, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2657_0_1"}, {"texts": ["The man lifted the dog."], "durations": null, "exact_frames_per_prompt": [11], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1U5necmvquE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 41, "npz_gt_video_start_frame": 41, "npz_gt_video_end_frame": 52, "skip_frames_after_generation": 41, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2657_0_2"}, {"texts": ["The man put it on the other stool and a dog with white fur jumps to the other stool."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1U5necmvquE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 52, "npz_gt_video_start_frame": 52, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 52, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2657_0_3"}, {"texts": ["A white dog is standing on the stool and being fed by the man in green t-shirt."], "durations": null, "exact_frames_per_prompt": [50], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1U5necmvquE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 54, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2657_1_0"}, {"texts": ["The dog jumps on the other stool the man in green t-shirt is feeding and looking towards the table."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1U5necmvquE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 54, "npz_gt_video_start_frame": 54, "npz_gt_video_end_frame": 69, "skip_frames_after_generation": 54, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2657_1_1"}, {"texts": ["A black and brown colored dog is sitting on the stool, it is at first watching the man feeding the white dog."], "durations": null, "exact_frames_per_prompt": [34], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1U5necmvquE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 38, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2657_2_0"}, {"texts": ["The black and brown dog is lifted by the man and keeps it on the other stool."], "durations": null, "exact_frames_per_prompt": [42], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1U5necmvquE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 38, "npz_gt_video_start_frame": 38, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 38, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2657_2_1"}, {"texts": ["A man on the left side is holding fishes in his hands and swimming in the water while the other person is swimming aside."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0fF_tX7Nl9s.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2661_1_0"}, {"texts": ["A girl wearing pink clothes is scuba diving in the water."], "durations": null, "exact_frames_per_prompt": [44], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0fF_tX7Nl9s.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 8, "npz_gt_video_start_frame": 8, "npz_gt_video_end_frame": 52, "skip_frames_after_generation": 8, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2661_2_0"}, {"texts": ["A man wearing a greyish-blue shirt is standing on the road and speaking."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/094prW-Sesc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 39, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2665_0_0"}, {"texts": ["A woman wearing a grey top is holding a metal object."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Ge_8vGZHmw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2667_0_0"}, {"texts": ["The woman wearing a grey top puts it on a tire."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Ge_8vGZHmw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 50, "npz_gt_video_start_frame": 50, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 50, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2667_0_1"}, {"texts": ["A woman wearing a grey t-shirt is standing and holding the steel tool in her hands"], "durations": null, "exact_frames_per_prompt": [44], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Ge_8vGZHmw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 48, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2668_0_0"}, {"texts": ["The woman touches the tire surface."], "durations": null, "exact_frames_per_prompt": [32], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Ge_8vGZHmw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 48, "npz_gt_video_start_frame": 48, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 48, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2668_0_1"}, {"texts": ["A man wearing a gray shirt is wiping the face of a horse."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2luWYpn3wqI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_266_0_0"}, {"texts": ["A gray-white horse is standing and getting its face wiped by a man."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2luWYpn3wqI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_266_1_0"}, {"texts": ["A man wearing a black tracksuit is walking on the grey road surface along with the dog."], "durations": null, "exact_frames_per_prompt": [11], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-9L5fpps3-M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 15, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2673_0_0"}, {"texts": ["The man wearing a black tracksuit starts dancing."], "durations": null, "exact_frames_per_prompt": [65], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-9L5fpps3-M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 15, "npz_gt_video_start_frame": 15, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 15, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2673_0_1"}, {"texts": ["A dog on the left side is tied with a leash and is walking ahead with the first man he started dancing and walking forward."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-9L5fpps3-M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2673_2_0"}, {"texts": ["A boy wearing a black printed t-shirt is holding a fry pan and tossing the food in the fry pan."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0S5GUT-AuxI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2675_0_0"}, {"texts": ["The boy puts the fry pan on the stove."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0S5GUT-AuxI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 44, "npz_gt_video_start_frame": 44, "npz_gt_video_end_frame": 53, "skip_frames_after_generation": 44, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2675_0_1"}, {"texts": ["A person whose hands are visible is cooking a lima bean and steering with the help of a wooden spoon."], "durations": null, "exact_frames_per_prompt": [55], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4RS0g6Exnog.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 59, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2679_0_0"}, {"texts": ["A man wearing gray cloth is standing and holding a horse and cleaning his eyes with a cloth."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2luWYpn3wqI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_267_0_0"}, {"texts": ["A black-white horse is standing and held by a man and is cleaned by the man."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2luWYpn3wqI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_267_1_0"}, {"texts": ["A woman wearing a black top is sitting and is speaking in a restaurant while one man is standing beside her and serving the food and the other is behind her holding a wine."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-cfCZm3Qp6E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2683_0_0"}, {"texts": ["A man on the left wearing white clothes is serving food to the woman."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-cfCZm3Qp6E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2683_1_0"}, {"texts": ["A woman wearing a brown jacket is sitting and pointing with her hand while the man wearing white dress is serving her food"], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-cfCZm3Qp6E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 47, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2684_0_0"}, {"texts": ["A girl wearing maroon cloth is sitting with a girl wearing grey jacket is wiping het mouth and is chewing food in the left"], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2Pchp3jrJs8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 20, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2685_0_0"}, {"texts": ["The girl is eating food."], "durations": null, "exact_frames_per_prompt": [60], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2Pchp3jrJs8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 20, "npz_gt_video_start_frame": 20, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 20, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2685_0_1"}, {"texts": ["A girl wearing gray cloth is sitting and eating food beside the girl wearing red shirt and eating donut."], "durations": null, "exact_frames_per_prompt": [51], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2Pchp3jrJs8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 55, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2685_1_0"}, {"texts": ["A girl wearing a pink dress is sitting on the black chair on the right side of another girl, eating."], "durations": null, "exact_frames_per_prompt": [45], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2Pchp3jrJs8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 49, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2686_0_0"}, {"texts": ["The girl puts the food on the table."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2Pchp3jrJs8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 49, "npz_gt_video_start_frame": 49, "npz_gt_video_end_frame": 74, "skip_frames_after_generation": 49, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2686_0_1"}, {"texts": ["The girl stand up on the white floor."], "durations": null, "exact_frames_per_prompt": [6], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2Pchp3jrJs8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 74, "npz_gt_video_start_frame": 74, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 74, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2686_0_2"}, {"texts": ["A woman whose only upper half-body is visible wearing a black tank-top with a dark gray blazer is sitting on the left side and is speaking while smiling."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/25Khw8juaEM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 30, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2688_0_ms_0"}, {"texts": ["A group of boats are moving in the sea."], "durations": null, "exact_frames_per_prompt": [45], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/25Khw8juaEM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 35, "npz_gt_video_start_frame": 35, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 35, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2688_2_ms_0"}, {"texts": [" A man wearing a black t-shirt is standing, taking out mac pro from the brown box."], "durations": null, "exact_frames_per_prompt": [34], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-AlzbNiAsPI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 38, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2693_0_0"}, {"texts": ["The man is opening the seal of the mac pro box."], "durations": null, "exact_frames_per_prompt": [42], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-AlzbNiAsPI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 38, "npz_gt_video_start_frame": 38, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 38, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2693_0_1"}, {"texts": ["A man whose hand is only visible, holding a black marker, starts writing on white paper."], "durations": null, "exact_frames_per_prompt": [52], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3eoZJybaoT4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 56, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2698_0_0"}, {"texts": ["The man whose hand is only visible then starts pointing at words written on the paper."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3eoZJybaoT4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 56, "npz_gt_video_start_frame": 56, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 56, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2698_0_1"}, {"texts": ["A man wearing a black hoodie is sitting and eating noodles."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0AisbPBEq-c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2699_0_0"}, {"texts": ["A man wearing brown pants is training a white and brown dog and the dog is following the man's command."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/474-RxD5H4U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_269_0_0"}, {"texts": ["A white and brown dog is being trained by the man wearing brown pants."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/474-RxD5H4U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_269_1_0"}, {"texts": ["A girl with the blond hair is lip-syncing while doing hand gestures while other girl wearing green top is doing the hand gestures."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/6AAKbAWvfcs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2700_0_0"}, {"texts": ["A girl on the left side is doing lip-sync while doing the hand gestures while a  girl on the right side wearing a white-green printed top is doing lip-sync while doing the hand gestures."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/6AAKbAWvfcs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2700_1_0"}, {"texts": ["A girl on the right side wearing a gray-green t-shirt is sitting and doing hand gestures while the other girl does the same hand gestures."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/6AAKbAWvfcs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2701_0_0"}, {"texts": ["A girl on the left side wearing a green t-shirt is also sitting and doing hand gestures as another girl on the right side wearing a green-grey t-shirt is also sitting and doing hand gestures."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/6AAKbAWvfcs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2701_1_0"}, {"texts": ["A man wearing a black printed t-shirt is holding a glass mug filled with a beverage and looking the mug."], "durations": null, "exact_frames_per_prompt": [57], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4acmBeZq2Fk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 61, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2707_0_0"}, {"texts": ["The man starts drinking."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4acmBeZq2Fk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 61, "npz_gt_video_start_frame": 61, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 61, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2707_0_1"}, {"texts": ["A man on the left, wearing a black suit is sitting and is speaking on the mic while the others are listening to him"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5d2RlEKburo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2708_0_0"}, {"texts": ["A woman wearing an orange coat is sitting opposite to person one and she is about to speak when a man wearing a gray necktie and sitting on the left side finished speaking."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5d2RlEKburo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2708_1_0"}, {"texts": ["A man wearing a grey t-shirt is standing on the left side as a boy wearing a red t-shirt is standing and looking at the potato."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5PrVKZ5Di6Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 14, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_270_0_0"}, {"texts": ["The man wearing a grey t-shirt putting a potato on the vegetable peeler machine."], "durations": null, "exact_frames_per_prompt": [39], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5PrVKZ5Di6Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 14, "npz_gt_video_start_frame": 14, "npz_gt_video_end_frame": 53, "skip_frames_after_generation": 14, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_270_0_1"}, {"texts": ["The man wearing a grey t-shirt steps back and the boy starts rotating the peeling machine."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5PrVKZ5Di6Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 53, "npz_gt_video_start_frame": 53, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 53, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_270_0_2"}, {"texts": ["A boy wearing a red t-shirt is standing on the right side, scratching his nose as a man wearing a grey t-shirt is standing and putting the potato into the vegetable peeler machine and then steps back."], "durations": null, "exact_frames_per_prompt": [56], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5PrVKZ5Di6Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 60, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_270_1_0"}, {"texts": ["The boy starts rotating the vegetable peeler machine."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5PrVKZ5Di6Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 60, "npz_gt_video_start_frame": 60, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 60, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_270_1_1"}, {"texts": ["A man is hanging a pot on a metal stand over a burning fire."], "durations": null, "exact_frames_per_prompt": [60], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/295yJgCrLTA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 64, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2711_0_0"}, {"texts": ["The main is pulling a pan with a metal stick on the stand."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/295yJgCrLTA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 64, "npz_gt_video_start_frame": 64, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 64, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2711_0_1"}, {"texts": ["A man wearing a black sleeveless jacket is in the front and eating French fry."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1Qz2zo--1lE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 21, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2714_0_0"}, {"texts": ["The man wearing a black sleeveless jacket puts his hand in a paper packet as another man wearing a blue lining t-shirt is standing while keeping a paper packet."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1Qz2zo--1lE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 21, "npz_gt_video_start_frame": 21, "npz_gt_video_end_frame": 39, "skip_frames_after_generation": 21, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2714_0_1"}, {"texts": ["The man wearing a black sleeveless jacket takes a french fry and another man eating it."], "durations": null, "exact_frames_per_prompt": [12], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1Qz2zo--1lE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 39, "npz_gt_video_start_frame": 39, "npz_gt_video_end_frame": 51, "skip_frames_after_generation": 39, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2714_0_2"}, {"texts": ["A man wearing a white shirt is standing and tying a red bow-tie."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/9D8lgyiM9qk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2719_0_0"}, {"texts": ["A girl wearing a graphic black t-shirt is standing and eating the food and covering her mouth with her hand while a woman wearing purple t-shirt dancing and saying something"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1Gq5O6AebNU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_271_0_0"}, {"texts": ["A girl wearing a white-red striped t-shirt is standing on the right side of the third girl and eating the food while people are standing beside and behind them doing different things such as eating, recording and cheering for them."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1Gq5O6AebNU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 59, "npz_gt_video_start_frame": 59, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 59, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_271_2_0"}, {"texts": ["A person whose hand is visible is rubbing the head and neck of a cat."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/11fx7kNit2M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2724_0_0"}, {"texts": ["A black and white cat is getting its head and neck rubbed by a person."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/11fx7kNit2M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2724_1_0"}, {"texts": ["A person wearing a white blue t-shirt is sitting and tapping on the bottom of the bottle as a man in a grey hoodie is bending and looking at the front and then stands up while clapping."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/svXGPnnheC0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 29, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2726_0_0"}, {"texts": ["The person is putting the bottle aside and then pointing him toward the back."], "durations": null, "exact_frames_per_prompt": [44], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/svXGPnnheC0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 29, "npz_gt_video_start_frame": 29, "npz_gt_video_end_frame": 73, "skip_frames_after_generation": 29, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2726_0_1"}, {"texts": ["A man wearing a blue-green dress and black shoes is walking on the snow surface."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3GZqnw9MDJk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 11, "npz_gt_video_start_frame": 11, "npz_gt_video_end_frame": 36, "skip_frames_after_generation": 11, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2727_0_0"}, {"texts": ["The man wearing a blue-green dress and black shoes is sitting."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3GZqnw9MDJk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 36, "npz_gt_video_start_frame": 36, "npz_gt_video_end_frame": 72, "skip_frames_after_generation": 36, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2727_0_1"}, {"texts": ["The man wearing a blue-green dress and black shoes is opening the container."], "durations": null, "exact_frames_per_prompt": [8], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3GZqnw9MDJk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 72, "npz_gt_video_start_frame": 72, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 72, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2727_0_2"}, {"texts": ["A brown elephant is walking in the jungle while carrying people on its back."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0p82v6cSzOk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2728_2_0"}, {"texts": ["A girl wearing a white top is sitting on a black chair while a man in white shirt holds a tattoo machine in hand."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/25JUEuCpFtg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 26, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2729_0_0"}, {"texts": ["The girl is getting a tattoo on her shoulder while a man in white shirt  drawing a tattoo."], "durations": null, "exact_frames_per_prompt": [48], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/25JUEuCpFtg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 26, "npz_gt_video_start_frame": 26, "npz_gt_video_end_frame": 74, "skip_frames_after_generation": 26, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2729_0_1"}, {"texts": ["A man wearing a white t-shirt is standing while the woman is sitting in the chair."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/25JUEuCpFtg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 32, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2729_1_0"}, {"texts": ["The man is making a tattoo on a girl's shoulder."], "durations": null, "exact_frames_per_prompt": [42], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/25JUEuCpFtg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 32, "npz_gt_video_start_frame": 32, "npz_gt_video_end_frame": 74, "skip_frames_after_generation": 32, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2729_1_1"}, {"texts": ["A woman whose upper body is visible wearing a black tank top is sitting on a chair and is getting tattoo on her right hand by the second woman."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2z4Yrwj6TsY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_272_0_0"}, {"texts": ["A second woman whose upper body is visible wearing a black top is making a tattoo with the tattoo machine on the first woman's right hand."], "durations": null, "exact_frames_per_prompt": [73], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2z4Yrwj6TsY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 7, "npz_gt_video_start_frame": 7, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 7, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_272_1_0"}, {"texts": ["A man wearing a green-white check shirt and blue jeans is sitting on a dark blue seat and holding a cup of liquid while another person is holding his phone and recording and the others are sitting around him."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Q__osPqNtE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 27, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2730_0_0"}, {"texts": ["The man wearing a green-white check shirt starts drinking and a person points at something on the table."], "durations": null, "exact_frames_per_prompt": [53], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Q__osPqNtE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 27, "npz_gt_video_start_frame": 27, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 27, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2730_0_1"}, {"texts": ["A person wearing a gray t-shirt and blue jeans is sitting on the right side of the man and looking at him the man wearing green and white shirt drinks a shot"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Q__osPqNtE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2730_1_0"}, {"texts": ["A man wearing black clothes is standing and putting food on a plate."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1mTzDYOIsvw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2737_0_0"}, {"texts": ["The man is putting sauce in it then a man and a woman walks to the side while a woman is sitting on a chair and talking."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1mTzDYOIsvw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 45, "npz_gt_video_start_frame": 45, "npz_gt_video_end_frame": 64, "skip_frames_after_generation": 45, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2737_0_1"}, {"texts": ["A woman wearing black top is sitting and speaking while another woman checked top is involved in that conversation"], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1mTzDYOIsvw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 64, "npz_gt_video_start_frame": 64, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 64, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2737_1_0"}, {"texts": ["A woman wearing a black design dress is sitting and speaking with other girl"], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1mTzDYOIsvw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 62, "npz_gt_video_start_frame": 62, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 62, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2737_2_0"}, {"texts": ["A man wearing a black suit is serving food on a plate."], "durations": null, "exact_frames_per_prompt": [59], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1mTzDYOIsvw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 63, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2738_0_0"}, {"texts": ["A woman wearing black clothes sitting on the left side is talking to another woman."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1mTzDYOIsvw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 57, "npz_gt_video_start_frame": 57, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 57, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2738_3_0"}, {"texts": ["A woman wearing a printed top sitting on the right side is talking to the first woman while a woman wearing black top sitting on the left side looking the opposite woman"], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1mTzDYOIsvw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 63, "npz_gt_video_start_frame": 63, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 63, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2738_4_0"}, {"texts": ["A boy wearing a black t-shirt is sitting."], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/00MUo_0F9-Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 37, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2740_0_0"}, {"texts": ["The boy is eating a burger."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/00MUo_0F9-Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 37, "npz_gt_video_start_frame": 37, "npz_gt_video_end_frame": 78, "skip_frames_after_generation": 37, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2740_0_1"}, {"texts": ["The boy is eating fries."], "durations": null, "exact_frames_per_prompt": [3], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/00MUo_0F9-Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 78, "npz_gt_video_start_frame": 78, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 78, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2740_0_2"}, {"texts": ["A person whose only a hand is visible, is at first scratching the gap of a tire with his finger and then scratching it with a knife."], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3qral2vBh8o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 37, "npz_gt_video_start_frame": 37, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 37, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2741_1_0"}, {"texts": ["A man wearing a grey-white-black t-shirt is eating cake."], "durations": null, "exact_frames_per_prompt": [51], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/68YgZyPHM3E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 55, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_274_0_0"}, {"texts": ["The man wearing a grey-white-black t-shirt starts licking his fingers."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/68YgZyPHM3E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 55, "npz_gt_video_start_frame": 55, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 55, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_274_0_1"}, {"texts": ["A man wearing a graphic gray t-shirt and pants is sitting while holding some coins, taking out one coin."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2VKn-EBqwe0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 28, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2759_0_0"}, {"texts": ["The man starts counting the coins on the table."], "durations": null, "exact_frames_per_prompt": [52], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2VKn-EBqwe0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 28, "npz_gt_video_start_frame": 28, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 28, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2759_0_1"}, {"texts": ["A boy wearing a red t-shirt is eating a white food item from a hanging thread."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/37GGeCScCxQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_275_0_0"}, {"texts": ["A person whose hand is visible is holding a thread with a tied food item while a boy wearing a red top is eating the food on the end of the rope and others are standing few feet away from the boy."], "durations": null, "exact_frames_per_prompt": [42], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/37GGeCScCxQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 38, "npz_gt_video_start_frame": 38, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 38, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_275_1_0"}, {"texts": ["A baby is sitting on a blue and white baby eating chair and eating food from a yellow bowl."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/18TVCQD2etE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2760_0_0"}, {"texts": ["A person whose hand is visible is putting a spoon in the baby's mouth."], "durations": null, "exact_frames_per_prompt": [69], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2FM5UIAx2o4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 11, "npz_gt_video_start_frame": 11, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 11, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2777_0_0"}, {"texts": ["A baby is lying on a baby bed, smiling and licking a spoon while a person with only his hand is visible is holding the spoon and feeding the baby."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2FM5UIAx2o4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2777_1_0"}, {"texts": ["A child wearing a green pyjama is tying knot of the lace in pyjama.\n"], "durations": null, "exact_frames_per_prompt": [54], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-pq8M-SI_Tk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2779_0_0"}, {"texts": ["A man wearing a gray t-shirt, gray jeans and a black apron, is bending over and cutting the nails of the brown-white dog."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1_qRIJdVykk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 21, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_277_0_0"}, {"texts": ["The man is holding it on the green table while the white dog looking at him"], "durations": null, "exact_frames_per_prompt": [58], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1_qRIJdVykk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 21, "npz_gt_video_start_frame": 21, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 21, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_277_0_1"}, {"texts": ["A brown white dog is standing on the green table and getting his nails cut by the man while a white dog is looking behind the glass cabin."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1_qRIJdVykk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 30, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_277_1_0"}, {"texts": ["The brown white dog is sitting on the green table while the man wearing a grey t-shirt is holding the brown dog and a white dog behind the glass cabin is moving."], "durations": null, "exact_frames_per_prompt": [50], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1_qRIJdVykk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 30, "npz_gt_video_start_frame": 30, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 30, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_277_1_1"}, {"texts": ["A white dog is standing in the cage and looking here and there while a man is holding a white and brown colored dog and grooming it on a table."], "durations": null, "exact_frames_per_prompt": [54], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1_qRIJdVykk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 26, "npz_gt_video_start_frame": 26, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 26, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_277_2_0"}, {"texts": ["A man wearing black cloth is standing."], "durations": null, "exact_frames_per_prompt": [12], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4MwQS1Mp9sA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 16, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2783_0_0"}, {"texts": ["The man is holding a kettle."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4MwQS1Mp9sA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 16, "npz_gt_video_start_frame": 16, "npz_gt_video_end_frame": 32, "skip_frames_after_generation": 16, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2783_0_1"}, {"texts": ["The man is pouring some liquids in glass."], "durations": null, "exact_frames_per_prompt": [48], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4MwQS1Mp9sA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 32, "npz_gt_video_start_frame": 32, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 32, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2783_0_2"}, {"texts": ["A woman whose hands are visible is holding a maroon-black drilling machine with attached potato and holding a green vegetable peeler towards the potato."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5GJRsNPu-Ck.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 29, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2784_0_0"}, {"texts": ["The woman presses the drilling machine and starts peeling the potato with vegetable peeler."], "durations": null, "exact_frames_per_prompt": [52], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5GJRsNPu-Ck.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 29, "npz_gt_video_start_frame": 29, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 29, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2784_0_1"}, {"texts": ["A woman wearing gray clothes is sitting on a black chair and is speaking on the mic while looking at the papers."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/---QUuC4vJs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 57, "npz_gt_video_start_frame": 57, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 57, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_278_3_0"}, {"texts": ["A man wearing a blue t-shirt is standing on the left and eating and putting his hand on the mouth then starts drinking from a white cup.\n while a group of people is standing and watching him, and a woman beside the man is standing while eating."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2DqelQSPOVA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2793_0_0"}, {"texts": ["A woman wearing a gray top is standing on the back side, holding the food, eating the food, and putting her hand on her mouth while a man wearing blue t-shirt standing left side holding a cup and drinking something"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2DqelQSPOVA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2793_2_0"}, {"texts": ["A man wearing a blue t-shirt is standing on the left and eating and putting his hand on the mouth while others are watching them."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2DqelQSPOVA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 19, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2794_0_0"}, {"texts": ["The man wearing a blue t-shirt starts drinking from a white cup."], "durations": null, "exact_frames_per_prompt": [61], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2DqelQSPOVA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 19, "npz_gt_video_start_frame": 19, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 19, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2794_0_1"}, {"texts": ["A woman wearing pink patterned clothes is standing and touching her eyes and speaking."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3UR5u_w2q2c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2795_0_0"}, {"texts": ["A woman whose upper body is visible, wearing a printed pink cloth, is showing her face while touching her face with her right hand fingers and speaking while moving her hands."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3UR5u_w2q2c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2796_0_0"}, {"texts": ["A person wearing a pink jacket and black pants is holding a dog by the leash and starts walking while The dog sits down."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-qC7E3t6smU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2798_0_0"}, {"texts": ["A brown dog is walking around the room while a woman in a pink jacket holding the dog belt and walking forward with a dog."], "durations": null, "exact_frames_per_prompt": [65], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-qC7E3t6smU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 69, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2798_1_0"}, {"texts": ["The dog sits down while the woman is scratching the dog's head."], "durations": null, "exact_frames_per_prompt": [11], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-qC7E3t6smU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 69, "npz_gt_video_start_frame": 69, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 69, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2798_1_1"}, {"texts": ["A woman wearing a white shirt is sitting on the black sofa and is tearing papers while looking at the baby."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2qEOHHrhafY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_279_0_0"}, {"texts": ["A baby wearing a purple t-shirt is picking up a piece of paper.  while a woman in white top is plying with baby."], "durations": null, "exact_frames_per_prompt": [62], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2qEOHHrhafY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 66, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_279_1_0"}, {"texts": ["The baby is laughing."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2qEOHHrhafY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 66, "npz_gt_video_start_frame": 66, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 66, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_279_1_1"}, {"texts": ["A boy wearing a white shirt is sitting and tying a maroon tie on his shirt collar.\n while a woman wearing specs sitting on the left side showing her finger towards the man"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0CkajhOMX1w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2803_0_0"}, {"texts": ["A woman wearing a dark gray-black vest is holding a makeup brush and brushing around her face while looking to the left side."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-xM5R1O8tos.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2806_0_0"}, {"texts": ["A woman wearing gray-black cloth is standing and holding a brush and spreading cream on her face and speaking."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-xM5R1O8tos.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2807_0_0"}, {"texts": ["A man wearing a black t-shirt and black jeans is sitting on a chair while holding a beer glass mug, putting the glass on the table."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5faGPNmdEcE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 14, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2808_3_0"}, {"texts": ["The man is pointing his right hand in the front."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5faGPNmdEcE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 14, "npz_gt_video_start_frame": 14, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 14, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2808_3_1"}, {"texts": ["The man looks in front. "], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5faGPNmdEcE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 50, "npz_gt_video_start_frame": 50, "npz_gt_video_end_frame": 70, "skip_frames_after_generation": 50, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2808_3_2"}, {"texts": ["The man is tilting his body towards the glass mug and is drinking beer with his mouth from the glass mug."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5faGPNmdEcE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 70, "npz_gt_video_start_frame": 70, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 70, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2808_3_3"}, {"texts": ["A person whose hands are visible is cutting the meat with a knife, the video of which is streaming side by side."], "durations": null, "exact_frames_per_prompt": [62], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1J9GghXhWuY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 18, "npz_gt_video_start_frame": 18, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 18, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2821_1_ms_0"}, {"texts": ["A person whose only hands are visible is holding a piece of paper in his hands and moving it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1J9GghXhWuY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2822_0_ms_0"}, {"texts": ["A person is making a cut into the meat with a knife."], "durations": null, "exact_frames_per_prompt": [62], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1J9GghXhWuY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 18, "npz_gt_video_start_frame": 18, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 18, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2822_1_0"}, {"texts": ["A boy wearing a multicolored printed t-shirt is standing in the front, holding a green packet of tissue paper."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1IxOss60EVU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 27, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2824_0_0"}, {"texts": ["The boy takes the tissue paper."], "durations": null, "exact_frames_per_prompt": [38], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1IxOss60EVU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 27, "npz_gt_video_start_frame": 27, "npz_gt_video_end_frame": 65, "skip_frames_after_generation": 27, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2824_0_1"}, {"texts": ["The boy puts it into a white cup."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1IxOss60EVU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 65, "npz_gt_video_start_frame": 65, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 65, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2824_0_2"}, {"texts": ["A man is standing."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2bKPE0ZeUU4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 13, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2828_0_0"}, {"texts": ["The man is holding a surgical tape."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2bKPE0ZeUU4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 13, "npz_gt_video_start_frame": 13, "npz_gt_video_end_frame": 36, "skip_frames_after_generation": 13, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2828_0_1"}, {"texts": ["The man is giving instructions how to apply surgical tape."], "durations": null, "exact_frames_per_prompt": [44], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2bKPE0ZeUU4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 36, "npz_gt_video_start_frame": 36, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 36, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2828_0_2"}, {"texts": ["A man whose upper half-body is visible wearing a lavender blue shirt and specs is sitting, making a funny face while putting the necktie on the table."], "durations": null, "exact_frames_per_prompt": [32], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0OOUOM8KRB4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 36, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2830_0_0"}, {"texts": ["The man wears a necktie while putting the necktie on his neck. "], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0OOUOM8KRB4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 36, "npz_gt_video_start_frame": 36, "npz_gt_video_end_frame": 65, "skip_frames_after_generation": 36, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2830_0_1"}, {"texts": ["The man starts tying the necktie."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0OOUOM8KRB4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 65, "npz_gt_video_start_frame": 65, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 65, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2830_0_2"}, {"texts": ["A woman wearing a maroon t-shirt is making a bed."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/j4t29DTNLQc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2833_0_ms_0"}, {"texts": ["A woman wearing a brown t-shirt is making a bed."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/j4t29DTNLQc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2834_0_0"}, {"texts": ["A man wearing white clothes is sitting on the floor and pouring egg mixture into a pan and spreading it. "], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2jDDp4ymnUA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 22, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2843_0_0"}, {"texts": ["The man is making scrambled eggs."], "durations": null, "exact_frames_per_prompt": [58], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2jDDp4ymnUA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 22, "npz_gt_video_start_frame": 22, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 22, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2843_0_1"}, {"texts": ["A person whose hands are visible is wrapping a box with wrapping paper and a tape."], "durations": null, "exact_frames_per_prompt": [64], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-oCRYzuBews.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 16, "npz_gt_video_start_frame": 16, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 16, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_284_0_0"}, {"texts": ["A girl wearing a graphic blue top and graphic black pants is sitting and eating food."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-LVbgohI4HA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 26, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2853_0_0"}, {"texts": ["The girl moved her hand forward with the food."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-LVbgohI4HA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 26, "npz_gt_video_start_frame": 26, "npz_gt_video_end_frame": 53, "skip_frames_after_generation": 26, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2853_0_1"}, {"texts": ["The girl is taking it back."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-LVbgohI4HA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 53, "npz_gt_video_start_frame": 53, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 53, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2853_0_2"}, {"texts": ["A person whose only hands is visible is turning a folded red napkin on the grey surface to the opposite side."], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1n3fYR2Jf8E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 47, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2855_0_0"}, {"texts": ["The person is pointing to the napkin with his finger."], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1n3fYR2Jf8E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 47, "npz_gt_video_start_frame": 47, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 47, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2855_0_1"}, {"texts": ["A girl wearing an off-white top is sitting on the bed and looking here and there while the other person sits along with her"], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0jFBHhjvbYs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 35, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2863_0_0"}, {"texts": ["A girl whose back is visible is also sitting on the bed and is doing something while a girl is sitting in front of her and smiling."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0jFBHhjvbYs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 34, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2863_1_0"}, {"texts": ["A girl wearing a gray jacket is sitting and opening the letters."], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0jFBHhjvbYs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 43, "npz_gt_video_start_frame": 43, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 43, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2863_2_0"}, {"texts": ["A girl wearing a light purple t-shirt and light purple leggings is sitting on the floor and smiling while looking to the left and the right."], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0jFBHhjvbYs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 35, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2864_0_0"}, {"texts": ["A woman wearing a gray top and black jeans is sitting on the floor on the right side and is picking up the paper object from the floor with her hands."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0jFBHhjvbYs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 45, "npz_gt_video_start_frame": 45, "npz_gt_video_end_frame": 66, "skip_frames_after_generation": 45, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2864_2_0"}, {"texts": ["The woman is opening the paper object."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0jFBHhjvbYs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 66, "npz_gt_video_start_frame": 66, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 66, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2864_2_1"}, {"texts": ["A person wearing black clothes is sitting near the car and holding a tool and touching the wheel."], "durations": null, "exact_frames_per_prompt": [70], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4oyV_yblhEo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 10, "npz_gt_video_start_frame": 10, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 10, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2872_0_0"}, {"texts": ["A baby wearing blue-white dress is crying."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-Dk0FFQ7hiU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_287_0_0"}, {"texts": ["A kid wearing a black color cap is sitting on the gray surface and throwing fish food in the water."], "durations": null, "exact_frames_per_prompt": [50], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/07JFxr9qwVc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 30, "npz_gt_video_start_frame": 30, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 30, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2880_0_0"}, {"texts": ["A standing baby is throwing brown stuff from a bowl he is holding in his hands."], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/07JFxr9qwVc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 30, "npz_gt_video_start_frame": 30, "npz_gt_video_end_frame": 73, "skip_frames_after_generation": 30, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2881_0_0"}, {"texts": ["The boy is bending towards the pond."], "durations": null, "exact_frames_per_prompt": [7], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/07JFxr9qwVc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 73, "npz_gt_video_start_frame": 73, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 73, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2881_0_1"}, {"texts": ["A boy wearing a black t-shirt is standing and has taken a brown snake around his neck."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/53sNjG-EWmE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2884_0_0"}, {"texts": ["A brown snake lying around the neck of the boy is hissing towards the boy's face."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/53sNjG-EWmE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_2884_1_0"}, {"texts": ["A girl wearing a polka-dot dress is plucking a red fruit from the green tree."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0kNcTxm63JQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_289_0_0"}, {"texts": ["A baby girl wearing a white-black frock standing in a green grass field is plucking fruit from the tree."], "durations": null, "exact_frames_per_prompt": [48], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0kNcTxm63JQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 52, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_290_0_0"}, {"texts": ["The baby girl is walking and showing the fruit."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0kNcTxm63JQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 52, "npz_gt_video_start_frame": 52, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 52, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_290_0_1"}, {"texts": ["A man wearing a gray t-shirt and blue jeans is standing and spreading food for the pigeons on the ground a woman wearing a purple dress is also feeding the pigeons."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-7BVb-zigbA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_291_0_0"}, {"texts": ["A girl wearing a purple frock is standing in the front holding food in her hand."], "durations": null, "exact_frames_per_prompt": [68], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-7BVb-zigbA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 12, "npz_gt_video_start_frame": 12, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 12, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_291_1_0"}, {"texts": ["A man wearing a white dress and a watch is standing and cutting a slice of a pineapple with a knife."], "durations": null, "exact_frames_per_prompt": [52], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-tdr5TVLqXs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 56, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_293_0_0"}, {"texts": ["The man putting a cookie cutter in the core of the slice and pressing it."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-tdr5TVLqXs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 56, "npz_gt_video_start_frame": 56, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 56, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_293_0_1"}, {"texts": ["A girl wearing a dark pink top is sitting on the gray surface and feeding the pigeons."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-1VyqbLf1Pg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_296_0_0"}, {"texts": ["A girl wearing a light pink jacket is sitting in the front on the road while the other girl is feeding the pigeons"], "durations": null, "exact_frames_per_prompt": [65], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-1VyqbLf1Pg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 69, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_297_1_0"}, {"texts": ["The girl is feeding the group of pigeons in her open palm."], "durations": null, "exact_frames_per_prompt": [12], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-1VyqbLf1Pg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 69, "npz_gt_video_start_frame": 69, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 69, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_297_1_1"}, {"texts": ["A man wearing t-shirt is playing golf on the golf course."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0eVZWU4H3Ao.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_298_0_0"}, {"texts": ["A boy wearing a sky-blue t-shirt is sitting and holding a hen the boy licking and eating something."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-irl68ywUzI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_299_0_0"}, {"texts": ["A boy wearing a green shirt is sitting a boy wearing a sky-blue t-shirt is sitting and holding a hen."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-irl68ywUzI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 21, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_299_1_0"}, {"texts": ["The boy licking and eating something."], "durations": null, "exact_frames_per_prompt": [59], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-irl68ywUzI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 21, "npz_gt_video_start_frame": 21, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 21, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_299_1_1"}, {"texts": ["A hen is sitting in the lap of a boy a boy with a green shirt is biting some straw"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-irl68ywUzI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_299_2_0"}, {"texts": ["A woman wearing a white sweatshirt and black pants is standing on the right side of the countertop, holding a hand mixer and mixing a black paste in a bowl a girl wearing a lavender color sweatshirt is standing on the chair,along with the woman, holding a mixer and mixing a black paste in a bowl."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2X40l56krhc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_308_0_0"}, {"texts": ["A girl wearing a lavender color sweatshirt is standing on the chair, beside the woman, holding a mixer and mixing a black paste in a bowl a woman wearing white clothes is standing and mixing a black paste with a hand mixer while holding a girls hand."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2X40l56krhc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_308_1_0"}, {"texts": ["A woman wearing white clothes is standing and mixing a black paste with a hand mixer while holding a girl's hand a girl wearing a lavender color sweatshirt is standing on the chair, holding a mixer and mixing a black paste in a bowl along with the woman."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2X40l56krhc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_309_0_0"}, {"texts": ["A girl wearing a purple hoodie is standing on the chair and mixing a black paste with a hand mixer while holding a woman's hand."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2X40l56krhc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_309_1_0"}, {"texts": ["A kid wearing an orange t-shirt and black-white-red-orange pants is standing and eating a fruit."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3aYXMxjjqc4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_30_0_0"}, {"texts": ["A person whose hands are visible is holding a pen."], "durations": null, "exact_frames_per_prompt": [56], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2YRdhTjKgR0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 60, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_311_0_0"}, {"texts": ["And starts writing on the paper."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2YRdhTjKgR0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 60, "npz_gt_video_start_frame": 60, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 60, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_311_0_1"}, {"texts": ["A girl wearing a black jacket is standing on the grey floor, caressing and touching the corn snake a person wearing white printed shirt is holding the snake in his hands"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5L0rNDJoGQY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_312_1_0"}, {"texts": ["A person wearing a blue jacket is standing on the left side, touching the snake a person wearing white printed shirt is holding the snake in his hands"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5L0rNDJoGQY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_313_1_0"}, {"texts": ["A man wearing a black jacket and dark brown pants is standing on the concrete surface and holding a car's tire with his hands on the concrete surface while tilting his body and is speaking while touching the tire with his right hand."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2Qkt9PX0jXU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_314_0_0"}, {"texts": ["A child wearing an orange bin is sitting on an orange-green bed, holding a brown object, laughing."], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0PUt5XSDGwA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 47, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_317_0_0"}, {"texts": ["The child wearing an orange bin is falling on the bed."], "durations": null, "exact_frames_per_prompt": [3], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0PUt5XSDGwA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 47, "npz_gt_video_start_frame": 47, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 47, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_317_0_1"}, {"texts": ["A woman wearing a gray top is sitting, holding a glass of beer while the other man sipping glass of beer."], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-Y9w-IDDK5Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 41, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_319_0_0"}, {"texts": ["The woman scratches her chin while the other man speaks something."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-Y9w-IDDK5Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 41, "npz_gt_video_start_frame": 41, "npz_gt_video_end_frame": 71, "skip_frames_after_generation": 41, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_319_0_1"}, {"texts": ["The woman raises a toast while the other man shows a glass of beer."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-Y9w-IDDK5Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 71, "npz_gt_video_start_frame": 71, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 71, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_319_0_2"}, {"texts": ["A man wearing a gray t-shirt is sitting, holding a glass of beer, and drinking the man wearing a black t-shirt is talking while drinking the beer"], "durations": null, "exact_frames_per_prompt": [68], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-Y9w-IDDK5Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 72, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_319_1_0"}, {"texts": ["The man raising a toast a woman wearing a grey t-shirt is lifting the glass of beer"], "durations": null, "exact_frames_per_prompt": [8], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-Y9w-IDDK5Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 72, "npz_gt_video_start_frame": 72, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 72, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_319_1_1"}, {"texts": ["A woman wearing a gray cloth is sitting, and holding a glass of beer the man wearing a black t-shirt is talking while drinking the beer"], "durations": null, "exact_frames_per_prompt": [66], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-Y9w-IDDK5Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 70, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_320_0_0"}, {"texts": ["The woman wearing a gray cloth is raising a toast a man wearing a black t-shirt is moving the beer glass"], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-Y9w-IDDK5Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 70, "npz_gt_video_start_frame": 70, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 70, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_320_0_1"}, {"texts": ["A woman wearing a white t-shirt is standing and picking up a brown pot."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4N3YV8tuZKE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_321_0_0"}, {"texts": ["The woman is applying some liquid on the food with a brush."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4N3YV8tuZKE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 44, "npz_gt_video_start_frame": 44, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 44, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_321_0_1"}, {"texts": ["A man wearing a grey-black t-shirt is standing on the backside, holding a poly-bag of water and showing the poly-bag to the group of people."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4B6D7gpYYBo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_333_0_0"}, {"texts": ["A brown fish, facing right side is swimming inside a transparent aquarium while a man standing behind the aquarium and watching fish"], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0wzBFCegdZI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 29, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_334_1_ms_0"}, {"texts": ["Another small brown fish on the right side is swimming inside a transparent aquarium with the second fish."], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0wzBFCegdZI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 30, "npz_gt_video_start_frame": 30, "npz_gt_video_end_frame": 73, "skip_frames_after_generation": 30, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_334_3_ms_0"}, {"texts": ["A woman wearing a colourful cloth is getting up while holding the table."], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1TZJqNJ4YtE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 14, "npz_gt_video_start_frame": 14, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 14, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_335_1_0"}, {"texts": ["The woman raise her hands in the air and starts speaking."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1TZJqNJ4YtE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 45, "npz_gt_video_start_frame": 45, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 45, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_335_1_1"}, {"texts": ["A person wearing a white shirt is tying a yellow bow around his neck."], "durations": null, "exact_frames_per_prompt": [45], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0l5AJVEcrb0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 49, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_336_0_0"}, {"texts": ["A man wearing a black t-shirt is standing and peeling an apple attached to a drill machine.\n a girl wearing a blue t-shirt is keenly looking at the task performed by the man"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2wqW177zwaA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_338_0_0"}, {"texts": ["A girl wearing a blue t-shirt is standing and watching the apple peeling process a man wearing a black t-shirt is standing and peeling an apple attached to a drill machine."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2wqW177zwaA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_338_1_0"}, {"texts": ["A man wearing a graphic dark gray t-shirt and dark blue jeans is holding a pan and flipping the food."], "durations": null, "exact_frames_per_prompt": [39], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Or3nOLTTwc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 43, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_339_0_0"}, {"texts": ["The man drops the utensil and starts laughing."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Or3nOLTTwc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 43, "npz_gt_video_start_frame": 43, "npz_gt_video_end_frame": 63, "skip_frames_after_generation": 43, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_339_0_1"}, {"texts": ["A man wearing a black suit is sitting group of people are looking at the man"], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/29_pCX3EY14.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 27, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_33_0_0"}, {"texts": ["The man stands up and picks up his belongings a man with black suit comes and takes some papers from the table"], "durations": null, "exact_frames_per_prompt": [49], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/29_pCX3EY14.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 27, "npz_gt_video_start_frame": 27, "npz_gt_video_end_frame": 76, "skip_frames_after_generation": 27, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_33_0_1"}, {"texts": ["A man also wearing a suit comes from the left and stands idle a man wearing a black suit gets up from the chair and moves"], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/29_pCX3EY14.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 33, "npz_gt_video_start_frame": 33, "npz_gt_video_end_frame": 76, "skip_frames_after_generation": 33, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_33_1_0"}, {"texts": ["A man wearing a dark grey printed t-shirt is standing and flipping the food in a frying pan."], "durations": null, "exact_frames_per_prompt": [59], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Or3nOLTTwc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 63, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_340_0_0"}, {"texts": ["A person whose hands are visible is cutting the pieces of food with a knife."], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0bN6zUGOehM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 37, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_342_0_0"}, {"texts": ["A person wearing a white t-shirt is tying a tie."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/15KFWFkp0MA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_343_0_0"}, {"texts": ["A man wearing white clothes is making a tie."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/15KFWFkp0MA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_344_0_0"}, {"texts": ["A woman wearing red clothes is standing and speaking."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-WdB8oVQHOk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 31, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_346_0_ms_0"}, {"texts": ["A woman wearing white clothes is also standing and reading the weather forecast."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-WdB8oVQHOk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 50, "npz_gt_video_start_frame": 50, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 50, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_346_1_0"}, {"texts": ["A man wearing a gray dress is standing, holding a skimmer with one hand and a cauldron from the other hand, sauteing the food from the skimmer on the stove."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0PmEiQ386CY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_351_0_0"}, {"texts": ["A man wearing grey pants is sitting on the carpet, first folding the cloth."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1VlTKG9_h68.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 31, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_352_0_0"}, {"texts": ["The man is holding his leg."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1VlTKG9_h68.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 31, "npz_gt_video_start_frame": 31, "npz_gt_video_end_frame": 56, "skip_frames_after_generation": 31, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_352_0_1"}, {"texts": ["The man is starting to hit his leg against his chest."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1VlTKG9_h68.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 56, "npz_gt_video_start_frame": 56, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 56, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_352_0_2"}, {"texts": ["A man wearing a jacket is filling fuel in the tank of his motor cycle."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1UHsw4nNMLA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_353_0_0"}, {"texts": ["A woman wearing a white and black printed cloth is speaking, and lying on the soil surface under a vehicle."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2mmx18Cf5xk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 61, "npz_gt_video_start_frame": 61, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 61, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_356_1_0"}, {"texts": ["A woman wearing a black jacket is standing and holding a child in her hands near a red fruit tree."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-M1W0Zj52T8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_358_0_0"}, {"texts": ["A child wearing blue clothes is sitting in the lap of a woman and touching the red fruit."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-M1W0Zj52T8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_358_1_0"}, {"texts": ["A man wearing a gray shirt and black trousers is sitting, moving his hand, and telling weather forecast."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-XlLzuqoXag.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_360_0_0"}, {"texts": ["A man wearing an orange vest and blue jeans is standing while tilting his body on the left side and is shearing the sheep with the sheep clipper a man wearing black t-shirt is trimming the sheep and man with blue pant is walking around"], "durations": null, "exact_frames_per_prompt": [43], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0vjCk03or88.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 37, "npz_gt_video_start_frame": 37, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 37, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_362_2_0"}, {"texts": ["A kid wearing a printed t-shirt is standing and holding a newspaper."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-CFiVdQyv4E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_366_0_0"}, {"texts": ["A man wearing a white cloth is sitting, folding a newspaper and beside him is a baby holding a newspaper while looking at what the man is holding."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-CFiVdQyv4E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_366_1_0"}, {"texts": ["The man is putting it on the brown table and the baby hands the newspaper to the man but later changes his mind, and refuses to give the newspaper."], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-CFiVdQyv4E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 44, "npz_gt_video_start_frame": 44, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 44, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_366_1_1"}, {"texts": ["A man wearing a white-brown striped shirt, black shorts, and black slippers is standing by the car and then standing with folding his hands and is talking to the different men."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3yzVVN43Z5o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_36_0_0"}, {"texts": ["A man wearing a white t-shirt and brown shorts is standing while putting his hands on his waist and is talking to the first man."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3yzVVN43Z5o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 34, "npz_gt_video_start_frame": 34, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 34, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_36_3_ms_0"}, {"texts": ["A person whom hands are visible is applying a spread on a piece of bread with a knife.\n"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2vvxK-Yaxgg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_373_0_0"}, {"texts": ["A boy wearing black t-shirt is taking out clothes from the washing machine."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/7712i5IsLTQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_374_0_0"}, {"texts": ["A boy wearing a white t-shirt takes the animal food from the man."], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0VZAgBAgdP8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 37, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_379_1_0"}, {"texts": ["The boy wearing a white t-shirt is feeding the white animal behind the cage."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0VZAgBAgdP8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 37, "npz_gt_video_start_frame": 37, "npz_gt_video_end_frame": 63, "skip_frames_after_generation": 37, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_379_1_1"}, {"texts": ["A person whose hands are visible is lying on the floor under the vehicle and fastening the nut using his hand."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1ExsR4wfJwU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_380_0_0"}, {"texts": ["The person is fastening the nut using a wrench."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1ExsR4wfJwU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 44, "npz_gt_video_start_frame": 44, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 44, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_380_0_1"}, {"texts": ["A person whose hands are visible is holding the bunch of notes in one hand and counting it one by one from the other hand, and putting it on the floor."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-WVXLhiSMg0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_382_0_0"}, {"texts": ["A person whom hands are visible is counting banknotes and throwing the notes on the floor."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-WVXLhiSMg0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_383_0_0"}, {"texts": ["A woman wearing a white top is at first standing and then she grabs a piece of food a man wearing a yellow top is standing on the left side"], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4bIa7q5fAZA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 15, "npz_gt_video_start_frame": 15, "npz_gt_video_end_frame": 56, "skip_frames_after_generation": 15, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_384_1_0"}, {"texts": ["The woman starts eating."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4bIa7q5fAZA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 56, "npz_gt_video_start_frame": 56, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 56, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_384_1_1"}, {"texts": ["A man wearing a yellow top is standing on the left side of the woman in a white clothes a woman wearing a white top is at first standing and then she grabs a piece of food."], "durations": null, "exact_frames_per_prompt": [63], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4bIa7q5fAZA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 17, "npz_gt_video_start_frame": 17, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 17, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_384_3_0"}, {"texts": ["A boy wearing a light gray t-shirt is sitting and folding a white paper sheet."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/02JpMEfAtMU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_388_0_0"}, {"texts": ["A man wearing a white t-shirt and white gloves is making a tattoo on the right arm of the other man with a tattoo machine a man without a shirt is sitting on a black chair and getting a tattoo"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1_bxueZ_tKE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_389_0_0"}, {"texts": ["A man without shirt is sitting on a black chair and getting a tattoo on his right arm by the man wearing white t-shirt."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1_bxueZ_tKE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_389_1_0"}, {"texts": ["A person wearing gray clothes is holding a white paper toy in their hand."], "durations": null, "exact_frames_per_prompt": [59], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0XN9eDzCz1U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 21, "npz_gt_video_start_frame": 21, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 21, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_391_0_0"}, {"texts": ["A girl wearing a green-blue top and a dark gray jacket is standing and peeling a potato."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/55lulACxaew.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 33, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_397_0_0"}, {"texts": ["The girl drops it into the sink."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/55lulACxaew.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 33, "npz_gt_video_start_frame": 33, "npz_gt_video_end_frame": 46, "skip_frames_after_generation": 33, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_397_0_1"}, {"texts": ["The girl starts peeling again."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/55lulACxaew.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 46, "npz_gt_video_start_frame": 46, "npz_gt_video_end_frame": 67, "skip_frames_after_generation": 46, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_397_0_2"}, {"texts": ["A woman wearing a gray jacket, standing in a kitchen is peeling a potato with a peeler."], "durations": null, "exact_frames_per_prompt": [63], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/55lulACxaew.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 67, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_398_0_0"}, {"texts": ["A boy sitting on a grass and soil surface is milking the first cow and collecting its milk into a bottle."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-gQJhQsWFXA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_399_2_0"}, {"texts": ["A small white calf is sucking milk from the first cow's breast while the boy is collecting the milk into a bottle"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-gQJhQsWFXA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_399_3_0"}, {"texts": ["A man wearing a gray t-shirt and black jeans is sitting on a chair on the left side, and is spreading the red sauce on the pizza base with a spoon while holding the spoon in his right hand."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-xq2AXf-rKE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_3_0_0"}, {"texts": ["A child wearing a maroon t-shirt and maroon shorts is sitting on a chair while putting his hands on the table on the right side and babbling while looking at the pizza base while the other person is preparing the pizza base"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-xq2AXf-rKE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_3_1_0"}, {"texts": ["A person whose hands are visible is cutting round rings from a flatten dough with a cookie cutter."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1mxNs9n5C-o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 33, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_400_0_0"}, {"texts": ["The man putting them into a tray."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1mxNs9n5C-o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 33, "npz_gt_video_start_frame": 33, "npz_gt_video_end_frame": 63, "skip_frames_after_generation": 33, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_400_0_1"}, {"texts": ["A girl wearing a black jacket is standing and moving her hand in sign language."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/7jrjnRyQLaE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_404_0_0"}, {"texts": ["A person whose only a hand is visible is holding a glass bowl and spreading the red sauce over the food with a spoon."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-zN1O9ZwjWg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_406_0_0"}, {"texts": ["A person wearing white glove is tattooing another person's sole a person wearing a printed black t-shirt is getting a tattoo on his sole."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1k_q9azW5ZI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_40_0_0"}, {"texts": ["A person wearing a printed black t-shirt is getting a tattoo on his sole.\n a person on the right side is holding the second person's feet with both hands while a person wearing white glove is tattooing."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1k_q9azW5ZI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_40_1_0"}, {"texts": ["A person on the right side is holding the second person's feet with both hands a person wearing a printed black t-shirt is getting a tattoo on his sole."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1k_q9azW5ZI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_40_2_0"}, {"texts": ["A boy wearing a white t-shirt with written words is on the left side, putting food in his mouth.\n"], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1SbmvZwbV4w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_414_0_0"}, {"texts": ["The boy starts drinking with a straw from a white-red cup. "], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1SbmvZwbV4w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 45, "npz_gt_video_start_frame": 45, "npz_gt_video_end_frame": 61, "skip_frames_after_generation": 45, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_414_0_1"}, {"texts": ["The boy puts his hand towards his mouth."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1SbmvZwbV4w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 61, "npz_gt_video_start_frame": 61, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 61, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_414_0_2"}, {"texts": ["A man wearing a colourful t-shirt is holding a dog leash and running along with the dog on the grey surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-d_4wMddlK8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_416_0_0"}, {"texts": ["A black-white dog tied with a leash and is running along with the man on the grey surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-d_4wMddlK8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_416_1_0"}, {"texts": ["A man wearing a shirt is sitting behind the table."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2M_SxI_s3r4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 18, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_41_0_0"}, {"texts": ["The man counting the notes then speaking while looking away"], "durations": null, "exact_frames_per_prompt": [52], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2M_SxI_s3r4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 18, "npz_gt_video_start_frame": 18, "npz_gt_video_end_frame": 70, "skip_frames_after_generation": 18, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_41_0_1"}, {"texts": ["The man is counting again."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2M_SxI_s3r4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 70, "npz_gt_video_start_frame": 70, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 70, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_41_0_2"}, {"texts": ["A man wearing a blue shirt is standing and getting his bow tied by another man."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5yPwHUy_kNQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_420_0_0"}, {"texts": ["A man wearing a check shirt whose hands are visible is tying the bow of person one."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5yPwHUy_kNQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_420_1_0"}, {"texts": ["A man whose hands are visible is tying the bow-tie of another man."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5yPwHUy_kNQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_421_0_0"}, {"texts": ["A man wearing a striped shirt is standing and getting bow-tie tied by a man."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5yPwHUy_kNQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_421_1_0"}, {"texts": ["A woman wearing a white-black design top is sitting on the left and holding a small white bowl with a spoon a woman wearing a floral top is eating something with a spoon."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0-mcCvalb6Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 22, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_422_0_0"}, {"texts": ["The woman is pointing her finger toward a bottle a woman wearing a floral top moves behind"], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0-mcCvalb6Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 22, "npz_gt_video_start_frame": 22, "npz_gt_video_end_frame": 41, "skip_frames_after_generation": 22, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_422_0_1"}, {"texts": ["The woman takes the bottle in her hand and starts looking at the bottle a woman wearing a floral top talks to her"], "durations": null, "exact_frames_per_prompt": [39], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0-mcCvalb6Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 41, "npz_gt_video_start_frame": 41, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 41, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_422_0_2"}, {"texts": ["A woman wearing a black top is sitting on the right side and taking out a spoon from her mouth while the women sitting on the left side is saying something"], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0-mcCvalb6Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 18, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_422_1_0"}, {"texts": ["The woman opens her blindfolded."], "durations": null, "exact_frames_per_prompt": [8], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0-mcCvalb6Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 18, "npz_gt_video_start_frame": 18, "npz_gt_video_end_frame": 26, "skip_frames_after_generation": 18, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_422_1_1"}, {"texts": ["The woman scratches her nose the other women picks up the bottle"], "durations": null, "exact_frames_per_prompt": [54], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0-mcCvalb6Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 26, "npz_gt_video_start_frame": 26, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 26, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_422_1_2"}, {"texts": ["A baby in pink clothing is at first looking behind while holding some food."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/22Y6OZHPPV0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 23, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_425_0_0"}, {"texts": ["The baby in pink clothing then puts the food in his mouth while looking here and there."], "durations": null, "exact_frames_per_prompt": [57], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/22Y6OZHPPV0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 23, "npz_gt_video_start_frame": 23, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 23, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_425_0_1"}, {"texts": ["A baby wearing a pink dress is sitting.\n"], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/22Y6OZHPPV0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 29, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_426_0_0"}, {"texts": ["The baby is eating food."], "durations": null, "exact_frames_per_prompt": [51], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/22Y6OZHPPV0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 29, "npz_gt_video_start_frame": 29, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 29, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_426_0_1"}, {"texts": ["A woman is talking and applying cream on her face."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2qSRaHtfVfA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_427_0_0"}, {"texts": ["A man is sitting on the chair and picking paper money from the table."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2M_SxI_s3r4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_42_0_0"}, {"texts": ["A man wearing a blue suit is standing on the stage and speaking on the mic."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-toLMKPWM8k.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_430_0_0"}, {"texts": ["A person whose hand is visible only, is lifting some meat and putting it\ninto the meat mincer machine."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/6nuOApf8XM8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_433_0_0"}, {"texts": ["A person wearing a black t-shirt is opening the artificial flower leaves."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-S4jWwhMpwY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_435_0_0"}, {"texts": ["A person whose hand is visible is holding a stick and a tong and setting the kebab on the stick."], "durations": null, "exact_frames_per_prompt": [68], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-3usVvvMGSY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 12, "npz_gt_video_start_frame": 12, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 12, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_436_0_0"}, {"texts": ["A man wearing black cloth is standing near the woman a man with a blue t-shirt is moving backward from barbecue tray"], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0FYtENQd_DU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_445_1_ms_0"}, {"texts": ["A man wearing a brown cloth is standing and laughing a man wearing blue clothes is standing on the left side."], "durations": null, "exact_frames_per_prompt": [42], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0FYtENQd_DU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 7, "npz_gt_video_start_frame": 7, "npz_gt_video_end_frame": 49, "skip_frames_after_generation": 7, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_445_2_ms_0"}, {"texts": ["A man wearing blue clothes is standing near the second man."], "durations": null, "exact_frames_per_prompt": [38], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0FYtENQd_DU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 42, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_445_3_ms_0"}, {"texts": ["A girl wearing a white-black printed top standing on the left side is holding a glass bottle on the white table and is trying to open it with the help of scissors a girl wearing a blue dress bends down and picks the glasses from the floor."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/rno1OddKJfw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_44_0_0"}, {"texts": ["A girl is wearing a blue top standing while another girl is leaning on the counter top while opening a bottle"], "durations": null, "exact_frames_per_prompt": [48], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/rno1OddKJfw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 52, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_44_1_0"}, {"texts": ["The girl is laying down and picking up a red disposable glass."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/rno1OddKJfw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 52, "npz_gt_video_start_frame": 52, "npz_gt_video_end_frame": 69, "skip_frames_after_generation": 52, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_44_1_1"}, {"texts": ["The girl is placing it on the table."], "durations": null, "exact_frames_per_prompt": [11], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/rno1OddKJfw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 69, "npz_gt_video_start_frame": 69, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 69, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_44_1_2"}, {"texts": ["A baby wearing a red t-shirt is laughing, sitting on the baby's high chair, and watching the dog a woman is throwing up something and the dog tries to catch it and the woman is laughing."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1wQX9m-gEi4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_453_0_0"}, {"texts": ["A woman wearing a red t-shirt is sitting, breaking a slice of food and giving it to a dog a baby wearing a red t-shirt is laughing by looking at the dog."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1wQX9m-gEi4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_453_1_0"}, {"texts": ["A baby wearing red cloth is sitting on a baby chair and laughing while a woman is feeding her and a brown dog"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1wQX9m-gEi4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_454_0_0"}, {"texts": ["A brown dog is sitting and jumping a baby wearing a red t-shirt is laughing by looking at the dog."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1wQX9m-gEi4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_454_2_0"}, {"texts": ["A baby lying in the baby stroller is being fed by a person."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3sSxqG80obE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_45_0_0"}, {"texts": ["A person whose hand is visible is feeding the baby with a green spoon."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3sSxqG80obE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_45_1_0"}, {"texts": ["A girl whose half body is visible wearing a gray t-shirt is eating a burger."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3GD4LE_FTDs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_460_0_0"}, {"texts": ["A girl wearing a gray t-shirt is sitting and eating a burger and then taking a bite of it."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3GD4LE_FTDs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_461_0_0"}, {"texts": ["A girl wearing gray clothes is holding some food in her hand and eating."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3GD4LE_FTDs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_462_0_0"}, {"texts": ["A man wearing a light-yellow t-shirt is sitting and floating on the left side while A man wearing a brown t-shirt is standing on the backside, holding a white glove and speaking on the microphone.while a man wearing a blue t-shirt is sitting and floating on the right side and the man with the black t-shirt is floating up and down"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0hiu7IaIWds.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_463_1_0"}, {"texts": ["A man wearing a brown t-shirt is standing on the backside, holding a white glove and speaking on the microphone a man wearing a light-yellow t-shirt is sitting and floating on the left side and man wearing a blue t-shirt is sitting and floating on the right side and the man black t-shirt is floating ups and down"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0hiu7IaIWds.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_463_2_0"}, {"texts": ["A woman wearing a black t-shirt is hanging upside down on a metal bar while a man wearing a brown t-shirt is speaking and other people are smiling"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0hiu7IaIWds.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_463_3_0"}, {"texts": ["A man wearing a yellow shirt is standing on a boat holding a fishing net stick while a man with a light blue shirt is fishing"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-B9gY3HccMk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_465_0_0"}, {"texts": ["A man wearing a white shirt stands with a fishing rod and is fishing while a man in a yellow shirt is holding a fishing net and standing beside"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-B9gY3HccMk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_465_1_0"}, {"texts": ["A girl sitting on a baby chair is rubbing her lips."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-4CxOUPL6o4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 26, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_468_0_0"}, {"texts": ["The girl starts eating noodles with a pink spoon from a bowl."], "durations": null, "exact_frames_per_prompt": [54], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-4CxOUPL6o4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 26, "npz_gt_video_start_frame": 26, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 26, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_468_0_1"}, {"texts": ["A girl is sitting on a baby's chair while holding a pink spoon in her hand."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-4CxOUPL6o4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 31, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_469_0_0"}, {"texts": ["The girl is eating noodles from a bowl."], "durations": null, "exact_frames_per_prompt": [49], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-4CxOUPL6o4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 31, "npz_gt_video_start_frame": 31, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 31, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_469_0_1"}, {"texts": ["A man wearing a red t-shirt picks up the golf ball tee and walks towards the right of the green field while the other people standing on the green surface moved backward."], "durations": null, "exact_frames_per_prompt": [55], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0eFgAUfHsEk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 59, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_470_0_0"}, {"texts": ["The man is standing on the green field and is about to hit the golf ball with a golf stick while the man in white shirt keeps some black object in his pocket"], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0eFgAUfHsEk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 59, "npz_gt_video_start_frame": 59, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 59, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_470_0_1"}, {"texts": ["A man wearing a white cap is standing while the man wearing a red t-shirt bends down and taking something from the ground"], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0eFgAUfHsEk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 23, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_470_1_0"}, {"texts": ["The man wearing a white cap is moving on the green field and is looking at person one while the man wearing a red t-shirt starts walking towards the right side"], "durations": null, "exact_frames_per_prompt": [57], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0eFgAUfHsEk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 23, "npz_gt_video_start_frame": 23, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 23, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_470_1_1"}, {"texts": ["A man whose upper body is visible wearing a blue t-shirt, black goggles, and a helmet is looking in the front and is horse riding on the brown hill path."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2OKtc3Gl-As.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_472_0_0"}, {"texts": ["A brown horse whose ears are visible is walking on the brown hill path."], "durations": null, "exact_frames_per_prompt": [44], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2OKtc3Gl-As.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 36, "npz_gt_video_start_frame": 36, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 36, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_472_1_0"}, {"texts": ["A person whose hands are visible is holding a metal plate. "], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-i7P7G7ChAc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_473_0_0"}, {"texts": ["The person puts the metal plate away."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-i7P7G7ChAc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 40, "npz_gt_video_start_frame": 40, "npz_gt_video_end_frame": 49, "skip_frames_after_generation": 40, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_473_0_1"}, {"texts": ["The person lifts the wires."], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-i7P7G7ChAc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 49, "npz_gt_video_start_frame": 49, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 49, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_473_0_2"}, {"texts": ["A person whose hands are visible is holding some electrical equipment and showing it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-i7P7G7ChAc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_474_0_0"}, {"texts": ["A man wearing black clothes is standing on the left side and tying the bow tie second man standing beside the black shirt is also tying the bow tie"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/8GVXmKtJp9U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_475_0_0"}, {"texts": ["A man wearing a black shirt standing on the right side is moving his hands while the other man who's wearing a neck band is laughing and saying something"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/8GVXmKtJp9U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_475_1_0"}, {"texts": ["A man wearing a checkered shirt is sitting."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/7mEi5joUf0w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_491_0_0"}, {"texts": ["The man picks up a newspaper."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/7mEi5joUf0w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 40, "npz_gt_video_start_frame": 40, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 40, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_491_0_1"}, {"texts": ["A group of people is standing and holding red glasses."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2G1zKFTA8m4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 24, "npz_gt_video_start_frame": 24, "npz_gt_video_end_frame": 59, "skip_frames_after_generation": 24, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_498_1_ms_0"}, {"texts": ["A person whose hands are visible is shaking a sushi roll in a shake mold machine."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3Or9260xH8A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_49_0_0"}, {"texts": ["A girl wearing white printed top is sitting, speaking."], "durations": null, "exact_frames_per_prompt": [44], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1_OOsNcx5tQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 48, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_4_0_0"}, {"texts": ["The girl starts licking her hand."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1_OOsNcx5tQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 48, "npz_gt_video_start_frame": 48, "npz_gt_video_end_frame": 75, "skip_frames_after_generation": 48, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_4_0_1"}, {"texts": ["A girl wearing white clothes is sitting on a brown chair and is peeling an apple using a green peeler while a girl wearing a pink t-shirt is standing and helps person one in peeling the apple."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3I8zuOPeod4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_500_0_0"}, {"texts": ["A girl wearing pink clothes is standing wile girl wearing white t-shirt is sitting on a brown chair and is peeling an apple using a green peeler."], "durations": null, "exact_frames_per_prompt": [58], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3I8zuOPeod4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 62, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_500_1_0"}, {"texts": ["The girl helps person one in peeling the apple."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3I8zuOPeod4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 62, "npz_gt_video_start_frame": 62, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 62, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_500_1_1"}, {"texts": ["A man wearing a denim shirt is holding the peeler while the kids are rotating the peeler"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3I8zuOPeod4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_500_2_0"}, {"texts": ["A man is wearing black clothes is sitting and holding a baby in his lap while the woman in red t-shirt takes toys from bag and shows to the baby"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-coRoBr2_cI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_503_0_0"}, {"texts": ["A woman wearing red clothes is taking a toy from a box baby trying to eat paper"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-coRoBr2_cI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_503_2_0"}, {"texts": ["A baby boy wearing a designer t-shirt is standing on a chair and cutting a watermelon slice into small pieces with a knife on the table."], "durations": null, "exact_frames_per_prompt": [51], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/Ae08WvfTcF0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 55, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_505_0_0"}, {"texts": ["The baby boy wearing a designer t-shirt starts screaming."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/Ae08WvfTcF0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 55, "npz_gt_video_start_frame": 55, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 55, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_505_0_1"}, {"texts": ["A person whose hands are only visible is making a knot from a green plastic thread."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0d7WFfVA7TA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_507_0_0"}, {"texts": ["A man wearing a black t-shirt is standing on a black carpet and juggling with glass bottles while the other man has a white cloth on the shoulder picking up the bottles."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4hQSTJYwHno.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_511_0_0"}, {"texts": ["A man on the left side wearing a black t-shirt is sitting on the grey surface while the man in a black t-shirt is playing with the bottles."], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4hQSTJYwHno.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 41, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_511_1_0"}, {"texts": ["The man moves forward to pick up the glass bottle as the man in black t-shirt takes the glass from the table"], "durations": null, "exact_frames_per_prompt": [39], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4hQSTJYwHno.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 41, "npz_gt_video_start_frame": 41, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 41, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_511_1_1"}, {"texts": ["A man wearing a black t-shirt and blue jeans is standing, starts flair bartending a man sitting down enjoy that movement"], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4hQSTJYwHno.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 30, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_512_0_0"}, {"texts": ["The man drops a glass another man trying to move forward"], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4hQSTJYwHno.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 30, "npz_gt_video_start_frame": 30, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 30, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_512_0_1"}, {"texts": ["The man lifts another glass other man searching for something on the floor"], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4hQSTJYwHno.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 50, "npz_gt_video_start_frame": 50, "npz_gt_video_end_frame": 63, "skip_frames_after_generation": 50, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_512_0_2"}, {"texts": ["The man again starts flair bartending other man move the table right a bit"], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4hQSTJYwHno.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 63, "npz_gt_video_start_frame": 63, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 63, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_512_0_3"}, {"texts": ["A man wearing a black t-shirt and light blue jeans is sitting.  while a man wearing black t-shirt and blue jeans is playing with the bottles"], "durations": null, "exact_frames_per_prompt": [38], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4hQSTJYwHno.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 42, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_512_1_0"}, {"texts": ["The man is moving on the ground on the left side then the man picked up a bottle from the table and rotated it."], "durations": null, "exact_frames_per_prompt": [38], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4hQSTJYwHno.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 42, "npz_gt_video_start_frame": 42, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 42, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_512_1_1"}, {"texts": ["A woman standing in the kitchen is mixing corn, capsicum and onion in a glass bowl."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2lRD0VCqdfE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_516_0_0"}, {"texts": ["A girl wearing a white top is standing on her knees and holding a long piece of paper towards the paper shredder."], "durations": null, "exact_frames_per_prompt": [61], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/6UMI9fX2Iew.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 65, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_519_0_0"}, {"texts": ["The girl moves her hands."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/6UMI9fX2Iew.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 65, "npz_gt_video_start_frame": 65, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 65, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_519_0_1"}, {"texts": ["A man wearing an off white shirt is standing, first inserting a hive."], "durations": null, "exact_frames_per_prompt": [58], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/59J7V_YRBG8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 62, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_525_0_0"}, {"texts": ["The man is lifting the hive from a hive box while holding a metal piece in his hand."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/59J7V_YRBG8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 62, "npz_gt_video_start_frame": 62, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 62, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_525_0_1"}, {"texts": ["A woman wearing a white-black top and a black blazer is sitting on a black chair and speaking while looking in front."], "durations": null, "exact_frames_per_prompt": [34], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-Ikki5WXc20.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 38, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_526_0_ms_0"}, {"texts": ["A person whose hands are visible is using a smartphone."], "durations": null, "exact_frames_per_prompt": [34], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-Ikki5WXc20.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 46, "npz_gt_video_start_frame": 46, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 46, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_526_1_ms_0"}, {"texts": ["A baby wearing white clothes is sitting on the man's lap and drinking from the transparent glass while holding the glass."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2L2yGXV8LLo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_527_0_0"}, {"texts": ["A man wearing a white shirt is holding the baby on his lap and making him drink from the glass."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2L2yGXV8LLo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_527_1_0"}, {"texts": ["A man wearing white cloth is sitting and holding a glass and a baby in his lap and giving a glass to drink water."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2L2yGXV8LLo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_528_0_0"}, {"texts": ["A baby wearing white cloth is sitting in the lap of the man and drinking water."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2L2yGXV8LLo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_528_1_0"}, {"texts": ["A man wearing white red costume is standing and conducting an orchestra."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2NFjzbUfR2k.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_534_0_0"}, {"texts": ["A man wearing a white shirt is standing on a gray floor while the man in blue t-shirt is trimming sheep's wool"], "durations": null, "exact_frames_per_prompt": [66], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0WT9sICw61A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 70, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_535_0_0"}, {"texts": ["The man wearing a white shirt is watching the second person."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0WT9sICw61A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 70, "npz_gt_video_start_frame": 70, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 70, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_535_0_1"}, {"texts": ["A man wearing a blue t-shirt is trimming a sheep's hair with a trimmer."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0WT9sICw61A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_535_1_0"}, {"texts": ["A white sheep is lying on the gray floor and getting hair trimmed by the second person and the man in white shirt is monitoring the task performed by the first person"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0WT9sICw61A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_535_3_0"}, {"texts": ["A man wearing a blue t-shirt is standing, leaning forward, and shaving a sheep."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0WT9sICw61A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_536_0_0"}, {"texts": ["A white sheep lying on the floor is being shaved by the first man."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0WT9sICw61A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_536_1_0"}, {"texts": ["A woman wearing a white t-shirt is peeling the peel of the brown-yellow fruit with her hands."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3GdY3KgWmmE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_539_0_0"}, {"texts": ["A boy wearing a white t-shirt is sitting on the bed."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1Ct5JVPONwY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 19, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_542_0_0"}, {"texts": ["A boy wearing a white t-shirt is reading and flipping the book pages."], "durations": null, "exact_frames_per_prompt": [61], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1Ct5JVPONwY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 19, "npz_gt_video_start_frame": 19, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 19, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_542_0_1"}, {"texts": ["A man wearing black clothes comes and opens the tyre nozzle cap."], "durations": null, "exact_frames_per_prompt": [60], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2g3ViPY2xlg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 64, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_543_0_0"}, {"texts": ["The man wearing black clothes inserts a silver pressure gauge in the nozzle."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2g3ViPY2xlg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 64, "npz_gt_video_start_frame": 64, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 64, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_543_0_1"}, {"texts": ["A woman wearing a black t-shirt standing on the right side is speaking and caressing the dog while the other women is standing on the left side and touching the dogs hair"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-SygWyDFFXQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_544_0_0"}, {"texts": ["A woman wearing a black t-shirt standing on the left side is caressing the dog another women in right side talking about the dog"], "durations": null, "exact_frames_per_prompt": [71], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-SygWyDFFXQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 9, "npz_gt_video_start_frame": 9, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 9, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_544_1_0"}, {"texts": ["A white dog is standing and moving its head.\n as the women in black t-shirt are playing with its fur"], "durations": null, "exact_frames_per_prompt": [67], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-SygWyDFFXQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 13, "npz_gt_video_start_frame": 13, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 13, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_544_3_0"}, {"texts": ["A man wearing a shirt is drinking something from white glass."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/04NyBK_C_h0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_545_0_0"}, {"texts": ["A man wearing a sky blue shirt drinks something from the white cup."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/04NyBK_C_h0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 7, "npz_gt_video_start_frame": 7, "npz_gt_video_end_frame": 24, "skip_frames_after_generation": 7, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_546_0_0"}, {"texts": ["A man wearing a black dress is ice fishing on the snow surface with an ice fishing gear."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/35bIxGrNzok.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_549_0_0"}, {"texts": ["A person wearing black cloth is standing on a white surface and holding a fishing rope and taking out from the water."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/35bIxGrNzok.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_550_0_0"}, {"texts": ["A woman wearing a tan cloth is sitting on the left side while holding a glass of beer while a man wearing a black cloth is sitting in the middle raising his one hand and a man wearing a black shirt is sitting holding a glass of beer and stroking it with the woman's glass."], "durations": null, "exact_frames_per_prompt": [11], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3dDOwh5hj1I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 15, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_552_0_0"}, {"texts": ["The woman is striking with the glass of second man on the right side."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3dDOwh5hj1I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 15, "npz_gt_video_start_frame": 15, "npz_gt_video_end_frame": 25, "skip_frames_after_generation": 15, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_552_0_1"}, {"texts": ["The woman starts drinking while the third person raise an hand of second person as soon as he completely drink the glass of beer."], "durations": null, "exact_frames_per_prompt": [55], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3dDOwh5hj1I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 25, "npz_gt_video_start_frame": 25, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 25, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_552_0_2"}, {"texts": ["A man wearing a black cloth is sitting in the middle, raising his one hand while a woman wearing a tan cloth is sitting on the left side holding a glass of beer and a man wearing a black shirt is sitting, holding a glass of beer and stroking it with the woman's glass."], "durations": null, "exact_frames_per_prompt": [51], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3dDOwh5hj1I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 55, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_552_1_0"}, {"texts": ["The man is holding the hand of the second man and raising it while the woman puts down her glass."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3dDOwh5hj1I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 55, "npz_gt_video_start_frame": 55, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 55, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_552_1_1"}, {"texts": ["A man wearing a black shirt is sitting, holding a glass of beer and stroking it with the woman's glass the man wearing white and black T-shirt is encouraging to drink"], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3dDOwh5hj1I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 22, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_552_2_0"}, {"texts": ["The man wearing a black shirt starts to drink it the woman starts drinking."], "durations": null, "exact_frames_per_prompt": [34], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3dDOwh5hj1I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 22, "npz_gt_video_start_frame": 22, "npz_gt_video_end_frame": 56, "skip_frames_after_generation": 22, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_552_2_1"}, {"texts": ["The man in a black t-shirt raised the hand of the second man the woman finishes the drink and put the glass on the table"], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3dDOwh5hj1I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 56, "npz_gt_video_start_frame": 56, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 56, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_552_2_2"}, {"texts": ["A woman wearing dark blue t-shirt is standing behind the counter-top and chopping the pineapple on the wooden chopping board with the help of knife."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1X_LV5o_krk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_556_0_0"}, {"texts": ["A person whose hand is only visible, is holding a spoon and feeding the food to the baby."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2hJJDGKmJc0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_558_0_0"}, {"texts": ["A baby wearing a white diaper is lying on the blue baby cot."], "durations": null, "exact_frames_per_prompt": [44], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2hJJDGKmJc0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 48, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_558_1_0"}, {"texts": ["The baby wearing a white diaper fed by the person."], "durations": null, "exact_frames_per_prompt": [32], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2hJJDGKmJc0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 48, "npz_gt_video_start_frame": 48, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 48, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_558_1_1"}, {"texts": ["A baby wearing a diaper is lying on a printed baby bed and licking his hands and getting fed by a person with a spoon."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2hJJDGKmJc0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_559_0_0"}, {"texts": ["A woman wearing a black sleeveless jacket is sitting in the front and moving her hand."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-Pc62CZZMlI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_55_0_ms_0"}, {"texts": ["A group of six people, five people are standing around the food counter and one person is taking something from the shelf then starts walking to the left."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-Pc62CZZMlI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 40, "npz_gt_video_start_frame": 40, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 40, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_55_1_ms_0"}, {"texts": ["A kid wearing a yellow t-shirt is standing and rotating the handle of a rotary peeler machine and peeling the potato while the baby in a multi color t-shirt is watching and smiling"], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0T3YtsWWEBM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_565_0_0"}, {"texts": ["A boy wearing a yellow t-shirt is standing and operating a peeling machine baby boy standing beside the first boy shouting with excitement"], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0T3YtsWWEBM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_566_0_0"}, {"texts": ["A boy wearing a lining t-shirt is standing on the right side of the first boy."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0T3YtsWWEBM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_566_1_0"}, {"texts": ["A person whose hand is visible only, wearing a white cloth, is holding the wheel rim and then repeating it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1n1TpFPG7TA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_56_0_0"}, {"texts": ["A baby wearing a blue t-shirt is moving their hands and lying on the black surface girl wearing a orange top trying to stop the baby's crying"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0QQEp8jAnFI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_570_0_0"}, {"texts": ["A girl wearing an orange top is standing while a infant wearing blue colour t -shirt is crying"], "durations": null, "exact_frames_per_prompt": [58], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0QQEp8jAnFI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 62, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_570_1_0"}, {"texts": ["The girl is moving her hand."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0QQEp8jAnFI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 62, "npz_gt_video_start_frame": 62, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 62, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_570_1_1"}, {"texts": ["A man whose only half body is visible is wearing a gray t-shirt standing and taking out green tea from the paper bag with a spoon then putting it into a jar."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/525tFmwP6Ic.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 34, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_571_0_0"}, {"texts": ["The man puts the paper bag aside on the table."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/525tFmwP6Ic.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 34, "npz_gt_video_start_frame": 34, "npz_gt_video_end_frame": 47, "skip_frames_after_generation": 34, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_571_0_1"}, {"texts": ["The man is placing his hands on the table."], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/525tFmwP6Ic.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 47, "npz_gt_video_start_frame": 47, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 47, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_571_0_2"}, {"texts": ["A person whose only hands are visible is folding a yellow paper with their hands."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-orvHtyWiEU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_573_0_0"}, {"texts": ["A man is wearing white cloth sitting on a chair and eating bread."], "durations": null, "exact_frames_per_prompt": [57], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3jKFKV7kQ6E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 61, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_574_0_0"}, {"texts": ["A person wearing blue jeans and black gloves is holding a shearing machine and doing sheep shearing."], "durations": null, "exact_frames_per_prompt": [42], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-BagREykXFM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 8, "npz_gt_video_start_frame": 8, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 8, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_575_3_ms_0"}, {"texts": ["Another person wearing blue trousers is holding a sheep between his legs."], "durations": null, "exact_frames_per_prompt": [42], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-BagREykXFM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 8, "npz_gt_video_start_frame": 8, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 8, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_575_5_ms_0"}, {"texts": ["A sheep is lying on the wooden surface and being sheared by the person wearing black gloves."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-BagREykXFM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 8, "npz_gt_video_start_frame": 8, "npz_gt_video_end_frame": 49, "skip_frames_after_generation": 8, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_575_6_0"}, {"texts": ["A person whose hand is visible is holding a bike tyre."], "durations": null, "exact_frames_per_prompt": [67], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1n1TpFPG7TA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 71, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_57_0_0"}, {"texts": ["The person whose hand is visible is rotating the bike tyre."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1n1TpFPG7TA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 71, "npz_gt_video_start_frame": 71, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 71, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_57_0_1"}, {"texts": ["A man is standing and holding a juicer and grinding meat in it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/6SU1P-ehJYU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_582_0_0"}, {"texts": ["A big boy whose head is visible wearing a black jacket and specs, is showing the sweets in the spoon while holding a spoon in his right hand."], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1pd9-tf17NE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 35, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_585_0_0"}, {"texts": ["And then starts eating the sweets."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1pd9-tf17NE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 35, "npz_gt_video_start_frame": 35, "npz_gt_video_end_frame": 56, "skip_frames_after_generation": 35, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_585_0_1"}, {"texts": ["A man wearing a green t-shirt and gray jeans is walking while pointing his hands towards the second man the two person wearing a black t-shirts are speaking in a mic"], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-2jqFdD__ag.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 15, "npz_gt_video_start_frame": 15, "npz_gt_video_end_frame": 52, "skip_frames_after_generation": 15, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_588_0_0"}, {"texts": ["The man is speaking while a man wearing a red jacket went forward and turned around"], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-2jqFdD__ag.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 52, "npz_gt_video_start_frame": 52, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 52, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_588_0_1"}, {"texts": ["A man wearing a black cloth, is standing and speaking on the mic while holding a mic."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-2jqFdD__ag.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 13, "npz_gt_video_start_frame": 13, "npz_gt_video_end_frame": 48, "skip_frames_after_generation": 13, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_588_2_0"}, {"texts": ["The man starts clapping hands."], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-2jqFdD__ag.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 48, "npz_gt_video_start_frame": 48, "npz_gt_video_end_frame": 79, "skip_frames_after_generation": 48, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_588_2_1"}, {"texts": ["A person whose hand is visible is plucking a green fruit from a tree."], "durations": null, "exact_frames_per_prompt": [49], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-tajNaB6B7Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 31, "npz_gt_video_start_frame": 31, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 31, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_590_1_ms_0"}, {"texts": ["A person on the left side whose hand is only visible is stroking his hand on a brown sea lion."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1bsRsgz_3zk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_592_0_0"}, {"texts": ["A person on the right side whose hand is only visible is stroking his hand on a brown sea lion."], "durations": null, "exact_frames_per_prompt": [58], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1bsRsgz_3zk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 22, "npz_gt_video_start_frame": 22, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 22, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_592_1_0"}, {"texts": ["A brown sea lion is lying on a blue deck while a person on the right side whose hand is only visible is stroking his hand on a brown sea lion."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1bsRsgz_3zk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_592_2_0"}, {"texts": ["A person whose hand is visible is pouring food into the yellow liquid."], "durations": null, "exact_frames_per_prompt": [58], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3MOfpmr7L8M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 62, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_593_0_0"}, {"texts": ["The person is then picking food with a fork."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3MOfpmr7L8M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 62, "npz_gt_video_start_frame": 62, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 62, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_593_0_1"}, {"texts": ["A girl whose only hands are visible is breaking an egg and putting egg yolk into a mixing jar."], "durations": null, "exact_frames_per_prompt": [45], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1u1rHQL28Ao.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 49, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_595_0_0"}, {"texts": ["A woman wearing a white coat and a yellow dress is standing putting a pink folded cloth on the table."], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/19i7oyiKVG0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 37, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_59_0_0"}, {"texts": ["The woman is moving her hands, and showing the cloth basket."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/19i7oyiKVG0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 37, "npz_gt_video_start_frame": 37, "npz_gt_video_end_frame": 61, "skip_frames_after_generation": 37, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_59_0_1"}, {"texts": ["A kid wearing a red t-shirt and blue jeans is sitting and holding a snake a person's whose hand is only visibling is trying to touch the snake"], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5mGZ_3kHcd0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_602_0_0"}, {"texts": ["The snake is then getting snatched by a person."], "durations": null, "exact_frames_per_prompt": [33], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5mGZ_3kHcd0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 44, "npz_gt_video_start_frame": 44, "npz_gt_video_end_frame": 77, "skip_frames_after_generation": 44, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_602_0_1"}, {"texts": ["A kid wearing a white shirt and cream pants is sitting on the right side of the first kid and touching the snake a kid in red t-shirt holding the snake"], "durations": null, "exact_frames_per_prompt": [59], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5mGZ_3kHcd0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 63, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_602_1_0"}, {"texts": ["A person wearing blue jeans is standing on the left side of the second kid while a boy wearing a red t-shirt holding a yellow-black snake"], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5mGZ_3kHcd0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_602_3_0"}, {"texts": ["The person starts snatching the snake from the first kid."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5mGZ_3kHcd0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 50, "npz_gt_video_start_frame": 50, "npz_gt_video_end_frame": 77, "skip_frames_after_generation": 50, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_602_3_1"}, {"texts": ["A yellow-black snake is getting held by a kid and the kid sitting beside the first kid is touching the snake while a person wearing blue jeans takes off the snake from the first kid."], "durations": null, "exact_frames_per_prompt": [61], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5mGZ_3kHcd0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 65, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_602_4_0"}, {"texts": ["A woman whose hands are visible is mixing her food with a grey spoon."], "durations": null, "exact_frames_per_prompt": [44], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1q6GwJ7ZxIs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 48, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_604_0_0"}, {"texts": ["The woman picking up a glass bowl filled with black wooden beads."], "durations": null, "exact_frames_per_prompt": [32], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1q6GwJ7ZxIs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 48, "npz_gt_video_start_frame": 48, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 48, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_604_0_1"}, {"texts": ["A man wearing a black t-shirt is standing on the right side of the stove."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2_mqSmwUUik.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 19, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_606_0_0"}, {"texts": ["The man is inserting eggs into a wok on the white stove."], "durations": null, "exact_frames_per_prompt": [61], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2_mqSmwUUik.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 19, "npz_gt_video_start_frame": 19, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 19, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_606_0_1"}, {"texts": ["A girl wearing a pink top is looking and pointing her hand towards the fishes."], "durations": null, "exact_frames_per_prompt": [65], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0bpbDvTs4is.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 69, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_607_1_0"}, {"texts": ["A man wearing beige color trousers is standing, speaking, holding a golf club stick and teaching golf."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0zTnlcsbP-M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_609_0_0"}, {"texts": ["A woman wearing a brown top and blue jeans is standing and feeding the birds."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0EXMXaj77A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_60_0_0"}, {"texts": ["A woman wearing a sweater and trousers is standing on the left and holding things while a man is laughing"], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1yNF2AahQEg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 19, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_610_0_ms_0"}, {"texts": ["A man wearing a suit is standing on the right and smiling while the woman is holding some packages in both the hands."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1yNF2AahQEg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 18, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_610_1_ms_0"}, {"texts": ["A man wearing a black suit is sitting in a chair."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1yNF2AahQEg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 20, "npz_gt_video_start_frame": 20, "npz_gt_video_end_frame": 48, "skip_frames_after_generation": 20, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_610_2_ms_0"}, {"texts": ["The man raises his hand.\n"], "durations": null, "exact_frames_per_prompt": [5], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1yNF2AahQEg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 48, "npz_gt_video_start_frame": 48, "npz_gt_video_end_frame": 53, "skip_frames_after_generation": 48, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_610_2_ms_1"}, {"texts": ["The man puts it down."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1yNF2AahQEg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 53, "npz_gt_video_start_frame": 53, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 53, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_610_2_ms_2"}, {"texts": ["A person whose legs are visible is lying on a white bed and getting a tattoo on the left foot."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/19Cl27Wpf4I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_611_0_0"}, {"texts": ["A man wearing a black t-shirt is standing and making a tattoo on the first person's left foot with a tattoo machine."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/19Cl27Wpf4I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_611_1_0"}, {"texts": ["A man wearing a black shirt is sitting and making a tattoo on the leg of a woman with a tattoo machine and wiping with the tissue paper."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/19Cl27Wpf4I.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_612_0_0"}, {"texts": ["A person whose hand is visible is writing on a wall."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1fNnSAka2Ec.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_616_0_0"}, {"texts": ["A girl wearing a white pink dress is standing holding a white cup and feeding a green parakeet."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0nYkK11fDZk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_618_0_0"}, {"texts": ["A green parakeet is eating from a white cup while girl wearing pink dotted frock feeding the bird"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0nYkK11fDZk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_618_1_0"}, {"texts": ["A woman wearing green-blue clothes is standing and holding cups and feeding the birds."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-0EXMXaj77A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_61_0_0"}, {"texts": ["A girl on the right side is sitting in front of a yellow cabinet facing left with the other two girls"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1MvYfgPOAzI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_622_0_0"}, {"texts": ["A girl on the left side wearing a blue top and spectacles is sitting in front of a yellow cabinet while a girl is reading and sitting in between the first and the second girl."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1MvYfgPOAzI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_622_1_0"}, {"texts": ["A girl is reading and sitting in between the first and the second girl while the two girls were watching the middle girl's actions."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1MvYfgPOAzI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_622_2_0"}, {"texts": ["A woman whose only eye and head is visible is brushing her eyebrow with a makeup brush."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-nLtSqMcmvo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_624_0_0"}, {"texts": ["A girl wearing a blue white top is sitting and holding an ice cream cone in her left hand."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/07KR3jta1Uo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_627_0_0"}, {"texts": ["A woman wearing a blue shirt is standing on white floor."], "durations": null, "exact_frames_per_prompt": [8], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2mzLvIuhIUE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 12, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_628_0_0"}, {"texts": ["The woman picks up her food from a silver tray."], "durations": null, "exact_frames_per_prompt": [34], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2mzLvIuhIUE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 12, "npz_gt_video_start_frame": 12, "npz_gt_video_end_frame": 46, "skip_frames_after_generation": 12, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_628_0_1"}, {"texts": ["The woman puts it into a black pan."], "durations": null, "exact_frames_per_prompt": [34], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2mzLvIuhIUE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 46, "npz_gt_video_start_frame": 46, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 46, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_628_0_2"}, {"texts": ["A man wearing blue cloth is sitting and speaking and moving his hand."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/6GQQo-Zw2hw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_631_0_0"}, {"texts": ["A man wearing a dark blue vest is standing and tying a boxing hand wrap round his hand."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-oww2bPbZIE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_632_0_0"}, {"texts": ["A man wearing a black suit is walking on the right side, holding a remote and moving his hands."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/05MI7UlnY4A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_635_0_0"}, {"texts": ["A man wearing a black t-shirt is sitting and speaking a women in black glasses is moving her hand and saying something"], "durations": null, "exact_frames_per_prompt": [54], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1zNdXTAHOzE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_637_0_0"}, {"texts": ["A woman wearing specs is also speaking."], "durations": null, "exact_frames_per_prompt": [45], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1zNdXTAHOzE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 13, "npz_gt_video_start_frame": 13, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 13, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_637_1_0"}, {"texts": ["A man wearing a black shirt is putting butter into the pan."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1HYTGM88W3o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_639_0_0"}, {"texts": ["The man is tossing the pan, while the food is being cooked."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1HYTGM88W3o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 44, "npz_gt_video_start_frame": 44, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 44, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_639_0_1"}, {"texts": ["A woman wearing a blue vest is sitting, talking, chewing something, and eating chips."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2eWnvXJWT_4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_63_0_0"}, {"texts": ["A man wearing a black shirt is opening a butter packet."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1HYTGM88W3o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 23, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_640_0_0"}, {"texts": ["The man is putting butter in the pan."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1HYTGM88W3o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 23, "npz_gt_video_start_frame": 23, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 23, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_640_0_1"}, {"texts": ["The man is tossing the pan."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1HYTGM88W3o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 45, "npz_gt_video_start_frame": 45, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 45, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_640_0_2"}, {"texts": ["A woman whose upper body is visible wearing a brown woolen sweater is standing and is visible in the mirror and is holding a mobile phone and recording the boy on a mobile phone camera."], "durations": null, "exact_frames_per_prompt": [57], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4u_u3VPnGDM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 61, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_642_0_0"}, {"texts": ["A boy whose upper body is visible, wearing a purple jacket, is applying the face cream to his cheek with his finger and smiling while a woman is recording in the mobile phone, which is reflecting in a mirror"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4u_u3VPnGDM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_642_1_0"}, {"texts": ["A woman wearing a white top is standing."], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-LxaYFnEu2U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 35, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_646_0_0"}, {"texts": ["The woman is trying to flip the food in the black pan."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-LxaYFnEu2U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 35, "npz_gt_video_start_frame": 35, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 35, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_646_0_1"}, {"texts": ["A girl wearing a white top is standing on a tile floor while holding a pan with some stuff in it."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-LxaYFnEu2U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 33, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_647_0_0"}, {"texts": ["The girl is tossing the stuff in the pan and then starts laughing."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-LxaYFnEu2U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 33, "npz_gt_video_start_frame": 33, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 33, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_647_0_1"}, {"texts": ["A man wearing a navy blue jacket and brown pants is standing and speaking while holding a coin."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/30FW-Um5sSk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 21, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_654_0_0"}, {"texts": ["The man is sitting on the right side of the car."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/30FW-Um5sSk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 21, "npz_gt_video_start_frame": 21, "npz_gt_video_end_frame": 56, "skip_frames_after_generation": 21, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_654_0_1"}, {"texts": ["The man is placing the coin in between the tire tread."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/30FW-Um5sSk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 56, "npz_gt_video_start_frame": 56, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 56, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_654_0_2"}, {"texts": ["A woman wearing a graphic black sweatshirt is dancing while lip-syncing."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2L4l0WoTntQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_655_0_0"}, {"texts": ["A girl wearing a blue cloth is walking and touching the goat inside the mesh wire cage while a small black goat is running away from the girl."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0_4zOwgabn4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_656_0_0"}, {"texts": ["A brown baby goat is standing while a baby wearing a blue t-shirt is playing with the goats."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0_4zOwgabn4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 27, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_656_1_0"}, {"texts": ["The brown baby goat starts walking on the green grass surface inside the mesh wire cage while the baby falls down"], "durations": null, "exact_frames_per_prompt": [53], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0_4zOwgabn4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 27, "npz_gt_video_start_frame": 27, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 27, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_656_1_1"}, {"texts": ["A man wearing blue clothes is pulling the thread out of the hole on the snowy surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2eeQoqp7YWw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_657_0_0"}, {"texts": ["A man is sitting on the right side of another man."], "durations": null, "exact_frames_per_prompt": [11], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-1z6wTJmBIU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 15, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_662_0_0"}, {"texts": ["The man is eating a burger man beside first man is also eating burger and talking something with the first man"], "durations": null, "exact_frames_per_prompt": [65], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-1z6wTJmBIU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 15, "npz_gt_video_start_frame": 15, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 15, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_662_0_1"}, {"texts": ["A man wearing a black shirt is sitting on the left side of the first man while the man wearing blue-shirt is eating the burger"], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-1z6wTJmBIU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 27, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_662_1_0"}, {"texts": ["The man is wiping his mouth with a tissue paper."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-1z6wTJmBIU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 27, "npz_gt_video_start_frame": 27, "npz_gt_video_end_frame": 56, "skip_frames_after_generation": 27, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_662_1_1"}, {"texts": ["The man is holding a burger in his hand."], "durations": null, "exact_frames_per_prompt": [23], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-1z6wTJmBIU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 56, "npz_gt_video_start_frame": 56, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 56, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_662_1_2"}, {"texts": ["A man wearing a blue shirt is adjusting his bow tie."], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/8cDQ_8nLMPU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 41, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_670_0_0"}, {"texts": ["A person whose hand is visible, is putting a paper in a shredding machine and shredding it."], "durations": null, "exact_frames_per_prompt": [42], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5F01Ci5yMLQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 17, "npz_gt_video_start_frame": 17, "npz_gt_video_end_frame": 59, "skip_frames_after_generation": 17, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_671_0_0"}, {"texts": ["A person whose only a hand is visible is holding a brush and brushing the back and the tail of a horse."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2P3foaIntm8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_675_0_0"}, {"texts": ["A white horse is getting its back and tail brushed by a person."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2P3foaIntm8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_675_1_0"}, {"texts": ["A man wearing a white t-shirt and black pants is standing on the gray surface and holding a black snake."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3x-E0J1yjX4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_680_0_0"}, {"texts": ["A black snake is getting caught by a man."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3x-E0J1yjX4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_680_1_0"}, {"texts": ["A man wearing a white t-shirt is standing on the gray surface and holding a snake in his hands."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3x-E0J1yjX4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_681_0_0"}, {"texts": ["A snake is being held by a man."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3x-E0J1yjX4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_681_1_0"}, {"texts": ["A boy whose upper half-body is visible, wearing a black vest is sitting on a chair on the left side and eating the brown food while a girl whose upper half-body is visible, wearing a blue top is standing on the right side, putting something in her mouth and starts walking towards the right."], "durations": null, "exact_frames_per_prompt": [56], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2F4jKXQDFtk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 60, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_684_0_0"}, {"texts": ["A girl whose upper half-body is visible, wearing a blue top is standing on the right side, putting something in her mouth and eating while a boy whose upper half-body is visible wearing a black vest is sitting on a chair on the left side and eating the brown food."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2F4jKXQDFtk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 39, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_684_1_0"}, {"texts": ["The girl starts walking towards the right."], "durations": null, "exact_frames_per_prompt": [8], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2F4jKXQDFtk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 39, "npz_gt_video_start_frame": 39, "npz_gt_video_end_frame": 47, "skip_frames_after_generation": 39, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_684_1_1"}, {"texts": ["A man wearing a blue t-shirt, black shorts, and a cap is climbing on an apple tree."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-nvFKzOKsxs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 34, "npz_gt_video_start_frame": 34, "npz_gt_video_end_frame": 60, "skip_frames_after_generation": 34, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_687_1_0"}, {"texts": ["The man is plucking the green apples with his hands."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-nvFKzOKsxs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 60, "npz_gt_video_start_frame": 60, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 60, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_687_1_1"}, {"texts": ["A woman wearing a royal blue dress and a black blazer is standing on the right side of the screen and forecasting the weather report on the screen."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0DpD7CHbhrw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 21, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_688_0_0"}, {"texts": ["The woman is turning and going backward while speaking."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0DpD7CHbhrw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 21, "npz_gt_video_start_frame": 21, "npz_gt_video_end_frame": 36, "skip_frames_after_generation": 21, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_688_0_1"}, {"texts": ["A woman wearing a blue dress is standing, holding something in her hand"], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0DpD7CHbhrw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 26, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_689_0_0"}, {"texts": ["A woman wearing a blue dress starts walking toward the right."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0DpD7CHbhrw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 26, "npz_gt_video_start_frame": 26, "npz_gt_video_end_frame": 35, "skip_frames_after_generation": 26, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_689_0_1"}, {"texts": ["A girl wearing a red t-shirt is standing and holding a peeled potato, then holding a grey bucket and speaking while the man on right with red jacket and green t-shirt is holding a drilling machine"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0VtQ4hcBhpU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_68_0_0"}, {"texts": ["A man wearing a black t-shirt is playing golf on a\n golf course and is giving a high-five."], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0MgG4dV56Ik.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 41, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_695_0_0"}, {"texts": ["A baby wearing a purple hair band is eating a colorful cake while sitting on a printed brown baby chair."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4mnnAWp42cg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_704_0_0"}, {"texts": ["A person on the left side wearing a blue t-shirt is holding the cake in her hand in front of the first baby while the baby is eating the cake."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4mnnAWp42cg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_704_3_0"}, {"texts": ["A child wearing a blue hoodie is sitting on the floor."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1exarhq0Tlg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 21, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_705_0_0"}, {"texts": ["The child is tearing gift wrap from a box."], "durations": null, "exact_frames_per_prompt": [59], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1exarhq0Tlg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 21, "npz_gt_video_start_frame": 21, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 21, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_705_0_1"}, {"texts": ["A man wearing a pink t-shirt is standing and is eating food and also a man wearing blue t-shirt on the right side eating food"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2S5DMUMvkyw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_706_0_0"}, {"texts": ["A man wearing a pink t-shirt is standing and eating a hot dog, in a competition with the first man."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2S5DMUMvkyw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_707_1_0"}, {"texts": ["A man wearing a black shirt, black pants, and black shoes is sitting on the camel's back while holding a rope with his left hand and a man with a blue shirt is walking along with the camel"], "durations": null, "exact_frames_per_prompt": [42], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/19DdD2JaU-Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 46, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_708_0_0"}, {"texts": ["A camel is standing on the soil surface while carrying the first man on his back while a man wearing black jacket sitting on the camel and saying something"], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/19DdD2JaU-Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 6, "npz_gt_video_start_frame": 6, "npz_gt_video_end_frame": 46, "skip_frames_after_generation": 6, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_708_2_0"}, {"texts": ["A big boy wearing a gray t-shirt and dark blue shorts is sitting while the girls wearing black t-shirts sitting on the floor and trying to eat doughnuts."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3S4RfsZcmGM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 14, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_709_2_0"}, {"texts": ["The big boy wearing a gray t-shirt and dark blue shorts is standing while holding donuts in his right hand while all the others are trying to catch the doughnuts with their mouth."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3S4RfsZcmGM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 14, "npz_gt_video_start_frame": 14, "npz_gt_video_end_frame": 32, "skip_frames_after_generation": 14, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_709_2_1"}, {"texts": ["The big boy wearing a gray t-shirt and dark blue shorts walks on the gay surface while a girl wearing black and brown t-shirt catches a doughnut and eats"], "durations": null, "exact_frames_per_prompt": [48], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3S4RfsZcmGM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 32, "npz_gt_video_start_frame": 32, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 32, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_709_2_2"}, {"texts": ["A horse is walking from left to right behind the person."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0e2OdCAOwe8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 32, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_711_1_0"}, {"texts": ["A person whose only a hand is visible is turning the page of a book."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1BTY5leiQFY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_722_0_0"}, {"texts": ["A person whose hand is visible is writing on a white paper with a yellow pencil."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2bGbK9LY3Jw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_724_0_0"}, {"texts": ["A baby wearing a graphic black dress is sitting on the gray surface and eating food."], "durations": null, "exact_frames_per_prompt": [68], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0qLW6rdj_Fk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 72, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_726_0_0"}, {"texts": ["A man wearing a green sweatshirt is sitting and eating food."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1gS5Udgciy0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_727_0_0"}, {"texts": ["A woman wearing a bracelet is getting a tattoo on her wrist and a woman wearing a red t-shirt is holding the bracelet hand"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-36nz7JP2Ac.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_729_0_0"}, {"texts": ["A person wearing black gloves is tattooing a woman's wrist."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-36nz7JP2Ac.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_729_1_0"}, {"texts": ["A man wearing a gray-black t-shirt and a red-white apron is standing in the kitchen and giving instructions to the kid."], "durations": null, "exact_frames_per_prompt": [47], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-GKnuhPmiwM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 51, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_72_0_0"}, {"texts": ["A kid wearing a black t-shirt and a red-white apron is standing near the kitchen counter, holding a wooden rolling pin and rolling the dough and a man is guiding the kid holding a wooden rolling pin and rolling the dough"], "durations": null, "exact_frames_per_prompt": [47], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-GKnuhPmiwM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 51, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_72_1_0"}, {"texts": ["A man wearing black clothes is standing and holding a golf stick."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/06rZT_6Rc5Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 14, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_731_0_0"}, {"texts": ["The man is hitting a ball with his golf stick."], "durations": null, "exact_frames_per_prompt": [44], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/06rZT_6Rc5Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 14, "npz_gt_video_start_frame": 14, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 14, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_731_0_1"}, {"texts": ["The man is arranging the ball platform."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/06rZT_6Rc5Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 58, "npz_gt_video_start_frame": 58, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 58, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_731_0_2"}, {"texts": ["A person whose legs are visible is standing and playing golf."], "durations": null, "exact_frames_per_prompt": [52], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/06rZT_6Rc5Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 56, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_732_0_0"}, {"texts": ["The person is using a line putting mirror."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/06rZT_6Rc5Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 56, "npz_gt_video_start_frame": 56, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 56, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_732_0_1"}, {"texts": ["A man wearing cap whose reflection is visible in the golf line putting mirror is putting white object into the small mirror holes."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/06rZT_6Rc5Q.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 58, "npz_gt_video_start_frame": 58, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 58, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_732_1_0"}, {"texts": ["A woman is talking and showing tweezers."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1-2iEw6vVB0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_733_0_0"}, {"texts": ["A woman whose head is visible is holding a plucker and showing it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1-2iEw6vVB0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_734_0_0"}, {"texts": ["A woman wearing a black top is sitting on the first camel's back and a woman wearing a purple top is siting beside the another camel"], "durations": null, "exact_frames_per_prompt": [65], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-W9-MeRbLeA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 69, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_738_2_0"}, {"texts": ["The woman hugged by the other woman and the woman wearing pink and black t-shirt waving the hand"], "durations": null, "exact_frames_per_prompt": [11], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-W9-MeRbLeA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 69, "npz_gt_video_start_frame": 69, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 69, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_738_2_1"}, {"texts": ["A woman wearing a black top is coming from the left side and then hugs the first woman."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-W9-MeRbLeA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 66, "npz_gt_video_start_frame": 66, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 66, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_738_3_0"}, {"texts": ["A man wearing a blue jacket is sitting in the car, holding a taco in his hand and mixing sauce on the taco."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0-x8UaESVnY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_739_0_0"}, {"texts": ["A man wearing a black t-shirt is sitting on the right side and speaking."], "durations": null, "exact_frames_per_prompt": [63], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2X9FfApT3Eg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 67, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_740_0_0"}, {"texts": ["A man wearing a dark blue t-shirt is sitting on the left side speaking."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2X9FfApT3Eg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 30, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_740_1_ms_0"}, {"texts": ["The man starts drinking. "], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2X9FfApT3Eg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 30, "npz_gt_video_start_frame": 30, "npz_gt_video_end_frame": 67, "skip_frames_after_generation": 30, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_740_1_ms_1"}, {"texts": ["A brown horse is walking and carrying a boy upon him while a woman in a brown jacket holds the horse's leash and turns on the sand surface."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/07e-mCJlvDw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_748_0_0"}, {"texts": ["A boy wearing green clothes is riding the horse while a woman wearing a black sweater is holding the leash and moving on the ground."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/07e-mCJlvDw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_748_1_0"}, {"texts": ["A woman wearing brown clothes is standing in the center and holding a rope and watching the horse while a boy wearing a green jacket is sitting on the brown horse and looking at the woman."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/07e-mCJlvDw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_748_2_0"}, {"texts": ["A woman wearing a dark brown jacket, dark blue jeans, and goggles is holding the horse by a rope with her left hand and holding a stick in her right hand and a boy in a green jacket is riding the horse."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/07e-mCJlvDw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_749_0_0"}, {"texts": ["A boy wearing a black jacket, black jeans, a black helmet, and boots is sitting on the horse's back while holding the horse's harness and riding a horse on the soil surface while a woman wearing a brown jacket is holding the horse's harness and moving on the soil surface."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/07e-mCJlvDw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_749_1_0"}, {"texts": ["A brown horse is walking on the soil surface while carrying a boy on its back while a woman wearing a brown jacket and blue jeans is standing on the soil surface and holding a red rope in her left hand and a horsewhip in her right hand."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/07e-mCJlvDw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_749_2_0"}, {"texts": ["A yellow python is held by a group of people."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-e_t-PH4AOM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_750_3_0"}, {"texts": ["A man wearing a black shirt is standing and knotting his tie while two men are knotting the tie, a woman wearing a black y-shirt is standing and filming with a camera, and a woman wearing a printed top is looking at the men."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1c9Vb0MI4OI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_75_2_0"}, {"texts": ["A woman wearing a black top is standing and holding a camera while a man in a black shirt is tying a tie, the other man helps the third man to tie a tie and the other woman wearing spectacles is standing with the men and watching them."], "durations": null, "exact_frames_per_prompt": [42], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1c9Vb0MI4OI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 46, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_75_5_0"}, {"texts": ["A man wearing an orange t-shirt is standing in a bending position, holding a trimmer and trimming the sheep's hair."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-QIB4pgBNuA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_767_0_0"}, {"texts": ["A sheep is lying on a soil surface and getting its hair trimmed by the man."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-QIB4pgBNuA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_767_1_0"}, {"texts": ["A man wearing orange clothes is holding a trimmer and trimming the hairs of a sheep."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-QIB4pgBNuA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_768_0_0"}, {"texts": ["A sheep is getting hair trimmed by the man."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-QIB4pgBNuA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_768_1_0"}, {"texts": ["A person whose hand is visible is writing on the white board with a pen."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1W2-thF1RX8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_777_0_0"}, {"texts": ["A girl wearing a blue t-shirt is sitting, speaking, and doing hand gestures on the chair."], "durations": null, "exact_frames_per_prompt": [50], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/8FN0X4e4FOg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 29, "npz_gt_video_start_frame": 29, "npz_gt_video_end_frame": 79, "skip_frames_after_generation": 29, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_778_0_ms_0"}, {"texts": ["A girl wearing a blue t-shirt is sitting, speaking, and doing hand gestures on the chair."], "durations": null, "exact_frames_per_prompt": [49], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/8FN0X4e4FOg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 30, "npz_gt_video_start_frame": 30, "npz_gt_video_end_frame": 79, "skip_frames_after_generation": 30, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_779_0_ms_0"}, {"texts": ["A man wearing a blue t-shirt is standing on a green mat, holding a golf club."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/09_k1eXA-U8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 24, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_77_0_0"}, {"texts": ["The man wearing a blue t-shirt is playing a golf shot."], "durations": null, "exact_frames_per_prompt": [56], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/09_k1eXA-U8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 24, "npz_gt_video_start_frame": 24, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 24, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_77_0_1"}, {"texts": ["A person whose only hands are visible is holding a bowl, picks an object from a bowl."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2d1qX_z7nps.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_780_0_0"}, {"texts": ["The person puts it on a plate."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2d1qX_z7nps.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 40, "npz_gt_video_start_frame": 40, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 40, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_780_0_1"}, {"texts": ["A man wearing a greenish-white shirt is holding the lid of the barbeque grill and speaking while holding a tong."], "durations": null, "exact_frames_per_prompt": [49], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0OpeXEmne1o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 53, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_781_0_0"}, {"texts": ["The man closes the lid of the barbeque grill."], "durations": null, "exact_frames_per_prompt": [8], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0OpeXEmne1o.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 53, "npz_gt_video_start_frame": 53, "npz_gt_video_end_frame": 61, "skip_frames_after_generation": 53, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_781_0_1"}, {"texts": ["A boy is holding a fork and picking butter from a bowl and pouring over a bread and spreading it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5-hila5PdW0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_782_0_0"}, {"texts": ["A person wearing a white apron is standing and making sushi using a bamboo mat on a white chopping board."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2k3n5OqKlrA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_784_0_0"}, {"texts": ["A man wearing a black cloth is sitting on the floor and moving his hand towards the yellow stuff and looking at the boy while a boy is standing on the right side and reading a paper loudly."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0PKC1pzBCFA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_785_0_0"}, {"texts": ["A boy is standing in the front and reading a newspaper while a man wearing black clothes is sitting and looking in the direction of the boy."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0PKC1pzBCFA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_785_1_0"}, {"texts": ["A man whose hand and head is visible, is holding a pair of tongs and grilling some shrimps and meat on the barbeque."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0y8Ni1jXW-Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_78_0_0"}, {"texts": ["A man wearing a striped t-shirt is standing near the table and peeling the potato while a group of people including kids are standing, sitting, and moving and a stopwatch on a tablet is running."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4obTIAbhTeE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_795_0_0"}, {"texts": ["A boy wearing a printed t-shirt is looking on the iPad in which a timer is running while a group of people in which some people are sitting, a man is standing and peeling a potato and another man is standing and drinking and two people are standing behind him."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4obTIAbhTeE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_795_2_0"}, {"texts": ["A boy wearing a yellow t-shirt is sitting on the bed, and trying to fold the cloth."], "durations": null, "exact_frames_per_prompt": [72], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-qlJmXRti-g.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 8, "npz_gt_video_start_frame": 8, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 8, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_798_1_0"}, {"texts": ["A man whose only hand is visible is holding a tong and turning over the food on the grill machine."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0y8Ni1jXW-Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_79_0_0"}, {"texts": ["A man wearing a black t-shirt and red shorts is sitting and opening a tape."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-R5bm4G2SpQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_7_0_0"}, {"texts": ["A man wearing green clothes is sitting while the other man in green top is holding a glass."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2RS9CrgQftk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 21, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_801_0_0"}, {"texts": ["The man is holding a glass."], "durations": null, "exact_frames_per_prompt": [32], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2RS9CrgQftk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 21, "npz_gt_video_start_frame": 21, "npz_gt_video_end_frame": 53, "skip_frames_after_generation": 21, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_801_0_1"}, {"texts": ["The man is cheering up."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2RS9CrgQftk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 53, "npz_gt_video_start_frame": 53, "npz_gt_video_end_frame": 71, "skip_frames_after_generation": 53, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_801_0_2"}, {"texts": ["The man is drinking."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2RS9CrgQftk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 71, "npz_gt_video_start_frame": 71, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 71, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_801_0_3"}, {"texts": ["A man wearing black clothes is sitting and holding a glass while another man wearing a green shirt is sitting on a brown sofa while speaking and then holding a glass."], "durations": null, "exact_frames_per_prompt": [52], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2RS9CrgQftk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 56, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_801_1_0"}, {"texts": ["The man wearing black clothes is cheering up and then drinking the man wearing a green shirt is cheering up and then drinking."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2RS9CrgQftk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 56, "npz_gt_video_start_frame": 56, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 56, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_801_1_1"}, {"texts": ["A baby girl wearing a pink dress is sitting on a couch, holding a pink cloth and playing with it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0mUIY4K-98c.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_805_0_0"}, {"texts": ["A woman wearing a maroon dress is sitting on a wooden floor with a cat on her lap and her hand in the front."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0qhFXtmwx9A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 29, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_806_0_0"}, {"texts": ["The woman then starts caressing the cat."], "durations": null, "exact_frames_per_prompt": [51], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0qhFXtmwx9A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 29, "npz_gt_video_start_frame": 29, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 29, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_806_0_1"}, {"texts": ["A white-black cat is lying in the lap of the woman."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0qhFXtmwx9A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 29, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_806_1_0"}, {"texts": ["The cat is getting caressed by the woman."], "durations": null, "exact_frames_per_prompt": [51], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0qhFXtmwx9A.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 29, "npz_gt_video_start_frame": 29, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 29, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_806_1_1"}, {"texts": ["A man wearing a white t-shirt is standing, places a glass on a white napkin."], "durations": null, "exact_frames_per_prompt": [36], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0jNFcr6wvFk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 40, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_809_0_0"}, {"texts": ["The man places a long clear glass on the table, and lifts the first glass again."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0jNFcr6wvFk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 40, "npz_gt_video_start_frame": 40, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 40, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_809_0_1"}, {"texts": ["A person whose hand is visible is caressing a dog."], "durations": null, "exact_frames_per_prompt": [58], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-iGWHpZ2TV4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 62, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_811_0_0"}, {"texts": ["A dog lying on the brown couch is being caressed by the person."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-iGWHpZ2TV4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_811_1_0"}, {"texts": ["A man wearing a brown-black t-shirt is standing on a soil golf course, moving his hand."], "durations": null, "exact_frames_per_prompt": [39], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1BmPuA4_AGk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 43, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_813_0_0"}, {"texts": ["The man starts playing golf."], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1BmPuA4_AGk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 43, "npz_gt_video_start_frame": 43, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 43, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_813_0_1"}, {"texts": ["A boy wearing an orange t-shirt is standing in front of the goats and feeding them the food."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0T_zBZCfq74.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_816_0_0"}, {"texts": ["A dark brown-white goat is standing on the left side of the boy and eating food by the boy while a white goat on the right side hits the brown-white goat."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0T_zBZCfq74.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 21, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_816_1_0"}, {"texts": ["The goat walks away while other white-grey goat comes from the left and starts eating the food by the boy and white goat walks towards the left."], "durations": null, "exact_frames_per_prompt": [59], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0T_zBZCfq74.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 21, "npz_gt_video_start_frame": 21, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 21, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_816_1_1"}, {"texts": ["A light brown-white goat is standing on the right side of the first goat and eating the food by the boy while another brown-white goat is coming from behind, towards the boy, and eating the food."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0T_zBZCfq74.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_816_2_0"}, {"texts": ["A boy wearing orange clothes is standing near the net and holding a cup and feeding the goats."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0T_zBZCfq74.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_817_0_0"}, {"texts": ["A white brown goat is standing and eating from the boy while another white goat is standing on the right."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0T_zBZCfq74.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 18, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_817_1_0"}, {"texts": ["The goat is going to the left."], "durations": null, "exact_frames_per_prompt": [7], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0T_zBZCfq74.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 18, "npz_gt_video_start_frame": 18, "npz_gt_video_end_frame": 25, "skip_frames_after_generation": 18, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_817_1_1"}, {"texts": ["A man wearing transparent gloves is putting a silver wheel trim on the wheel."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1j7qDoi1LP0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 45, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_82_0_0"}, {"texts": ["The man pointing his finger on the brake fluid container."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1j7qDoi1LP0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 45, "npz_gt_video_start_frame": 45, "npz_gt_video_end_frame": 71, "skip_frames_after_generation": 45, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_82_0_1"}, {"texts": ["The man starts opening the top of that container."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1j7qDoi1LP0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 71, "npz_gt_video_start_frame": 71, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 71, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_82_0_2"}, {"texts": ["A man wearing a dark-green t-shirt is standing and flipping a pancake in a pan with a spatula."], "durations": null, "exact_frames_per_prompt": [26], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1eCO28FZTXs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 30, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_830_0_0"}, {"texts": ["A girl wearing a white shirt is tying a black and red neck tie."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-GnF9V3-nuw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_831_0_0"}, {"texts": ["A girl wearing a white shirt is standing and adjusting a blue-red tie."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-GnF9V3-nuw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_832_0_0"}, {"texts": ["A woman wearing a pink top is standing and helping the girl while a boy wearing a brown t-shirt is standing, holding a knife, and spreading the sauce with it, and a man wearing a beige t-shirt is standing on the right side and putting sauce in the food."], "durations": null, "exact_frames_per_prompt": [51], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1JK-yDbqK_M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 55, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_834_0_0"}, {"texts": ["A girl wearing a white frock is standing and making a sandwich.\n while a woman wearing a red t-shirt is guiding her, a boy in a brown t-shirt is also making a sandwich, and a man in gray t-shirt is standing on the right and pouring the sauce."], "durations": null, "exact_frames_per_prompt": [51], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1JK-yDbqK_M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 55, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_834_1_0"}, {"texts": ["A man wearing a grey t-shirt is standing and helping the boy.\n while a woman wearing a red top is standing on the left and assisting the girl."], "durations": null, "exact_frames_per_prompt": [51], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1JK-yDbqK_M.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 55, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_834_3_0"}, {"texts": ["A man wearing a blue tracksuit is standing and doing a sheep shearing on the green grass surface with the help of a sheep shearing machine while group of people are standing on the backside."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-ZKVV01VwLM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 24, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_836_0_0"}, {"texts": ["A white sheep is getting sheared by the man while a group of people are standing at the back and few are moving."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-ZKVV01VwLM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 24, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_836_1_0"}, {"texts": ["A woman wearing a pink top is flipping an omelet in a black pan."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1z9-Z2gpWEI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 20, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_840_0_0"}, {"texts": ["A man wearing a black t-shirt and pants is standing in a golf swing position."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-RvbvRbhpgk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 25, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_841_0_0"}, {"texts": ["The man is hitting a golf ball with a golf stick."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-RvbvRbhpgk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 25, "npz_gt_video_start_frame": 25, "npz_gt_video_end_frame": 65, "skip_frames_after_generation": 25, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_841_0_1"}, {"texts": ["The man is leaning forward and picking up the golf tee from the ground."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-RvbvRbhpgk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 65, "npz_gt_video_start_frame": 65, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 65, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_841_0_2"}, {"texts": ["A woman wearing floral printed top is standing, removing the lid of the mixing jar."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-36efvC2K54.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 19, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_845_0_0"}, {"texts": ["The woman wearing floral printed top starts putting stuff from the mixing jar into a red bowl."], "durations": null, "exact_frames_per_prompt": [45], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-36efvC2K54.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 19, "npz_gt_video_start_frame": 19, "npz_gt_video_end_frame": 64, "skip_frames_after_generation": 19, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_845_0_1"}, {"texts": ["The woman wearing floral printed top then shows the bowl."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-36efvC2K54.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 64, "npz_gt_video_start_frame": 64, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 64, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_845_0_2"}, {"texts": ["A person whose only hands are visible is holding a pan handle in his left hand, and holding a steel spatula in his right hand and frying the green vegetables while stirring the vegetables in the pan with a steel spatula."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/08MbEs0I1Y4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_850_0_0"}, {"texts": ["A brown dog is sitting on the white surface and is looking at the white-brown dog and the person wearing grey clothes."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/3Q7L3gWx7QA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_857_4_0"}, {"texts": ["A boy wearing a black t-shirt is sitting in the baby trend sit chair and eating food."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-tTDXLTRZwQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_860_0_0"}, {"texts": ["A person wearing black clothes is fixing the tyre."], "durations": null, "exact_frames_per_prompt": [64], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2ztRm_qsKxo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 16, "npz_gt_video_start_frame": 16, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 16, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_862_0_0"}, {"texts": ["A woman wearing a white t-shirt and blue jeans is standing and starts walking."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/i8rtS5z9iJU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 34, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_864_0_0"}, {"texts": ["The woman is tilting her body to pick up the bed-sheet."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/i8rtS5z9iJU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 34, "npz_gt_video_start_frame": 34, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 34, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_864_0_1"}, {"texts": ["A man whose hand is only visible is taking out a baking tray from the oven. "], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0rJ0lbQDl3k.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 22, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_865_0_0"}, {"texts": ["The man is taking out some chicken juice through the spoon and pour it on the chicken."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0rJ0lbQDl3k.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 22, "npz_gt_video_start_frame": 22, "npz_gt_video_end_frame": 62, "skip_frames_after_generation": 22, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_865_0_1"}, {"texts": ["The man is adding some coriander."], "durations": null, "exact_frames_per_prompt": [18], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0rJ0lbQDl3k.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 62, "npz_gt_video_start_frame": 62, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 62, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_865_0_2"}, {"texts": ["A man on the right is standing and is speaking while a man on the left side in a blue jacket is standing on the grass while holding a golf stick."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1A7LqsE_knI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 39, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_868_0_0"}, {"texts": ["The man on the right then sits on the ground and is looking at the golf ball while speaking while the man on the left side bends towards the grass surface, he hits the golf ball to the left."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1A7LqsE_knI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 39, "npz_gt_video_start_frame": 39, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 39, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_868_0_1"}, {"texts": ["A man on the left is standing still while another man wearing blue and grey outfit, holding a golf stick in his right hand, is standing on the right side of first man and he is moving his left hand and saying something."], "durations": null, "exact_frames_per_prompt": [31], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1A7LqsE_knI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 35, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_868_1_0"}, {"texts": ["The man is looking at the golf ball."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1A7LqsE_knI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 35, "npz_gt_video_start_frame": 35, "npz_gt_video_end_frame": 76, "skip_frames_after_generation": 35, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_868_1_1"}, {"texts": ["The man hits the golf ball."], "durations": null, "exact_frames_per_prompt": [4], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1A7LqsE_knI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 76, "npz_gt_video_start_frame": 76, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 76, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_868_1_2"}, {"texts": ["A man wearing blue cloth is standing and holding golf stick while a man wearing blue cloth is standing on the left side on a green grass surface, holding a golf stick."], "durations": null, "exact_frames_per_prompt": [34], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1A7LqsE_knI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 38, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_869_0_0"}, {"texts": ["The man wearing blue cloth then sits down and talking about the golf while a man wearing blue cloth is playing a golf shot."], "durations": null, "exact_frames_per_prompt": [42], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1A7LqsE_knI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 38, "npz_gt_video_start_frame": 38, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 38, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_869_0_1"}, {"texts": ["A man wearing blue-black cloth is standing and holding golf stick while another man wearing grey pats is first standing and speaking then sits down while holding the golf stick."], "durations": null, "exact_frames_per_prompt": [73], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1A7LqsE_knI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 77, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_869_1_0"}, {"texts": ["The man is hitting a ball with the golf stick."], "durations": null, "exact_frames_per_prompt": [3], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1A7LqsE_knI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 77, "npz_gt_video_start_frame": 77, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 77, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_869_1_1"}, {"texts": ["A person whose hands are visible, is holding fork and picking food from the bowl."], "durations": null, "exact_frames_per_prompt": [42], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0n7pCDumJXs.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 7, "npz_gt_video_start_frame": 7, "npz_gt_video_end_frame": 49, "skip_frames_after_generation": 7, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_86_0_0"}, {"texts": ["A girl wearing a maroon dress is sitting and picking up a glass of shot from the table while a group of people are sitting near the woman and a few are standing at backside and one of them wipe the woman face with a white cloth."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5NP93lDKXK0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_872_0_ms_0"}, {"texts": ["A boy wearing a white t-shirt is sitting in the middle and looking at the girl while a person whose hand is visible is wiping the face of the woman with a white cloth, another girl wearing a pink jacket is sitting on the right side, and another boy wearing a red sweatshirt is moving at the back while holding a green bottle."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5NP93lDKXK0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_872_1_ms_0"}, {"texts": ["A girl wearing a red cloth whose hands are visible is wiping the neck of the first girl while a boy in a white t-shirt and a girl in a pink jacket is sitting at the back, and a person in red-white clothes is walking at the back holding a green bottle."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5NP93lDKXK0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 31, "npz_gt_video_start_frame": 31, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 31, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_872_2_0"}, {"texts": ["A girl wearing a pink jacket is sitting on the right side of the boy while another girl wearing a maroon top is sitting on the left and drinking shots, a person whose hand is visible is cleaning the girl's face with a towel, and another boy wearing a red sweatshirt is moving at the back while holding a green bottle."], "durations": null, "exact_frames_per_prompt": [40], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5NP93lDKXK0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 44, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_872_3_ms_0"}, {"texts": ["A boy wearing a white-black striped t-shirt is standing and drinking while a group of people are standing and drinking in the backside."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5NP93lDKXK0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 44, "npz_gt_video_start_frame": 44, "npz_gt_video_end_frame": 63, "skip_frames_after_generation": 44, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_872_5_0"}, {"texts": ["The boy starts eating something from the girl hand while a group of people looks at the man."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5NP93lDKXK0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 63, "npz_gt_video_start_frame": 63, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 63, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_872_5_1"}, {"texts": ["A group of people is standing and drinking."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5NP93lDKXK0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 45, "npz_gt_video_start_frame": 45, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 45, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_872_6_ms_0"}, {"texts": ["An elephant is walking in the middle of the first and the second elephant on the beach."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-TItfMkZpXo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_875_5_0"}, {"texts": ["A man wearing a light-blue shirt is fixing a blue bow with black spots."], "durations": null, "exact_frames_per_prompt": [54], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/29tH0AWxd84.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_876_0_0"}, {"texts": ["The man then turns the collar of the shirt down."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/29tH0AWxd84.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 58, "npz_gt_video_start_frame": 58, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 58, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_876_0_1"}, {"texts": ["A woman wearing a black coat is standing in front of a lectern and speaking."], "durations": null, "exact_frames_per_prompt": [53], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5JxdV8u3H9U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 27, "npz_gt_video_start_frame": 27, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 27, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_877_0_ms_0"}, {"texts": ["A woman wearing a black coat is standing and delivering a speech."], "durations": null, "exact_frames_per_prompt": [53], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5JxdV8u3H9U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 27, "npz_gt_video_start_frame": 27, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 27, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_878_0_ms_0"}, {"texts": ["A person whose only hands are visible is wearing white gloves and is rotating an apple with a black knife."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2hiPMnxCtDw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_884_0_0"}, {"texts": ["A man wearing a dark blue full-sleeve t-shirt and blue-printed sky blue shorts, is standing while holding a chainsaw machine, and he starts to turn on the switch of the chainsaw machine."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/sG4BmLx8DUQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 33, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_888_0_0"}, {"texts": ["The man touches cap of the bottle by the chainsaw guide bar to opens the cap of the bottle."], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/sG4BmLx8DUQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 33, "npz_gt_video_start_frame": 33, "npz_gt_video_end_frame": 70, "skip_frames_after_generation": 33, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_888_0_1"}, {"texts": ["The man keeps the chainsaw machine on the surface and tilts his body to pick up the bottle."], "durations": null, "exact_frames_per_prompt": [10], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/sG4BmLx8DUQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 70, "npz_gt_video_start_frame": 70, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 70, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_888_0_2"}, {"texts": ["A woman wearing a black cloth is standing and spreading the rice on the half nori sheet."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1DqDmAXzMhQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_890_0_0"}, {"texts": ["A baby on the left side is sitting on a blue chair wearing white clothes."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Bzn7lSvTmA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_891_0_0"}, {"texts": ["A man wearing a red t-shirt and a black cap is standing on the cream colored surface, and is putting the red food material on the bread."], "durations": null, "exact_frames_per_prompt": [28], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5X07hibp4MI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 32, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_896_0_0"}, {"texts": ["The man is pouring the brown food material on the bread."], "durations": null, "exact_frames_per_prompt": [48], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5X07hibp4MI.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 32, "npz_gt_video_start_frame": 32, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 32, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_896_0_1"}, {"texts": ["A person wearing black-red clothes is sitting and holding a surgical tape and peeling it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-R5bm4G2SpQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_8_0_0"}, {"texts": ["A man is standing and holding the leash of the dog."], "durations": null, "exact_frames_per_prompt": [55], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2lB6dcyys34.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 59, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_901_0_0"}, {"texts": ["The man is feeding the dog food."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2lB6dcyys34.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 59, "npz_gt_video_start_frame": 59, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 59, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_901_0_1"}, {"texts": ["A brown dog is walking on the grey floor and eating food while a person is standing and holding the leash, and the other person is feeding it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2lB6dcyys34.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_901_1_0"}, {"texts": ["A girl wearing a blue top is standing and mixing a dough in a bowl while a woman wearing a purple top is standing and mixing a dough in her hands and then she puts a dough in a bowl."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Y4zTYoHg4Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_906_0_0"}, {"texts": ["A girl wearing a purple top is standing and mixing a dough with hands while another girl wearing blue outfit is standing on the left side of first girl and she is mixing dough using her hands and she touched her face once using her left hand."], "durations": null, "exact_frames_per_prompt": [54], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Y4zTYoHg4Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 58, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_906_1_0"}, {"texts": ["The girl wearing a purple top is putting the dough down in the bowl."], "durations": null, "exact_frames_per_prompt": [22], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0Y4zTYoHg4Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 58, "npz_gt_video_start_frame": 58, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 58, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_906_1_1"}, {"texts": ["A man wearing a black cloth is holding a bowl with one hand and holding a chicken marinated in spices with another hand."], "durations": null, "exact_frames_per_prompt": [65], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0oAJm3f37WU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 69, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_907_0_0"}, {"texts": ["The man is putting it on the plate."], "durations": null, "exact_frames_per_prompt": [11], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0oAJm3f37WU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 69, "npz_gt_video_start_frame": 69, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 69, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_907_0_1"}, {"texts": ["A boy wearing a yellow-blue dress is sitting on the lap of a girl while a person whose hand is visible is sitting on the right side."], "durations": null, "exact_frames_per_prompt": [32], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-MytqRwRwBg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 36, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_908_0_0"}, {"texts": ["The boy is eating noodles with a white plastic fork while a girl wearing a frock is sitting behind the boy and a person wearing a blue t-shirt is sitting on the right side."], "durations": null, "exact_frames_per_prompt": [44], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-MytqRwRwBg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 36, "npz_gt_video_start_frame": 36, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 36, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_908_0_1"}, {"texts": ["A girl wearing a pink dress is sitting with a boy on her lap while a person wearing a blue t-shirt is sitting on the right side."], "durations": null, "exact_frames_per_prompt": [59], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-MytqRwRwBg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 63, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_908_1_0"}, {"texts": ["The girl is picking noodles from the boy's dress and putting it back on the plate."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-MytqRwRwBg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 63, "npz_gt_video_start_frame": 63, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 63, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_908_1_1"}, {"texts": ["A kid wearing a white cloth is sitting on the chair and eating cake with his finger."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/4NEOPglw-zM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_912_0_0"}, {"texts": ["A person wearing a graphic black t-shirt is sitting behind the table and making a bow."], "durations": null, "exact_frames_per_prompt": [49], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-gdyA7pMlBc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 53, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_914_0_0"}, {"texts": ["The person is cutting the extra pieces of fabrics from the bow."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-gdyA7pMlBc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 53, "npz_gt_video_start_frame": 53, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 53, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_914_0_1"}, {"texts": ["A man whose half body is visible wearing a black sweatshirt is standing and tying a knot into a bow tie."], "durations": null, "exact_frames_per_prompt": [46], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-gdyA7pMlBc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 50, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_915_0_0"}, {"texts": ["The man is cutting off the extra cloth in the bow tie with a scissor."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-gdyA7pMlBc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 50, "npz_gt_video_start_frame": 50, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 50, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_915_0_1"}, {"texts": ["A girl wearing a white designer t-shirt is standing and squeezing red paste from a packet."], "durations": null, "exact_frames_per_prompt": [24], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-vX6KljYppA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 28, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_927_0_0"}, {"texts": ["The girl puts the packet back and holds the spoon. "], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-vX6KljYppA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 28, "npz_gt_video_start_frame": 28, "npz_gt_video_end_frame": 53, "skip_frames_after_generation": 28, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_927_0_1"}, {"texts": ["The girl is spreading it on a piece of white bread with a spoon.\n"], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-vX6KljYppA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 53, "npz_gt_video_start_frame": 53, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 53, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_927_0_2"}, {"texts": ["A boy wearing a green and white striped t-shirt is sitting on the muddy surface near the brown rabbit, he is at first looking in the left direction and smiling."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/06lRs8M7bSA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 17, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_931_0_0"}, {"texts": ["The boy points to the rabbit."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/06lRs8M7bSA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 17, "npz_gt_video_start_frame": 17, "npz_gt_video_end_frame": 32, "skip_frames_after_generation": 17, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_931_0_1"}, {"texts": ["The boy starts touching the rabbit."], "durations": null, "exact_frames_per_prompt": [47], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/06lRs8M7bSA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 32, "npz_gt_video_start_frame": 32, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 32, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_931_0_2"}, {"texts": ["A brown rabbit sitting on the muddy surface is chewing the food while a boy wearing a white t -shirt sitting on the ground"], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/06lRs8M7bSA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 33, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_931_1_0"}, {"texts": ["The rabbit is at first caressed by the boy in a striped t-shirt"], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/06lRs8M7bSA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 33, "npz_gt_video_start_frame": 33, "npz_gt_video_end_frame": 63, "skip_frames_after_generation": 33, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_931_1_1"}, {"texts": ["The rabbit then moves in the left direction while a boy wearing a white t-shirt goes to pick the cup"], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/06lRs8M7bSA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 63, "npz_gt_video_start_frame": 63, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 63, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_931_1_2"}, {"texts": ["A boy wearing a green-white t-shirt is sitting on the ground, moving his hand while a brown rabbit is sitting on the ground, facing left, and eating something."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/06lRs8M7bSA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 33, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_932_0_0"}, {"texts": ["The boy is touching the rabbit."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/06lRs8M7bSA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 33, "npz_gt_video_start_frame": 33, "npz_gt_video_end_frame": 63, "skip_frames_after_generation": 33, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_932_0_1"}, {"texts": ["A brown rabbit sniffing the ground while a man wearing a white-green t-shirt is sitting and trying to touch the rabbit."], "durations": null, "exact_frames_per_prompt": [29], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/06lRs8M7bSA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 33, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_932_1_0"}, {"texts": ["The rabbit is being touched by a boy."], "durations": null, "exact_frames_per_prompt": [47], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/06lRs8M7bSA.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 33, "npz_gt_video_start_frame": 33, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 33, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_932_1_1"}, {"texts": ["A kid wearing blue-golden clothes is sitting and crying. "], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-PNcaCDLaFw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 13, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_934_0_0"}, {"texts": ["The kid wearing blue-golden clothes is keeping his hand on the woman."], "durations": null, "exact_frames_per_prompt": [67], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-PNcaCDLaFw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 13, "npz_gt_video_start_frame": 13, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 13, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_934_0_1"}, {"texts": ["A kid wearing a gray t-shirt is picking up garbage from the floor and is throwing it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/8HVSLiPy8Nw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_937_0_0"}, {"texts": ["A boy wearing a gray t-shirt is picking paper confetti from the floor and throwing it in the air."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/8HVSLiPy8Nw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_938_0_0"}, {"texts": ["A baby wearing a pink top is sitting in a baby feeding chair, drinking something from a straw while a lady is holding a juice box and a straw."], "durations": null, "exact_frames_per_prompt": [21], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2ByBLPJD82Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 25, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_948_0_0"}, {"texts": ["The baby is moving while a lady is moving her hands."], "durations": null, "exact_frames_per_prompt": [55], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2ByBLPJD82Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 25, "npz_gt_video_start_frame": 25, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 25, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_948_0_1"}, {"texts": ["A person whose hands are visible is giving the straw to the baby."], "durations": null, "exact_frames_per_prompt": [27], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2ByBLPJD82Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 31, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_948_1_0"}, {"texts": ["The person is moving."], "durations": null, "exact_frames_per_prompt": [49], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2ByBLPJD82Y.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 31, "npz_gt_video_start_frame": 31, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 31, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_948_1_1"}, {"texts": ["A woman wearing a black-white top and blue jeans is sitting and combing the hair of a dog."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-w3KSGlo1uY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_94_0_0"}, {"texts": ["A black-white dog is lying on the gray carpeted floor and getting his hair combed by the woman."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-w3KSGlo1uY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_94_1_0"}, {"texts": ["A man wearing a white t-shirt and grey pants is hitting a golf ball with a golf stick."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1V_7ovkjHCg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 17, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_953_0_0"}, {"texts": ["The man stands on the green grass field holding a golf stick."], "durations": null, "exact_frames_per_prompt": [64], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1V_7ovkjHCg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 17, "npz_gt_video_start_frame": 17, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 17, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_953_0_1"}, {"texts": ["A man wearing a white t-shirt and gray pants is standing in the golf swing position and hitting a golf ball with a golf stick."], "durations": null, "exact_frames_per_prompt": [17], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1V_7ovkjHCg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 21, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_954_0_0"}, {"texts": ["The man is standing and speaking."], "durations": null, "exact_frames_per_prompt": [60], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1V_7ovkjHCg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 21, "npz_gt_video_start_frame": 21, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 21, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_954_0_1"}, {"texts": ["A girl wearing a white shirt and a grey skirt is sitting on the bench, first holding a blue napkin,then She puts the napkin on the bench and starting to fold it."], "durations": null, "exact_frames_per_prompt": [77], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1QeszSopJhc.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 81, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_955_0_0"}, {"texts": ["A boy on the left side wearing a black t-shirt is sitting, moving his hands and speaking while a man wearing a black shirt is sitting on the right while putting his hands on the table and then he holds a glass and laughing while watching towards the boy."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-zSEHrWQ2BE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_961_0_0"}, {"texts": ["A man on the right side wearing a black shirt is sitting and laughing on the boy's talks."], "durations": null, "exact_frames_per_prompt": [65], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-zSEHrWQ2BE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 69, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_961_1_0"}, {"texts": ["The man at the end lifts his glass."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-zSEHrWQ2BE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 69, "npz_gt_video_start_frame": 69, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 69, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_961_1_1"}, {"texts": ["A girl wearing a blue top is sitting on a bed and picking the clothes kept on her right side on the bed."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-YKDJrc2p5w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_962_0_0"}, {"texts": ["A man in black clothing is at first standing on the wooden stage and watching the sheep shearing while another man wearing black and blue outfit is standing on the stage and removing the woolen fleece and the sheep is getting his woolen fleece removed."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-2-nYjSwo8U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 31, "npz_gt_video_start_frame": 31, "npz_gt_video_end_frame": 51, "skip_frames_after_generation": 31, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_966_6_0"}, {"texts": ["The man in black clothing turns while group of people are standing on the stage and third man wearing white and black outfit is moving towards left side."], "durations": null, "exact_frames_per_prompt": [13], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-2-nYjSwo8U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 51, "npz_gt_video_start_frame": 51, "npz_gt_video_end_frame": 64, "skip_frames_after_generation": 51, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_966_6_1"}, {"texts": ["The man in black clothing starts walking in the left direction while fourth man wearing purple outfit is standing near the stage, holding a mop in his hand and he is cleaning and other group of people are standing on the ground and fifth man wearing blue outfit is sitting on the right side."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-2-nYjSwo8U.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 64, "npz_gt_video_start_frame": 64, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 64, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_966_6_2"}, {"texts": ["A man wearing a black chef dress is standing, pouring something into the pan and mixing it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1ruzPN0fSKw.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_967_0_0"}, {"texts": ["A boy wearing a vine-colored shirt is standing on the grassy surface and feeding the pigeons sitting on the rock."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/-kHCPj7_bqU.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_969_0_0"}, {"texts": ["A person whose hands are visible is bandaging the leg of another person."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2dE9NFxQijo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_970_0_0"}, {"texts": ["A person whose leg is visible is getting his leg wrapped with a bandage while a person on the left side is wrapping the bandage."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2dE9NFxQijo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_970_1_0"}, {"texts": ["A woman is brushing her eyebrows with an eyebrow brush."], "durations": null, "exact_frames_per_prompt": [61], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0gTdR-nnLyY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 65, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_971_0_0"}, {"texts": ["The woman is showing the eyebrow maker pencil."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0gTdR-nnLyY.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 65, "npz_gt_video_start_frame": 65, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 65, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_971_0_1"}, {"texts": ["A man wearing specs is holding the newspaper and looking into it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/6vZS95ajUlo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_977_0_0"}, {"texts": ["A man is sitting and reading a newspaper."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/6vZS95ajUlo.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_978_0_0"}, {"texts": ["A man is wearing black pants is standing in a bending position while a black dog is eating something, a woman wearing a greet t-shirt is holding the dog's leash, a woman at the back is playing with another dog and a person is sitting at the back."], "durations": null, "exact_frames_per_prompt": [9], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1EVYUcLNXbE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 13, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_979_0_0"}, {"texts": ["The man steps back while the woman wearing a green t-shirt is coming towards the dog and caressing him."], "durations": null, "exact_frames_per_prompt": [44], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1EVYUcLNXbE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 13, "npz_gt_video_start_frame": 13, "npz_gt_video_end_frame": 57, "skip_frames_after_generation": 13, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_979_0_1"}, {"texts": ["A woman wearing a green t-shirt is standing holding a black dog's leash as a man wearing a grey t-shirt is bending and looking at the dog and then gets up and steps back to the right on a grey road surface."], "durations": null, "exact_frames_per_prompt": [37], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1EVYUcLNXbE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 41, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_979_1_0"}, {"texts": ["The woman wearing a green t-shirt is walking."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1EVYUcLNXbE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 41, "npz_gt_video_start_frame": 41, "npz_gt_video_end_frame": 55, "skip_frames_after_generation": 41, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_979_1_1"}, {"texts": ["The woman wearing a green t-shirt is caressing the dog and a group of people in which one is sitting rest are standing and doing different activities on a grey road surface."], "durations": null, "exact_frames_per_prompt": [25], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1EVYUcLNXbE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 55, "npz_gt_video_start_frame": 55, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 55, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_979_1_2"}, {"texts": ["A woman wearing gray pants is playing with the third dog while a black dog is eating and being caressed by the woman, a man is looking at it, two people are playing with the white dog, a woman is playing with the brown dog and a person is sitting on the path."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1EVYUcLNXbE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_979_2_0"}, {"texts": ["A black dog is standing and eating from a white bowl while a man wearing a blue t-shirt is leaning forward and looking at the dog, he then stands and steps back, and a woman wearing a green top is standing on the road holding the dog's belt, She moves her hand, starts scratching her neck, then walks forward and starts caressing the dog, A group of people are standing on the road in the backside while holding their dog's belt doing different activity."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1EVYUcLNXbE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_979_4_0"}, {"texts": ["A white-black dog is waking while a person is sitting and a person wearing blue t-shirt is leaning forward, and a woman wearing green t-shirt is standing and looking towards the black dog that is eating something in a bowl, and a man wearing gray t-shirt is standing and looking towards the black dog."], "durations": null, "exact_frames_per_prompt": [20], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1EVYUcLNXbE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 24, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_979_6_0"}, {"texts": ["The dog is playing with the second woman while a group of people are walking on the road, and a dog is moving on the road, and a woman wearing a green t-shirt is coming towards the black dog and petting."], "durations": null, "exact_frames_per_prompt": [56], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1EVYUcLNXbE.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 24, "npz_gt_video_start_frame": 24, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 24, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_979_6_1"}, {"texts": ["A person whose hand is visible, holding a fry pan, a plate and tongs and taking fish fry from the frying pan and putting in the plate."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/02pEmMBwFME.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_97_0_0"}, {"texts": ["A baby wearing a white t-shirt and purple pajamas is sitting on the floor and reading a book while a man is lying on the carpet next to the baby."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/10fd-o-m8lg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_980_0_0"}, {"texts": ["A person wearing a yellow t-shirt and green checkered pajamas is laying on the floor next to the baby."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/10fd-o-m8lg.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_980_1_0"}, {"texts": ["A woman wearing a striped cloth is standing, ironing the shirt with the iron machine on the ironing board."], "durations": null, "exact_frames_per_prompt": [30], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2z-a1d-w5zQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 34, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_981_0_0"}, {"texts": ["The woman wearing a striped cloth is showing the iron machine in the front."], "durations": null, "exact_frames_per_prompt": [14], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2z-a1d-w5zQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 34, "npz_gt_video_start_frame": 34, "npz_gt_video_end_frame": 48, "skip_frames_after_generation": 34, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_981_0_1"}, {"texts": ["The woman wearing a striped cloth is standing while holding the baby on the counter with her hands and speaking."], "durations": null, "exact_frames_per_prompt": [32], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2z-a1d-w5zQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 48, "npz_gt_video_start_frame": 48, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 48, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_981_0_2"}, {"texts": ["A baby wearing printed clothes is sitting on the counter while a woman is holding the baby and she is talking."], "durations": null, "exact_frames_per_prompt": [15], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2z-a1d-w5zQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 49, "npz_gt_video_start_frame": 49, "npz_gt_video_end_frame": 64, "skip_frames_after_generation": 49, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_981_1_0"}, {"texts": ["The baby wearing printed clothes starts holding curtains with it's right hand."], "durations": null, "exact_frames_per_prompt": [16], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2z-a1d-w5zQ.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 64, "npz_gt_video_start_frame": 64, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 64, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_981_1_1"}, {"texts": ["A black horse on the right side is moving and getting its feet cleaned by a woman and putting its mouth in the black-pink basket and another horse is standing on the left side and sniffing on the floor."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1tEJRzqqalM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_986_0_0"}, {"texts": ["A brown-white horse on the left side is moving and eating something while a woman wearing a blue sweater is brushing another horse then moves back and goes to the right then again starts brushing the horse."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1tEJRzqqalM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_986_1_0"}, {"texts": ["A woman wearing blue clothes is walking, touching and cleaning the feet of horse one while a white-brown horse is moving and eating something."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1tEJRzqqalM.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_986_2_0"}, {"texts": ["A man wearing a white cloth and a pink turban is sitting on the back of the first elephant while a man is sitting wearing a red turban, and a man in black t-shirt is riding another black elephant at the front."], "durations": null, "exact_frames_per_prompt": [19], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/05hKGU5928E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 23, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_987_0_0"}, {"texts": ["The man is riding while smoking while a man wearing a white shirt is standing on the wall on the right side next to the other black elephant."], "durations": null, "exact_frames_per_prompt": [57], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/05hKGU5928E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 23, "npz_gt_video_start_frame": 23, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 23, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_987_0_1"}, {"texts": ["A man wearing black clothes is sitting on the back of the second elephant and riding while another man wearing white clothes is riding the first elephant."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/05hKGU5928E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_987_1_0"}, {"texts": ["A black elephant is walking on the right side of the second elephant, in the opposite direction of the second elephant, carrying the first man on his back while a group of people are sitting on the back of elephants and a man is standing on the right side with an elephant."], "durations": null, "exact_frames_per_prompt": [58], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/05hKGU5928E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 62, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_987_4_0"}, {"texts": ["A black elephant is walking on the right side of the blackish boundary in the opposite direction of the first elephant and carrying the second man on his back while a black elephant standing beside the wall on the ride side"], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/05hKGU5928E.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_987_5_0"}, {"texts": ["A woman wearing a purple top and blue jeans is sitting on the dark brown horse's back while holding the horse harness and riding from left to right on the soil surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5-qOl012I-4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_988_0_0"}, {"texts": ["A dark brown horse is walking from left to right on the soil surface while carrying a woman on his back."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/5-qOl012I-4.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_988_1_0"}, {"texts": ["A baby wearing black cloth is sitting in the lap of a man and crying."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0cnlFOiCSO8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_991_0_0"}, {"texts": ["A man wearing a black cap is sitting and holding a baby and watching the baby."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/0cnlFOiCSO8.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_991_1_0"}, {"texts": ["A man wearing a white shirt and blue jeans is standing on a boat, holding a fishing rod, and pulling it."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/2E0x_34Fnps.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_996_0_0"}, {"texts": ["A man whose upper half-body is visible, wearing a black t-shirt and black gloves, is standing on the left side and is holding a ham meat in his hand, and is speaking while putting the ham meat on the griddle."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/13ba6HzNUlk.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_997_1_0"}, {"texts": ["A person in a black clothing is at first spreading a black paper with his hands."], "durations": null, "exact_frames_per_prompt": [35], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/11dU4SaFA-w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 39, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_999_0_0"}, {"texts": ["The person picks up the tape and applies it on the black paper."], "durations": null, "exact_frames_per_prompt": [41], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/11dU4SaFA-w.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 39, "npz_gt_video_start_frame": 39, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 39, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_999_0_1"}, {"texts": ["A person wearing a black top is dancing on a green surface."], "durations": null, "exact_frames_per_prompt": [76], "background": null, "npz_video": "storybench/npy_96x160pix_8fps/uvo-valid/videos/1qNpl-VZjM0.npy", "npz_video_start_frame": 0, "npz_video_end_frame": 4, "npz_gt_video_start_frame": 4, "npz_gt_video_end_frame": 80, "skip_frames_after_generation": 4, "storybench_mode": "action_exe", "indices_to_select": null, "comment": "UVO_sparse_val_9_0_0"}]